<!DOCTYPE HTML>
<html lang="en">

<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="教书的先生">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="http://yoursite.com">
    <!--SEO-->

<meta name="keywords" content="深度学习">


<meta name="description" content="第1章 Python入门1.5.4  Numpy的N维数组12345import numpy as npa = np.array([[1,2],[3,4]])b = np.array([[3,0...">


<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">
    <!--Title-->

<title>
    
    《深度学习入门》阅读笔记 |
    
    教书的先生
</title>

<link rel="alternate" href="/atom.xml" title="教书的先生" type="application/atom+xml">


<link rel="icon" href="/favicon.ico">

    

<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.7.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">
    



    

<script>
(function() {
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    } else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

</head></html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->
<body>
    <header class="main-header"  style="background-image:url(
    http://snippet.shenliyang.com/img/banner.jpg)"
     >
    <div class="main-header-box">
        <a class="header-avatar" href="/" title='王荣胜'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a>
        <div class="branding">
            <!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
            <img src="/img/branding.png" alt="Snippet 博客主题" class="img-responsive center-block">
            
        </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                        <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://yoursite.com">
                        教书的先生</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                        <li role="presentation" class="text-center">
                            <a href="/"><i class="fa "></i>
                                Home</a>
                        </li>
                        
                        <li role="presentation" class="text-center">
                            <a href="/archives/"><i class="fa "></i>
                                时间轴</a>
                        </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="《深度学习入门》阅读笔记">
            
            《深度学习入门》阅读笔记
            
        </h1>
        <div class="post-meta">
    
    <span class="categories-meta fa-wrap">
        <i class="fa fa-folder-open-o"></i>
        <a class="category-link" href="/categories/阅读笔记/">阅读笔记</a>
    </span>
    
    
    <span class="fa-wrap">
        <i class="fa fa-tags"></i>
        <span class="tags-meta">
            
            <a class="tag-link" href="/tags/深度学习/">深度学习</a>
            
        </span>
    </span>
    
    
    
    <span class="fa-wrap">
        <i class="fa fa-clock-o"></i>
        <span class="date-meta">
            2019/09/07</span>
    </span>
    
    <span class="fa-wrap">
        <i class="fa fa-eye"></i>
        <span id="busuanzi_value_page_pv"></span>
    </span>
    
    
</div>
        
        
    </div>
    
    <div class="post-body post-content">
        <h1 id="第1章-Python入门"><a href="#第1章-Python入门" class="headerlink" title="第1章 Python入门"></a>第1章 Python入门</h1><h2 id="1-5-4-Numpy的N维数组"><a href="#1-5-4-Numpy的N维数组" class="headerlink" title="1.5.4  Numpy的N维数组"></a>1.5.4  Numpy的N维数组</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">b = np.array([[<span class="number">3</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">6</span>]])</span><br><span class="line">print(a+b)</span><br><span class="line">print(a*b)</span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>:数学上，一维数组称为向量；二维数组称为矩阵；可以将一般化后的向量或矩阵等统称为张量。</p>
<h2 id="1-5-5-广播"><a href="#1-5-5-广播" class="headerlink" title="1.5.5 广播"></a>1.5.5 广播</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">b = np.array([<span class="number">10</span>,<span class="number">20</span>])</span><br><span class="line">print(a*b)</span><br></pre></td></tr></table></figure>

<h2 id="1-6-3-显示图像"><a href="#1-6-3-显示图像" class="headerlink" title="1.6.3 显示图像"></a>1.6.3 显示图像</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.image <span class="keyword">import</span> imread</span><br><span class="line">img = imread(<span class="string">'图片名称'</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="第2章-感知机"><a href="#第2章-感知机" class="headerlink" title="第2章 感知机"></a>第2章 感知机</h1><p>感知机是神经网络(深度学习)的起源算法。</p>
<h2 id="2-3-3-使用权重和偏置的实现"><a href="#2-3-3-使用权重和偏置的实现" class="headerlink" title="2.3.3 使用权重和偏置的实现"></a>2.3.3 使用权重和偏置的实现</h2><p>权重值是控制输入信号的重要参数；偏置值调整了神经元被激活的容易程度。</p>
<h2 id="2-4-2-线性和非线性"><a href="#2-4-2-线性和非线性" class="headerlink" title="2.4.2 线性和非线性"></a>2.4.2 线性和非线性</h2><p>单层感知机的局限性在于它只能表示由一条直线分割的区间。</p>
<h2 id="2-5-2-异或门的实现"><a href="#2-5-2-异或门的实现" class="headerlink" title="2.5.2 异或门的实现"></a>2.5.2 异或门的实现</h2><p>叠加了多层的感知机称为多层感知机。</p>
<p>感知机的层数叫法问题。</p>
<h2 id="2-6-从与非门到计算机"><a href="#2-6-从与非门到计算机" class="headerlink" title="2.6 从与非门到计算机"></a>2.6 从与非门到计算机</h2><p>实际上，使用感知机甚至可以表示计算机！</p>
<h1 id="第3章-神经网络"><a href="#第3章-神经网络" class="headerlink" title="第3章 神经网络"></a>第3章 神经网络</h1><p>当拥有感知机的同时我们也知道了两个消息：</p>
<ol>
<li><p>好消息：对于复杂的函数，感知机也能通过叠加层数来有可能性的实现。</p>
</li>
<li><p>坏消息是：<strong>设定权重的工作在感知机中仍只能是由人工进行的</strong>。</p>
</li>
</ol>
<p>而神经网络的出现就是为了解决来自感知机的坏消息。</p>
<h3 id="3-1-3-激活函数登场"><a href="#3-1-3-激活函数登场" class="headerlink" title="3.1.3 激活函数登场"></a>3.1.3 激活函数登场</h3><p>激活函数的作用在于决定如何来激活输入信号的总和。</p>
<p><img src="https://i.loli.net/2019/09/07/UgvDeCzXq1MoBdV.png" alt="微信截图_20190907111807.png"></p>
<h3 id="3-2-激活函数"><a href="#3-2-激活函数" class="headerlink" title="3.2 激活函数"></a>3.2 激活函数</h3><p>阶跃函数：函数以阈值为界，一旦输入超过阈值，就切换输出。</p>
<p>实际上，<strong>如果将激活函数从阶跃函数换成其他函数，我们就可以进入到神经网络的世界了</strong>。</p>
<h3 id="3-2-5-sigmiod函数和阶跃函数的比较"><a href="#3-2-5-sigmiod函数和阶跃函数的比较" class="headerlink" title="3.2.5 sigmiod函数和阶跃函数的比较"></a>3.2.5 sigmiod函数和阶跃函数的比较</h3><p>sigmoid函数是一条平滑的曲线，输出随着输入发生连续性变化；而阶跃函数以0为界，输出发生急剧性的变化。<br>sigmoid函数的平滑性对神经网络的学习具有重要的意义。</p>
<p>也就是说，相对于感知机中的神经元只能返回0或1的信号，神经网络中返回的是连续的实数值信号。</p>
<h4 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h4><ul>
<li><p>两者的图像结构均表示为：“输入小时，输出接近0（为0）；输入大时，随着输入的增大，输出靠近1（为1）”。</p>
</li>
<li><p>不管输入的大小为多少，输出信号的值始终在0到1之间。</p>
</li>
<li><p>均为非线性函数。</p>
</li>
</ul>
<h4 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h4><ul>
<li><p>阶跃函数：“竹筒敲石”。</p>
</li>
<li><p>sigmoid函数：“水车”。</p>
</li>
</ul>
<h3 id="3-2-6-非线性函数"><a href="#3-2-6-非线性函数" class="headerlink" title="3.2.6 非线性函数"></a>3.2.6 非线性函数</h3><p>输出值为输入值的常数倍的函数称为线性函数。</p>
<p>为了发挥叠加层的优势，神经网络必须使用非线性函数。</p>
<h3 id="3-5-输出层的设计"><a href="#3-5-输出层的设计" class="headerlink" title="3.5 输出层的设计"></a>3.5 输出层的设计</h3><p>神经网络可以使用在分类和回归问题上，不过需要根据情况改变<strong>输出层的激活函数</strong> ，一般而言，回归问题用恒等函数，分类问题用softmax函数。</p>
<p>softmax函数python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(a)</span>:</span></span><br><span class="line">	exp_a = np.exp(a)</span><br><span class="line">	sum_exp_a = np.sum(exp_a)</span><br><span class="line">	y = exp_a / sum_exp_a</span><br><span class="line">	<span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>

<h3 id="3-5-2-使用softmax函数时的注意事项"><a href="#3-5-2-使用softmax函数时的注意事项" class="headerlink" title="3.5.2 使用softmax函数时的注意事项"></a>3.5.2 使用softmax函数时的注意事项</h3><p>softmax函数的分子进行了指数的运算，可能会产生一些超大值，如果这些超大值进行除法运算，会出现”不确定”的情况，这就是产生了溢出问题。</p>
<p>改进的softmax函数python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(a)</span>:</span></span><br><span class="line">	c = np.max(a)</span><br><span class="line">	exp_a = np.exp(a - c)</span><br><span class="line">	sum_exp_a = np.sum(exp_a)</span><br><span class="line">	y = exp_a / sum_exp_a</span><br><span class="line">	<span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>

<h3 id="3-5-4-输出层的神经元数量"><a href="#3-5-4-输出层的神经元数量" class="headerlink" title="3.5.4 输出层的神经元数量"></a>3.5.4 输出层的神经元数量</h3><p>输出层的神经元数量需要根据需要解决的问题来决定。对于分类问题，输出层的神经元的数量一般设为类别的数量。</p>
<h2 id="第4章-神经网络的学习"><a href="#第4章-神经网络的学习" class="headerlink" title="第4章 神经网络的学习"></a>第4章 神经网络的学习</h2><p>“学习”是指从训练数据中自动获取<strong>最优权重参数</strong>的过程。</p>
<h3 id="4-1-1-数据驱动"><a href="#4-1-1-数据驱动" class="headerlink" title="4.1.1 数据驱动"></a>4.1.1 数据驱动</h3><p>对于一个数字“5”的识别，我们可以采用一些方法来识别：</p>
<ul>
<li><p>人暴力想出一个算法识别，得出答案。-人参与</p>
</li>
<li><p>人想到特征量（如一个横，一个类似s构成了5），然后采用机器学习（SVM，KNN）得出答案。-人参与</p>
</li>
<li><p>神经网络（深度学习）利用数据学习，机器自己识别判断。-完全机器</p>
</li>
</ul>
<p>深度学习也被称为端到端的机器学习。</p>
<p>神经网络的优点是对所有问题都可以采用同样的流程来解决，不管解决的是识别数字还是人脸，神经网络都是通过不断的学习所提供的数据，尝试发现待解决的问题。</p>
<h3 id="4-1-2-训练数据和测试数据"><a href="#4-1-2-训练数据和测试数据" class="headerlink" title="4.1.2 训练数据和测试数据"></a>4.1.2 训练数据和测试数据</h3><ul>
<li><p>训练数据：也称<strong>监督数据</strong>，用来训练新的模型的数据。</p>
</li>
<li><p>测试数据：为了检验模型的泛化能力。</p>
</li>
</ul>
<p>泛化能力指处理未被观察过的数据（不包含在训练数据中的数据）的能力。</p>
<p>获得泛化能力是机器学习的最终目标。</p>
<h3 id="4-4-1-梯度法"><a href="#4-4-1-梯度法" class="headerlink" title="4.4.1 梯度法"></a>4.4.1 梯度法</h3><p>根据寻找最小值还是最大值，寻找最小值的梯度法称为梯度下降法，寻找最大值的梯度法称为梯度上升法。但是通过反转损失函数的符号，求最大和最小值会变成相同的问题，所以一般来说，神经网络（深度学习）中，梯度法指的是梯度下降法。</p>
<h2 id="第5章-误差反向传播法"><a href="#第5章-误差反向传播法" class="headerlink" title="第5章 误差反向传播法"></a>第5章 误差反向传播法</h2><h3 id="5-4-简单层的实现"><a href="#5-4-简单层的实现" class="headerlink" title="5.4 简单层的实现"></a>5.4 简单层的实现</h3><p>Affine层是负责矩阵乘积的。</p>
<h2 id="第6章-与学习相关的技巧"><a href="#第6章-与学习相关的技巧" class="headerlink" title="第6章 与学习相关的技巧"></a>第6章 与学习相关的技巧</h2><h3 id="6-1-3-SGD的缺点"><a href="#6-1-3-SGD的缺点" class="headerlink" title="6.1.3 SGD的缺点"></a>6.1.3 SGD的缺点</h3><p>为了改正SGD的缺点，我们可以使用优化算法Momentum，AdaGrad，Adam等。</p>
<h2 id="第7章-卷积神经网络"><a href="#第7章-卷积神经网络" class="headerlink" title="第7章 卷积神经网络"></a>第7章 卷积神经网络</h2><h2 id="第8章-深度学习"><a href="#第8章-深度学习" class="headerlink" title="第8章 深度学习"></a>第8章 深度学习</h2>
    </div>
    
    <div class="post-footer">
        <div>
            
            转载声明：
            商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="http://wpa.qq.com/msgrd?v=3&uin=603329354&site=qq&menu=yes" target="_blank">教书的先生</a>
            
            
        </div>
        <div>
            
        </div>
    </div>
</article>
<div class="article-nav prev-next-wrap clearfix">
    
    
    <a href="/2019/09/05/机器学习VS深度学习的区别/" class="next-post btn btn-default" title='机器学习VS深度学习的区别'>
        <span class="hidden-lg">下一篇</span>
        <span class="hidden-xs">
            机器学习VS深度学习的区别</span><i class="fa fa-angle-right fa-fw"></i>
    </a>
    
</div>

<div id="comments">
    
<div id="lv-container" data-id="city" data-uid="MTAyMC8zMzA1MS85NjEz">
    <script type="text/javascript">
    (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
    })(document, 'script');
    </script>
</div>

</div>

                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">
            Table of Contents
        </h3>
        
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#第1章-Python入门"><span class="toc-text">第1章 Python入门</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-4-Numpy的N维数组"><span class="toc-text">1.5.4  Numpy的N维数组</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-5-广播"><span class="toc-text">1.5.5 广播</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-3-显示图像"><span class="toc-text">1.6.3 显示图像</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#第2章-感知机"><span class="toc-text">第2章 感知机</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-3-使用权重和偏置的实现"><span class="toc-text">2.3.3 使用权重和偏置的实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-2-线性和非线性"><span class="toc-text">2.4.2 线性和非线性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-2-异或门的实现"><span class="toc-text">2.5.2 异或门的实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-6-从与非门到计算机"><span class="toc-text">2.6 从与非门到计算机</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#第3章-神经网络"><span class="toc-text">第3章 神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-3-激活函数登场"><span class="toc-text">3.1.3 激活函数登场</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-激活函数"><span class="toc-text">3.2 激活函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-5-sigmiod函数和阶跃函数的比较"><span class="toc-text">3.2.5 sigmiod函数和阶跃函数的比较</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#相同点"><span class="toc-text">相同点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#不同点"><span class="toc-text">不同点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-6-非线性函数"><span class="toc-text">3.2.6 非线性函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-输出层的设计"><span class="toc-text">3.5 输出层的设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-2-使用softmax函数时的注意事项"><span class="toc-text">3.5.2 使用softmax函数时的注意事项</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-4-输出层的神经元数量"><span class="toc-text">3.5.4 输出层的神经元数量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第4章-神经网络的学习"><span class="toc-text">第4章 神经网络的学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-1-数据驱动"><span class="toc-text">4.1.1 数据驱动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-2-训练数据和测试数据"><span class="toc-text">4.1.2 训练数据和测试数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-1-梯度法"><span class="toc-text">4.4.1 梯度法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第5章-误差反向传播法"><span class="toc-text">第5章 误差反向传播法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-简单层的实现"><span class="toc-text">5.4 简单层的实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第6章-与学习相关的技巧"><span class="toc-text">第6章 与学习相关的技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-3-SGD的缺点"><span class="toc-text">6.1.3 SGD的缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第7章-卷积神经网络"><span class="toc-text">第7章 卷积神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第8章-深度学习"><span class="toc-text">第8章 深度学习</span></a></li></ol></li></ol>
        
    </div>
</aside>
                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
	


	
</footer>
<a id="back-to-top" class="icon-btn hide">
    <center><a href="https://sm.ms/image/XFPAnNmzoVjyf7k" target="_blank"><img src="https://i.loli.net/2019/09/06/XFPAnNmzoVjyf7k.png" ></a></center>
	
	
	
	
	
	
		<div class="dandelion">
  <span class="smalldan"></span>
  <span class="bigdan"></span>
</div>
<style type="text/css">
@media screen and (max-width:600px){
.dandelion{display: none !important;}
}
 .dandelion .smalldan {
width: 36px;
height: 60px;
left: 88px;   
background-position: 0 -90px;
border: 0px solid red;
}
.dandelion span {
-webkit-animation: ball-x 3s linear 2s infinite;
 -moz-animation: ball-x 3s linear 2s infinite;
 animation: ball-x 3s linear 2s infinite;
-webkit-transform-origin: bottom center;
 -moz-transform-origin: bottom center;
 transform-origin: bottom center;
}
.dandelion span {
display: block;
position: fixed;
z-index:9999999999;
bottom: 0px;
background-image: url(https://s2.ax1x.com/2019/08/17/mnS12j.png);
background-repeat: no-repeat;
_background: none;
}
.dandelion .bigdan {
width: 64px;
height: 115px;
left: 41px;
background-position: -86px -36px;
border: 0px solid red;
}
@keyframes ball-x {
 0% { transform:rotate(0deg);}
 25% { transform:rotate(5deg); }
 50% { transform:rotate(0deg);}
 75% { transform:rotate(-5deg);}
 100% { transform:rotate(0deg);}  
}
@-webkit-keyframes ball-x {
 0% { -webkit-transform:rotate(0deg);}
 25% { -webkit-transform:rotate(5deg); }
 50% { -webkit-transform:rotate(0deg);}
 75% { -webkit-transform:rotate(-5deg);}
 100% { -webkit-transform:rotate(0deg);}
}
@-moz-keyframes ball-x {
 0% { -moz-transform:rotate(0deg);}
 25% { -moz-transform:rotate(5deg); }
 50% { -moz-transform:rotate(0deg);}
 75% { -moz-transform:rotate(-5deg);}
 100% { -moz-transform:rotate(0deg);}
}
</style>
	
    <i class="fa fa-chevron-up"></i>
</a>
    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
    Total:
    <strong id="busuanzi_value_site_pv">
        <i class="fa fa-spinner fa-spin"></i>
    </strong>
    &nbsp; | &nbsp;
    Visitors:
    <strong id="busuanzi_value_site_uv">
        <i class="fa fa-spinner fa-spin"></i>
    </strong>
    
</div>
            </div>
            <div class="col-sm-12">
                <span>Copyright &copy;
                    2017
                </span> |
                <span>
                    Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a>
                </span> |
                <span>
                    Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a>
                </span>
            </div>
        </div>
    </div>
</div>


<script src="/assets/tagcanvas.min.js?rev=2.9"></script>
<script>
var tagOption = {
    textColour: '#444', // 字体颜色
    outlineMethod: 'block', // 选中模式
    outlineColour: '#FFDAB9', // 选中模式的颜色
    interval: 30 || 30, // 动画帧之间的时间间隔，值越大，转动幅度越大
    textHeight: 13,
    outlineRadius: 3,
    freezeActive: true || '', // 选中的标签是否继续滚动
    frontSelect: true || '', // 不选标签云后部的标签
    initial: [0.1, -0.1],
    depth: 0.5,
    decel: 0.95,
    maxSpeed: 0.03,
    reverse: true || '', // 是否反向触发
    fadeIn: 500, // 进入动画时间
    wheelZoom: false || '' // 是否启用鼠标滚轮
}
TagCanvas.Start('tag-cloud-3d', '', tagOption);
</script>


<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/app.js?rev=@@hash"></script>
</body>
</html>