<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>《深度学习入门》阅读笔记 | 教书的先生</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="第1章 Python入门1.5.4  Numpy的N维数组12345import numpy as npa = np.array([[1,2],[3,4]])b = np.array([[3,0],[0,6]])print(a+b)print(a*b)">
<meta name="keywords" content="深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="《深度学习入门》阅读笔记">
<meta property="og:url" content="http://yoursite.com/2019/09/07/《深度学习入门》阅读笔记/index.html">
<meta property="og:site_name" content="教书的先生">
<meta property="og:description" content="第1章 Python入门1.5.4  Numpy的N维数组12345import numpy as npa = np.array([[1,2],[3,4]])b = np.array([[3,0],[0,6]])print(a+b)print(a*b)">
<meta property="og:locale" content="ch">
<meta property="og:image" content="https://i.loli.net/2019/09/07/UgvDeCzXq1MoBdV.png">
<meta property="og:updated_time" content="2019-09-29T11:25:48.838Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《深度学习入门》阅读笔记">
<meta name="twitter:description" content="第1章 Python入门1.5.4  Numpy的N维数组12345import numpy as npa = np.array([[1,2],[3,4]])b = np.array([[3,0],[0,6]])print(a+b)print(a*b)">
<meta name="twitter:image" content="https://i.loli.net/2019/09/07/UgvDeCzXq1MoBdV.png">
  
  <link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.2.0/styles/github.min.css">
  <script src="//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', (event) => {
      document.querySelectorAll('pre code').forEach((block) => {
        hljs.highlightBlock(block);
      });
    });
  </script>
  <link rel="stylesheet" href="/css/index.css">
</head>
</html>
<body style="


  background-color: #eff0f6

">
  <div id="container">
    <nav id="nav">
  <header class="header">
    <a href="/" class="title">Clover Tuan</a>
  </header>
  <div class="ctnWrap">
    <div class="icons">
      
        
          
            <a href="https://dribbble.com/clovertuan" target="_blank" class="nav-icn iconfont icon-dribbble"></a>
          
        
          
            <a href="https://www.behance.net/clovertuan" target="_blank" class="nav-icn iconfont icon-behance"></a>
          
        
          
            <a href="http://clovertuan.lofter.com/" target="_blank" class="nav-icn iconfont icon-lofter"></a>
          
        
          
            <a href="https://www.instagram.com/clovertuan/" target="_blank" class="nav-icn iconfont icon-instagram"></a>
          
        
          
            <a href="https://github.com/cloverTuan" target="_blank" class="nav-icn iconfont icon-github"></a>
          
        
      
    </div>
    <div class="menu">
      
        
            <a href="/" class="nav-menu ">HOME</a>
          
        
            <a href="/archives" class="nav-menu ">ARCHIVE</a>
          
        
            <a href="/about" class="nav-menu ">ABOUT</a>
          
        
      
    </div>
  </div>
</nav>
    <div id="main"><section class="article">
  <h2 class="title">《深度学习入门》阅读笔记</h2>
  <p class="sub">Sep 7, 2019</p>
  <article class="content">
    <p><strong>注意</strong>:数学上，一维数组称为向量；二维数组称为矩阵；可以将一般化后的向量或矩阵等统称为张量。</p>
<h2 id="1-5-5-广播"><a href="#1-5-5-广播" class="headerlink" title="1.5.5 广播"></a>1.5.5 广播</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">b = np.array([<span class="number">10</span>,<span class="number">20</span>])</span><br><span class="line">print(a*b)</span><br></pre></td></tr></table></figure>

<h2 id="1-6-3-显示图像"><a href="#1-6-3-显示图像" class="headerlink" title="1.6.3 显示图像"></a>1.6.3 显示图像</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.image <span class="keyword">import</span> imread</span><br><span class="line">img = imread(<span class="string">'图片名称'</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="第2章-感知机"><a href="#第2章-感知机" class="headerlink" title="第2章 感知机"></a>第2章 感知机</h1><p>感知机是神经网络(深度学习)的起源算法。</p>
<h2 id="2-3-3-使用权重和偏置的实现"><a href="#2-3-3-使用权重和偏置的实现" class="headerlink" title="2.3.3 使用权重和偏置的实现"></a>2.3.3 使用权重和偏置的实现</h2><p>权重值是控制输入信号的重要参数；偏置值调整了神经元被激活的容易程度。</p>
<h2 id="2-4-2-线性和非线性"><a href="#2-4-2-线性和非线性" class="headerlink" title="2.4.2 线性和非线性"></a>2.4.2 线性和非线性</h2><p>单层感知机的局限性在于它只能表示由一条直线分割的区间。</p>
<h2 id="2-5-2-异或门的实现"><a href="#2-5-2-异或门的实现" class="headerlink" title="2.5.2 异或门的实现"></a>2.5.2 异或门的实现</h2><p>叠加了多层的感知机称为多层感知机。</p>
<p>感知机的层数叫法问题。</p>
<h2 id="2-6-从与非门到计算机"><a href="#2-6-从与非门到计算机" class="headerlink" title="2.6 从与非门到计算机"></a>2.6 从与非门到计算机</h2><p>实际上，使用感知机甚至可以表示计算机！</p>
<h1 id="第3章-神经网络"><a href="#第3章-神经网络" class="headerlink" title="第3章 神经网络"></a>第3章 神经网络</h1><p>当拥有感知机的同时我们也知道了两个消息：</p>
<ol>
<li><p>好消息：对于复杂的函数，感知机也能通过叠加层数来有可能性的实现。</p>
</li>
<li><p>坏消息是：<strong>设定权重的工作在感知机中仍只能是由人工进行的</strong>。</p>
</li>
</ol>
<p>而神经网络的出现就是为了解决来自感知机的坏消息。</p>
<h3 id="3-1-3-激活函数登场"><a href="#3-1-3-激活函数登场" class="headerlink" title="3.1.3 激活函数登场"></a>3.1.3 激活函数登场</h3><p>激活函数的作用在于决定如何来激活输入信号的总和。</p>
<p><img src="https://i.loli.net/2019/09/07/UgvDeCzXq1MoBdV.png" alt="微信截图_20190907111807.png"></p>
<h3 id="3-2-激活函数"><a href="#3-2-激活函数" class="headerlink" title="3.2 激活函数"></a>3.2 激活函数</h3><p>阶跃函数：函数以阈值为界，一旦输入超过阈值，就切换输出。</p>
<p>实际上，<strong>如果将激活函数从阶跃函数换成其他函数，我们就可以进入到神经网络的世界了</strong>。</p>
<h3 id="3-2-5-sigmiod函数和阶跃函数的比较"><a href="#3-2-5-sigmiod函数和阶跃函数的比较" class="headerlink" title="3.2.5 sigmiod函数和阶跃函数的比较"></a>3.2.5 sigmiod函数和阶跃函数的比较</h3><p>sigmoid函数是一条平滑的曲线，输出随着输入发生连续性变化；而阶跃函数以0为界，输出发生急剧性的变化。<br>sigmoid函数的平滑性对神经网络的学习具有重要的意义。</p>
<p>也就是说，相对于感知机中的神经元只能返回0或1的信号，神经网络中返回的是连续的实数值信号。</p>
<h4 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h4><ul>
<li><p>两者的图像结构均表示为：“输入小时，输出接近0（为0）；输入大时，随着输入的增大，输出靠近1（为1）”。</p>
</li>
<li><p>不管输入的大小为多少，输出信号的值始终在0到1之间。</p>
</li>
<li><p>均为非线性函数。</p>
</li>
</ul>
<h4 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h4><ul>
<li><p>阶跃函数：“竹筒敲石”。</p>
</li>
<li><p>sigmoid函数：“水车”。</p>
</li>
</ul>
<h3 id="3-2-6-非线性函数"><a href="#3-2-6-非线性函数" class="headerlink" title="3.2.6 非线性函数"></a>3.2.6 非线性函数</h3><p>输出值为输入值的常数倍的函数称为线性函数。</p>
<p>为了发挥叠加层的优势，神经网络必须使用非线性函数。</p>
<h3 id="3-5-输出层的设计"><a href="#3-5-输出层的设计" class="headerlink" title="3.5 输出层的设计"></a>3.5 输出层的设计</h3><p>神经网络可以使用在分类和回归问题上，不过需要根据情况改变<strong>输出层的激活函数</strong> ，一般而言，回归问题用恒等函数，分类问题用softmax函数。</p>
<p>softmax函数python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(a)</span>:</span></span><br><span class="line">	exp_a = np.exp(a)</span><br><span class="line">	sum_exp_a = np.sum(exp_a)</span><br><span class="line">	y = exp_a / sum_exp_a</span><br><span class="line">	<span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>

<h3 id="3-5-2-使用softmax函数时的注意事项"><a href="#3-5-2-使用softmax函数时的注意事项" class="headerlink" title="3.5.2 使用softmax函数时的注意事项"></a>3.5.2 使用softmax函数时的注意事项</h3><p>softmax函数的分子进行了指数的运算，可能会产生一些超大值，如果这些超大值进行除法运算，会出现”不确定”的情况，这就是产生了溢出问题。</p>
<p>改进的softmax函数python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(a)</span>:</span></span><br><span class="line">	c = np.max(a)</span><br><span class="line">	exp_a = np.exp(a - c)</span><br><span class="line">	sum_exp_a = np.sum(exp_a)</span><br><span class="line">	y = exp_a / sum_exp_a</span><br><span class="line">	<span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>

<h3 id="3-5-4-输出层的神经元数量"><a href="#3-5-4-输出层的神经元数量" class="headerlink" title="3.5.4 输出层的神经元数量"></a>3.5.4 输出层的神经元数量</h3><p>输出层的神经元数量需要根据需要解决的问题来决定。对于分类问题，输出层的神经元的数量一般设为类别的数量。</p>
<h2 id="第4章-神经网络的学习"><a href="#第4章-神经网络的学习" class="headerlink" title="第4章 神经网络的学习"></a>第4章 神经网络的学习</h2><p>“学习”是指从训练数据中自动获取<strong>最优权重参数</strong>的过程。</p>
<h3 id="4-1-1-数据驱动"><a href="#4-1-1-数据驱动" class="headerlink" title="4.1.1 数据驱动"></a>4.1.1 数据驱动</h3><p>对于一个数字“5”的识别，我们可以采用一些方法来识别：</p>
<ul>
<li><p>人暴力想出一个算法识别，得出答案。-人参与</p>
</li>
<li><p>人想到特征量（如一个横，一个类似s构成了5），然后采用机器学习（SVM，KNN）得出答案。-人参与</p>
</li>
<li><p>神经网络（深度学习）利用数据学习，机器自己识别判断。-完全机器</p>
</li>
</ul>
<p>深度学习也被称为端到端的机器学习。</p>
<p>神经网络的优点是对所有问题都可以采用同样的流程来解决，不管解决的是识别数字还是人脸，神经网络都是通过不断的学习所提供的数据，尝试发现待解决的问题。</p>
<h3 id="4-1-2-训练数据和测试数据"><a href="#4-1-2-训练数据和测试数据" class="headerlink" title="4.1.2 训练数据和测试数据"></a>4.1.2 训练数据和测试数据</h3><ul>
<li><p>训练数据：也称<strong>监督数据</strong>，用来训练新的模型的数据。</p>
</li>
<li><p>测试数据：为了检验模型的泛化能力。</p>
</li>
</ul>
<p>泛化能力指处理未被观察过的数据（不包含在训练数据中的数据）的能力。</p>
<p>获得泛化能力是机器学习的最终目标。</p>
<h3 id="4-4-1-梯度法"><a href="#4-4-1-梯度法" class="headerlink" title="4.4.1 梯度法"></a>4.4.1 梯度法</h3><p>根据寻找最小值还是最大值，寻找最小值的梯度法称为梯度下降法，寻找最大值的梯度法称为梯度上升法。但是通过反转损失函数的符号，求最大和最小值会变成相同的问题，所以一般来说，神经网络（深度学习）中，梯度法指的是梯度下降法。</p>
<h2 id="第5章-误差反向传播法"><a href="#第5章-误差反向传播法" class="headerlink" title="第5章 误差反向传播法"></a>第5章 误差反向传播法</h2><h3 id="5-4-简单层的实现"><a href="#5-4-简单层的实现" class="headerlink" title="5.4 简单层的实现"></a>5.4 简单层的实现</h3><p>Affine层是负责矩阵乘积的。</p>
<h2 id="第6章-与学习相关的技巧"><a href="#第6章-与学习相关的技巧" class="headerlink" title="第6章 与学习相关的技巧"></a>第6章 与学习相关的技巧</h2><h3 id="6-1-3-SGD的缺点"><a href="#6-1-3-SGD的缺点" class="headerlink" title="6.1.3 SGD的缺点"></a>6.1.3 SGD的缺点</h3><p>为了改正SGD的缺点，我们可以使用优化算法Momentum，AdaGrad，Adam等。</p>
<h2 id="第7章-卷积神经网络"><a href="#第7章-卷积神经网络" class="headerlink" title="第7章 卷积神经网络"></a>第7章 卷积神经网络</h2><h2 id="第8章-深度学习"><a href="#第8章-深度学习" class="headerlink" title="第8章 深度学习"></a>第8章 深度学习</h2>
  </article>
  <footer class="f-cf">
    
      <a href="/2019/09/10/使用cython加速代码运行/" class="link f-fl">⟵使用cython加速代码运行</a>
    
    
      <a href="/2019/09/05/机器学习VS深度学习的区别/" class="link f-fr">机器学习VS深度学习的区别⟶</a>
    
  </footer>
</section></div>
    <footer id="footer" class="f-cf">
  d.guangying@foxmail.com
  
    
      
        · <a href="https://dribbble.com/clovertuan" target="_blank" class="nav-icn">Dribbble</a>
      
    
      
        · <a href="https://www.behance.net/clovertuan" target="_blank" class="nav-icn">Behance</a>
      
    
      
        · <a href="http://clovertuan.lofter.com/" target="_blank" class="nav-icn">Lofter</a>
      
    
      
        · <a href="https://www.instagram.com/clovertuan/" target="_blank" class="nav-icn">Instagram</a>
      
    
      
        · <a href="https://github.com/cloverTuan" target="_blank" class="nav-icn">GitHub</a>
      
    
  
  <span class="copyright">All rights reserved @Clover Tuan</span>
</footer>
  </div>
</body>
</html>