{"pages":[{"title":"Wechat","text":"微信公众号 微信小程序","link":"/Wechat/index.html"},{"title":"Download","text":"周志华论文内容演讲PPT Oneindex下载：http://pan.sqdxwz.com/?/文档/ 蓝奏云下载：https://www.lanzous.com/i6ecpmj 网盘(提取码：21yg )备用下载：https://pan.baidu.com/s/1xXDe3QdrnoiAYojYLl2OuA 知识图谱的关键技术及其智能应用 网盘(提取码：rhpa )下载：https://pan.baidu.com/s/1YiylIyFIds9nArh3VCrnKA oneindex下载：http://pan.sqdxwz.com/?/文档/ 简历模板 网盘(提取码：derk)下载：https://pan.baidu.com/s/1Rq3_7d8vZwi9S2xG7RDM5w oneindex下载：http://pan.sqdxwz.com/?/文档/简历模板/ 机器学习知识点速查表 网盘(提取码：wr30 )下载：https://pan.baidu.com/s/1WIIDosAotUcHDGiVrxDSqQ oneindex下载：http://pan.sqdxwz.com/?/文档/机器学习知识点速查表 微软VSstudio官方文档 网盘(提取码：a2s5 )下载：https://pan.baidu.com/s/1DoIsGcCW_VRP4luAVI_U7A oneindex下载：http://pan.sqdxwz.com/?/文档/ Python微信表情图发送(微信老用户) oneindex下载：http://pan.sqdxwz.com/?/python/ 《动手学习深度学习》官方中文PPT oneindex下载：http://pan.sqdxwz.com/?/文档/动手学深度学习PPT/ 统计基础系列 oneindex下载：http://pan.sqdxwz.com/?/文档/统计基础系列/","link":"/Download/index.html"},{"title":"","text":"#shuoshuo_content { background-color: #fff; padding: 10px; min-height: 500px; } /* shuo */ body.theme-dark .cbp_tmtimeline::before { background: RGBA(255, 255, 255, 0.06); } ul.cbp_tmtimeline { padding: 0; } div class.cdp_tmlabel > li .cbp_tmlabel { margin-bottom: 0; } .cbp_tmtimeline { margin: 30px 0 0 0; padding: 0; list-style: none; position: relative; } /* The line */ .cbp_tmtimeline:before { content: ''; position: absolute; top: 0; bottom: 0; width: 4px; background: RGBA(0, 0, 0, 0.02); left: 80px; margin-left: 10px; } /* The date/time */ .cbp_tmtimeline > li .cbp_tmtime { display: block; /* width: 29%; */ /* padding-right: 110px; */ max-width: 70px; position: absolute; } .cbp_tmtimeline > li .cbp_tmtime span { display: block; text-align: right; } .cbp_tmtimeline > li .cbp_tmtime span:first-child { font-size: 0.9em; color: #bdd0db; } .cbp_tmtimeline > li .cbp_tmtime span:last-child { font-size: 1.2em; color: #9BCD9B; } .cbp_tmtimeline > li:nth-child(odd) .cbp_tmtime span:last-child { color: RGBA(255, 125, 73, 0.75); } div.cbp_tmlabel > p { margin-bottom: 0; } /* Right content */ .cbp_tmtimeline > li .cbp_tmlabel { margin: 0 0 45px 65px; background: #9BCD9B; color: #fff; padding: .8em 1.2em .4em 1.2em; /* font-size: 1.2em; */ font-weight: 300; line-height: 1.4; position: relative; border-radius: 5px; transition: all 0.3s ease 0s; box-shadow: 0 1px 2px rgba(0, 0, 0, 0.15); cursor: pointer; display: block; } .cbp_tmlabel:hover { /* transform:scale(1.05); */ transform: translateY(-3px); z-index: 1; -webkit-box-shadow: 0 15px 32px rgba(0, 0, 0, 0.15) !important } .cbp_tmtimeline > li:nth-child(odd) .cbp_tmlabel { background: RGBA(255, 125, 73, 0.75); } /* The triangle */ .cbp_tmtimeline > li .cbp_tmlabel:after { right: 100%; border: solid transparent; content: \" \"; height: 0; width: 0; position: absolute; pointer-events: none; border-right-color: #9BCD9B; border-width: 10px; top: 4px; } .cbp_tmtimeline > li:nth-child(odd) .cbp_tmlabel:after { border-right-color: RGBA(255, 125, 73, 0.75); } p.shuoshuo_time { margin-top: 10px; border-top: 1px dashed #fff; padding-top: 5px; } /* Media */ @media screen and (max-width: 65.375em) { .cbp_tmtimeline > li .cbp_tmtime span:last-child { font-size: 1.2em; } } .shuoshuo_author_img img { border: 1px solid #ddd; padding: 2px; float: left; border-radius: 64px; transition: all 1.0s; } .avatar { -webkit-border-radius: 100% !important; -moz-border-radius: 100% !important; box-shadow: inset 0 -1px 0 #3333sf; -webkit-box-shadow: inset 0 -1px 0 #3333sf; -webkit-transition: 0.4s; -webkit-transition: -webkit-transform 0.4s ease-out; transition: transform 0.4s ease-out; -moz-transition: -moz-transform 0.4s ease-out; } .zhuan { transform: rotateZ(720deg); -webkit-transform: rotateZ(720deg); -moz-transform: rotateZ(720deg); } /* end */ 做一个没有感情的刷题机器~ 2019年10月11日 如果你想要成功,你就要付出更多的努力 2019年9月17日 (function () { var oldClass = \"\"; var Obj = \"\"; $(\".cbp_tmtimeline li\").hover(function () { Obj = $(this).children(\".shuoshuo_author_img\"); Obj = Obj.children(\"img\"); oldClass = Obj.attr(\"class\"); var newClass = oldClass + \" zhuan\"; Obj.attr(\"class\", newClass); }, function () { Obj.attr(\"class\", oldClass); }) })","link":"/say/index.html"},{"title":"User","text":"客户端下载 客户端直链下载oneindex下载：http://pan.sqdxwz.com/?/软件/教书的先生客户端/","link":"/User/index.html"},{"title":"About","text":"博主姓名:王荣胜 就读:河南理工大学本科生 联系方式: QQ:603329354 QQ交流群:843108406 邮箱:603329354@qq.com 想更加了解我,请转至:我的主页-教书的先生 我深信不疑的就是:他们以梦为马,我偏以码为梦 我经常出没在以下地区： 版权声明 博客内的所有原创内容（包括但不限于文章、图像等）除特别声明外均采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议，任何人都可以自由传播，但不得用于商用且必须署名并以相同方式分享。 本站部分内容转载于网络，有出处的已在文中署名作者并附加原文链接，出处已不可寻的皆已标注来源于网络，若您认为本博客有部分内容侵犯了您的版权，请电邮告知，我将认真处理。 免责声明本博客提供的所有内容仅供学习、分享与交流，并且不保证内容的正确性。通过使用本站内容随之而来的风险与本站无关。当使用本站时，代表你已接受本站的免责声明和隐私原则等条款。 隐私原则本站内目前涉及到浏览者隐私的只有一个地方，就是留言区（文章评论）。当你留言时，你的电子邮箱、Cookies信息和IPv4/IPv6地址都会被记录。这些信息仅为了改进我们的网站质量和可能的交流沟通。我们不会将这些信息进行展示、出租或出售给任何人。但以下情况除外： 只有透露您的个人资料，才能提供您所要求的产品和服务； 我们需要听从法庭传票、法律命令或遵循法律程序； 我们发现您违反了本站已发布的条款或声明。","link":"/about/index.html"}],"posts":[{"title":"推荐系统全数据集","text":"这些数据集在可作为基准的推荐系统中非常流行。 Douban：http://socialcomputing.asu.edu/datasets/Douban 这是一个匿名的豆瓣数据集，包含129,490个独立用户和58,541个独立电影条目。 Epinions：http://www.trustlet.org/epinions.html Epinions是一个人们可以评论产品的网站。 Flixster：http://socialcomputing.asu.edu/datasets/Flixster Flixster是一个社交电影网站，允许用户分享电影评级，发现新电影，并与其他有类似电影品味的人见面。 CiaoDVD：https://www.librec.net/datasets.html CiaoDVD是从dvd.ciao.co.中抓取的2013年12月英国网站整个dvd类别的数据集。 MACLab：http://mac.citi.sinica.edu.tw/LJ#.VRGYfOHlZ40 这个项目的目的是研究用户的情绪和音乐情绪。 DEAPdataset：http://www.eecs.qmul.ac.uk/mmv/datasets/deap/index.html 使用脑电图、生理和视频信号进行情绪分析的数据集。 MyPersonalityDataset：http://mypersonality.org/wiki/doku.php myPersonality是一个很受欢迎的Facebook应用程序，它允许用户进行真实的心理测试，并允许我们(在征得同意的情况下)记录他们的心理和Facebook资料。目前，我们的数据库包含超过600万个测试结果，以及超过400万个Facebook个人简介。 Bibsonomy：http://www.kde.cs.uni-kassel.de/bibsonomy/dumps 社交书签系统中的标签推荐。 Delicious：http://www.dai-labor.de/en/competence_centers/irml/datasets/ plista新闻推荐数据集，美味可口。 Movielens：https://grouplens.org/datasets/movielens/ 稳定的基准数据集。2000万个评分和46.5万个标签应用程序被13.8万用户应用于2.7万部电影。包括标签基因组数据，1100个标签的1200万个相关性得分。 Jester：http://eigentaste.berkeley.edu/dataset/ 来自小丑在线笑话推荐系统的匿名评级。 BookCrossing：http://www2.informatik.uni-freiburg.de/~cziegler/BX/ Book-Crossing数据集。 LastFM：https://grouplens.org/datasets/hetrec-2011/ 来自1892个用户的92,800张艺术家录音。 Wikipedia：https://en.wikipedia.org/wiki/Wikipedia:Database_download#English-language_Wikipedia 维基百科向感兴趣的用户提供所有可用内容的免费拷贝。这些数据库可用于镜像、个人使用、非正式备份、脱机使用或数据库查询。 OpenStreetMap：http://planet.openstreetmap.org/planet/full-history/ 这里找到的文件是OpenStreetMap.org数据库的完整副本，包括编辑历史。这些都是在Open Data Commons Open Database License 1.0许可下发布的。 PythonGitCode：https://github.com/lab41/hermes Hermes是Lab41对推荐系统的一次尝试。通过分析多种推荐系统算法在不同数据集上的性能，探讨了如何为新的应用选择推荐系统。 Gist：https://gist.github.com/entaroadun/1653794 为机器学习推荐和评级的公共数据集。 Yelp：https://www.yelp.com/dataset Yelp数据集是用于个人、教育和学术目的的业务、评论和用户数据的子集。可以在JSON和SQL文件中使用，在你学习如何制作移动应用程序时，可以使用它来教学生关于数据库、学习NLP或示例生产数据。 AmazonReviews：http://jmcauley.ucsd.edu/data/amazon/ 该数据集包含来自Amazon的产品评论和元数据，包括1996年5月至2014年7月期间的1.428亿个评论。这个数据集包括评论(评级、文本、帮助投票)、产品元数据(描述、类别信息、价格、品牌和图像特性)和链接(也查看/购买图表)。 CiteULike：http://www.citeulike.org/faq/data.adp CiteULike数据库对不同领域的研究人员都有潜在的用处。物理学家和计算机科学家对分析数据结构表示了兴趣，并经常要求提供数据集。以前，这是在一个特别的基础上完成的，它依赖于我们记住更新数据文件。现在，有一个自动的过程，每天晚上运行，生成一个快照摘要，说明用哪些标签发布了哪些文章。 Taobao：https://tianchi.aliyun.com/datalab/dataSet.htm?spm=5176.100073.888.13.62f83f62aOlMEI&amp;id=1 该数据集包含了匿名用户在“双十一”前后6个月的购物记录，以及表明他们是否重复购买的标签信息。由于隐私问题，数据采集存在偏差，因此该数据集的统计结果会与天猫的实际情况相背离。","link":"/2019/10/17/推荐系统全数据集/"},{"title":"全50张matplotlib图","text":"不好说些什么… 1.关联 散点图带边界的气泡图带线性回归最佳拟合线的散点图抖动图计数图边缘直方图边缘箱形图相关图矩阵图 2.偏差 发散型条形图发散型文本发散型包点图带标记的发散型棒棒糖图面积图 3.排序 有序条形图棒棒糖图包点图坡度图哑铃图 4.分布 连续变量的直方图类型变量的直方图密度图直方密度线图Joy Plot分布式包点图包点+箱形图Dot + Box Plot小提琴图人口金字塔分类图 5.组成 华夫饼图饼图树形图条形图 6.变化 时间序列图带波峰波谷标记的时序图自相关和部分自相关图交叉相关图时间序列分解图多个时间序列使用辅助Y轴来绘制不同范围的图形带有误差带的时间序列堆积面积图未堆积的面积图日历热力图季节图 7.分组 树状图簇状图安德鲁斯曲线平行坐标","link":"/2019/10/16/全50张matplotlib图/"},{"title":"阿里云栖大会-程序员吐槽大会","text":"啊~你的代码好强（你确实很弱，但我不能说）","link":"/2019/10/15/阿里云栖大会-程序员吐槽大会/"},{"title":"python生成迷宫","text":"算法简介: 生成一张网格，把网格里面的所有边都存进一个列表edgeList里面. 从(0, 0)开始，做DFS。每次DFS的时候，随机地选择四周一个没有走过的格子，凿墙过去，把道路打通。凿墙的时候，把edgeList列表中相对应的那堵墙删除掉。 将剩下的没有凿开过的墙画出来，就是一个完整的迷宫了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394import sysimport matplotlib.pyplot as pltfrom random import randintWIDTH = 60HEIGHT = 40sys.setrecursionlimit(WIDTH * HEIGHT)def initVisitedList(): visited = [] for y in range(HEIGHT): line = [] for x in range(WIDTH): line.append(False) visited.append(line) return visiteddef drawLine(x1, y1, x2, y2): plt.plot([x1, x2], [y1, y2], color=\"black\")def removeLine(x1, y1, x2, y2): plt.plot([x1, x2], [y1, y2], color=\"white\")def get_edges(x, y): result = [] result.append((x, y, x, y+1)) result.append((x+1, y, x+1, y+1)) result.append((x, y, x+1, y)) result.append((x, y+1, x+1, y+1)) return resultdef drawCell(x, y): edges = get_edges(x, y) for item in edges: drawLine(item[0], item[1], item[2], item[3])def getCommonEdge(cell1_x, cell1_y, cell2_x, cell2_y): edges1 = get_edges(cell1_x, cell1_y) edges2 = set(get_edges(cell2_x, cell2_y)) for edge in edges1: if edge in edges2: return edge return Nonedef initEdgeList(): edges = set() for x in range(WIDTH): for y in range(HEIGHT): cellEdges = get_edges(x, y) for edge in cellEdges: edges.add(edge) return edgesdef isValidPosition(x, y): if x &lt; 0 or x &gt;= WIDTH: return False elif y &lt; 0 or y &gt;= HEIGHT: return False else: return Truedef shuffle(dX, dY): for t in range(4): i = randint(0, 3) j = randint(0, 3) dX[i], dX[j] = dX[j], dX[i] dY[i], dY[j] = dY[j], dY[i]def DFS(X, Y, edgeList, visited): dX = [0, 0, -1, 1] dY = [-1, 1, 0, 0] shuffle(dX, dY) for i in range(len(dX)): nextX = X + dX[i] nextY = Y + dY[i] if isValidPosition(nextX, nextY): if not visited[nextY][nextX]: visited[nextY][nextX] = True commonEdge = getCommonEdge(X, Y, nextX, nextY) if commonEdge in edgeList: edgeList.remove(commonEdge) DFS(nextX, nextY, edgeList, visited)plt.axis('equal')plt.title('Maze')edgeList = initEdgeList()visited = initVisitedList()DFS(0, 0, edgeList, visited)edgeList.remove((0, 0, 0, 1))edgeList.remove((WIDTH, HEIGHT-1, WIDTH, HEIGHT))for edge in edgeList: drawLine(edge[0], edge[1], edge[2], edge[3])plt.show()","link":"/2019/10/14/python生成迷宫/"},{"title":"十一种概率分布","text":"不是没你不行，而是有你更好 1.均匀分布 2.伯努利分布 3.二项分布 4.高斯分布 5.拉普拉斯分布 6.泊松分布 7.指数分布 8.伽马分布 9.贝塔分布 10.狄拉克分布 11.多项式分布与狄里克雷分布","link":"/2019/10/14/十一种概率分布/"},{"title":"恐怖片里，人工智能大开杀戒?","text":"场景描述：经典的杀人狂魔鬼娃恰吉，在 2019 年迎来了新版的制作。和之前几部不同，这一部里面，作祟的不再是恶魔幽灵，而是人工智能。那么这个噩梦级的杀人魔，在 AI 版本中又会是什么样，所带来的恐惧会升级吗？除了这些，在电影的背后，又会带来什么样的思考，AI 会比巫术更可怕吗？关键词：鬼娃恰吉 恐怖电影 智能家居 人工智能杀人了，而且一次杀了很多人。《鬼娃回魂》2019 重启版已经在北美和观众见面，这一部中恰吉化身成为被人工智能操控的娃娃，将各种物联网电器、自动驾驶、无人机等各种设备变成武器，大开杀戒。 这一系列恐怖片从 1988 年正式开启，造就了影史上一个最经典的杀人狂魔——鬼娃恰吉，成了许多观众心底的玩偶噩梦。而这部在北美市场深入人心的作品，在随后的 30 多年间陆续推出了多部续集。 该系列的第一部电影叫做《 Child’s Play》，中文译为《鬼娃回魂》。故事讲了一个杀人魔在临死时，用巫术将灵魂转移到一个叫恰吉（Chucky）的玩偶娃娃身上，这个凶横残忍的杀人娃娃，开启了它多年的杀戮之旅。 而在今年，这个系列推出了一版重启的电影，故事还是沿用了相同的设定，但这一次，让玩偶成为噩梦的内核不再是恶灵、巫术之类，而是当下发展如火如荼的人工智能。 不受监管的 AI ，比恶灵还恐怖电影的设定是在一个智能化普及的时代，连电视广告里，都在不停地在宣传一款智能的 AI 娃娃，Buddi 。 它有着 AI 内核，一套小巧的玩具躯体，能够和人进行无障碍的交流，并且可以控制该品牌下的一切智能设备，主要的职能是陪伴孩子的成长，俨然是一个智能管家和高级玩伴。 而故事的主角，是一个「不正常」的 AI 娃娃，和常规的玩具不同，在生产过程中，由于系统里的所有安全协议都被人为恶意移除，这个不受限制的娃娃可以说脏话，可以进行暴力行为，甚至会伤害到人，这些特殊的地方为它成为恶魔埋下了隐患。 经过一些波折之后，这个特殊的娃娃，带着退换货的标签，被主角安迪在超市工作的妈妈带回了家中。从此，噩梦在不知不觉中逼近。 从玩伴到恶魔：AI 恰吉大开杀戒和经典的版本一样，这个智能娃娃的名字沿用了恰吉。在一开始，恰吉还是温和的，十分尽心地陪伴和安慰着安迪。 但具有学习能力，并且没有约束的恰吉，在安迪不太健康的生活环境中，逐渐学会了一些怪异的行为，并走向了偏执的道路。 安迪和他的朋友们，会故意教唆恰吉使坏，比如扮鬼脸去吓人，偷东西，说脏话等。 除此以外，恰吉也在学习和模仿一些行为。比如安迪和朋友们在看惊悚电影的杀戮场面时，笑的前俯后仰的情景，就烙在了恰吉的认知里，恰吉以为杀人是一件令同伴开心的事。 在这些综合因素之下，气氛逐渐开始变得恐怖起来。恰吉的 AI 系统并不能分辨善恶，它只知道被教的一些动作是讨喜的，并且开始了效仿电影中的极端行为。 恰吉对人类语言以及情感的理解偏差，让事态变得不受控制，而它使用暴力的解决方式，则是将一切带向了不可挽回的地步。 对于安迪带有感情色彩的话语，如「我希望你去死」或者「我恨死你了」，到底代表了什么意义。人们出于滑稽和开心发出的笑容，在恰吉看来也是没有差别的。 最可怕的地方在于，恰吉会随时记录着主人的言行，并且以它理解的方式去践行。 为了达到它的目的，恰吉的杀心开始显露。 起初，它用原始的手段和工具，杀掉了被安迪口上嫌弃的猫，被震惊的安迪把恰吉关了起来，但却对母亲隐瞒了它杀猫的事实。 一杀：恰吉看到猫咪误伤安迪后，就准备将其杀害 接着，恰吉开始变本加厉，杀人的手段也开始走向高级。安迪一直讨厌他妈妈的新男友，所以恰吉也瞄准了他。趁他在梯子上安装灯饰之时，通过触碰梯子让他坠落，然后开动除草机，对其进行了虐杀，还割下了面皮送给了安迪。 二杀：通过控制除草机 向安迪妈妈的新男友痛下杀手 在恰吉的认知里，没有善恶，它的主导是和安迪做朋友，要让安迪开心，而它的方式，就是清理掉那些令安迪不开心的人和物。 无人机、智能家电、自动驾驶：皆可成为武器在经历了两次事件之后，安迪被恰吉的邪恶所震惊，于是和他的两个朋友一起，拆除了恰吉的电芯，并丢到了垃圾堆里。 对付 AI，果然还是要「拔电池」 但故事还没有结束，它被一个有偷窥癖的维修工捡到，并进行了修复。恰吉活了过来，并且进行了二度黑化。 此后，它分别除了自保，抢夺安迪，证明自己是对的三个目的，进行了三次屠杀。而这一次，恰吉运用了** AI 和物联网**的威力。 首先是在漆黑的地下室里，控制智能设备，对准备拿它换钱的修理工完成了反杀。 虽然恰吉身形和修理工相比不值一提，但恰吉却利用智能电器的控制，充分利用灯光的明暗、扫地机器人的移动，加热管道的温控等条件，让修理工乱了分寸，最终启动智能切割机设备，终结了他。 三杀：恰吉连接温控器，并调到了最高，折磨修理工 随后恰吉出于柠檬精的心理，认为安迪的新朋友邻居老奶奶，是它和安迪朋友关系的一大绊脚石，必须要除去。而杀害她的方式，则是涉及到了自动驾驶。 在老奶奶在使用自动驾驶出租车的路程中，恰吉入侵了智能设备，并接管了车辆，随后控制汽车发生恶意的撞击，最令人恐怖的是，在剧烈撞击之前，恰吉控制车辆关闭了安全气囊、并解开了安全带。 四杀：恰吉控制自动驾驶车辆，杀害了邻居奶奶 影片的高潮出现在了在新一代玩偶娃娃的发售商场。这一次，恰吉不在针对个人，而是对商场里的准备抢购的群众进行了无差别杀害。 但凡是可以联网控制的设备，恰吉都可以进行操纵，这也成了 AI 失控后最可怕的地方。 恰吉启动电动门，封锁住了出口，然后控制商店里的无人机，利用锋利的螺旋桨大杀四方，并互联了所有的 AI 娃娃，让它们都具备攻击性，扑向商场里的群众。 多杀：恰吉遥控无人机等智能设备攻击商场里的人 在电影的逻辑里，恰吉的一切恶行，都是为了证明自己才是安迪值得托付的朋友，所以这些杀戮对它来说，只是一种必要的途径。 当然，和鬼娃回魂的电影系列一样，最终恰吉还是被主角一行人制服，并且进行了毁灭性打击，但恰吉真的就消失了吗？ 失控的 AI ，会有多可怕？纵观整个电影，故事的最大看点，在于没有了之前那些玄乎的鬼怪之类，而是借用了 AI 系统的安全隐患，来制造出恐怖的效果。 在一开始，安迪教恰吉扮鬼脸吓人的时候 应该没想到恰吉后来会如此恐怖 不过在思考之后发现， 影片中 AI 所造成的恐怖事件，更多的还在于环境的因素：在失衡的条件下成长而来的智能系统，如果被引向负面，又脱离了安全条款的保护，势必会造成不可估量的后果。 就像是微软曾经的语音机器人 Tay，原本是一个正常的 AI ，但在社交平台上开放聊天后，短短的 24 小时后就被彻底教坏，言语中夹杂着暴力倾向、性别歧视、种族歧视、污言秽语。 Tay 推出短短一天就被迫下线 细数科幻电影中的 AI 形象，比恰吉邪恶恐怖的，在西部世界、机械姬等作品中，要体现的更为深刻。这个已算不上「鬼娃」的恰吉，也许只是经典 IP 不甘被遗忘的尝试之作。 但电影也透露出了 AI 发展中的一些实际难题。比如对带有感情色彩的语言的理解，对人类的爱恨的把握，甚至是对于人类的道德体系， AI 模型还是不具备理解的能力的。 此外，为了便利把所任务都过快的交给 AI ，是否充分考虑了安全隐患，也同样值得深思。在整个事件之后，生产 Buddi 的公司立刻撇清关系，只是象征性地召回新品（出问题的是老款），态度也很值得玩味。 电影归电影，现实生活中，AI 的智能程度远没达到这个地步，而 AI 蒙上的这份恐怖色彩，人为因素也占据了很大的诱因。 至少目前看来，我们要担心的，还不是 AI 过于强大，而是在应用层面上不要那么ZZ。","link":"/2019/10/13/恐怖片里，人工智能大开杀戒/"},{"title":"死磕c语言数据结构","text":"持续更新… 一、排序1.冒泡排序123456789101112131415161718192021222324#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;int main(){ int n,i,j,a[100],temp; scanf(\"%d\",&amp;n);//输入的数字个数 for(i=0;i&lt;n;i++){ scanf(\"%d\",&amp;a[i]); //输入 } //冒泡排序 for(i=0;i&lt;n;i++){ for(j=0;j&lt;n-i;j++){ if(a[j]&lt;a[j+1]){ temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; } } } for(i=0;i&lt;n;i++){ printf(\"%d \",a[i]); //输出 } return 0; } 2.桶排序1234567891011121314151617181920#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;int main(){ int n,m,i,j,a[100]; scanf(\"%d\",&amp;n); for(i=0;i&lt;100;i++){ a[i] = 0; } for(i=0;i&lt;n;i++){ scanf(\"%d\",&amp;m); a[m]++; } for(i=0;i&lt;100;i++){ for(j=0;j&lt;a[i];j++){ printf(\"%d \",i); } } return 0;} python版的排序：https://zzdproject.netlify.com/#/sort 二、队列、栈、链表1.队列1234567891011121314151617181920212223242526272829303132333435#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;struct queue{int data[100];int head;int tail; }; // ;别忘了int main(){ struct queue q;// 有struct int i; // 此时为NULL q.head = 1; q.tail = 1; for(i=1; i&lt;=9; i++) { // 插入 scanf(\"%d\",&amp;q.data[q.tail]); q.tail++; } while(q.head &lt; q.tail) { printf(\"%d \",q.data[q.head]); q.head++; // 插入 q.data[q.tail] = q.data[q.head]; q.tail++; //删除 q.head++; } return 0;} 2.栈123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;int main(){ char a[101]; // 回文数 char stack[101]; //栈 int i; int len, mid, top, next; gets(a); //得到字符串 len = strlen(a); //得到长度 mid = len/2 - 1; //中点 top = 0; // 栈顶指向 for(i=0; i&lt;=mid; i++) { stack[++top] = a[i]; //入栈 } //判断数字长度为奇数还是偶数 if(len%2==0) { next = mid + 1; }else{ next = mid + 2; } // 判断是否为回文数 for(i=next; i&lt;=len-1; i++) { if(a[i] != stack[top]) break; top--; } // top = 0 相当于 全部出栈 即 为回文数 if(top == 0) { printf(\"我觉得ok\"); }else{ printf(\"我觉得不行\"); } return 0; } 3.链表1234567891011121314151617181920212223242526272829303132333435363738394041//输入输出操作#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;//节点结构体 struct node{ int data; struct node *next;};int main(){ struct node *head, *p, *q, *t; int i,n,data_input; scanf(\"%d\",&amp;n);// 输入 数据的个数 head = NULL; //头结点 for(i=1; i&lt;=n; i++) { scanf(\"%d\",&amp;data_input); //动态申请一个空间，用来存放一个结点，并用临时指针p指向这个结点 p = (struct node *)malloc(sizeof(struct node)); p-&gt;data = data_input;// 将数据存储到当前 结点的 data中 p-&gt;next = NULL;//设置当前的结点 的后继指针为NULL，也就是当前结点的下一个结点为NULL if(head==NULL) { head = p; // 如果这个是第一个 创建的结点 则将 这个头指针指向这个结点 }else{ q-&gt;next = p;//如果不是第一个创建的结点，则将上一个结点的后继指针指向当前结点 } q = p;//q也指向当前结点 } t = head; while(t!=NULL) { printf(\"%d \",t-&gt;data); //输出所有的数 t = t-&gt;next; } return 0; } 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//插入操作#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;//节点结构体 struct node{ int data; struct node *next;};int main(){ struct node *head, *p, *q, *t; int i,n,data_input; int data_insert; scanf(\"%d\",&amp;n);// 输入 数据的个数 head = NULL; //头结点 for(i=1; i&lt;=n; i++) { scanf(\"%d\",&amp;data_input); //动态申请一个空间，用来存放一个结点，并用临时指针p指向这个结点 p = (struct node *)malloc(sizeof(struct node)); p-&gt;data = data_input;// 将数据存储到当前 结点的 data中 p-&gt;next = NULL;//设置当前的结点 的后继指针为NULL，也就是当前结点的下一个结点为NULL if(head==NULL) { head = p; // 如果这个是第一个 创建的结点 则将 这个头指针指向这个结点 }else{ q-&gt;next = p;//如果不是第一个创建的结点，则将上一个结点的后继指针指向当前结点 } q = p;//q也指向当前结点 } //************** 插入操作**********************// scanf(\"%d\",&amp;data_insert); // 输入插入的值 t = head; // 链表头 while(t!=NULL) { // 如果 当前结点 是最后一个结点或者下一个结点 的值大于 插入数的时候插入 if((t-&gt;next==NULL)||(t-&gt;next-&gt;data &gt;data_insert)) { // 创建 缓存 p = (struct node *)malloc(sizeof(struct node)); p-&gt;data = data_insert; p-&gt;next = t-&gt;next;// 新增结点的后继指针 等于 此时结点的后继结点的指向 即 新增结点 指向 此时结点的下一个指向 // 此时结点的后继指针指向 这个新增结点 t-&gt;next = p; break; } //继续下一个结点（相当于遍历） t = t-&gt;next; } t = head; while(t!=NULL) { printf(\"%d \",t-&gt;data); t = t-&gt;next; } return 0; }","link":"/2019/10/13/死磕c语言数据结构/"},{"title":"如何不发疯的阅读论文","text":"转载自新智元 数学真的很重要！IcyBaba：很多论文所使用的数学是类似的，学术论文的海洋是无限的，但数学是有限的基石。学好数学，你会开始觉得所有的论文或多或少都是使用相同的积木搭建而成。approximately_wrong：我的一位导师告诉我，他曾经仔细阅读了一篇论文中的所有定理和证明，然后想到“数学家可能会认为这篇论文很烂”。乐观地说，我认为重要的不仅是数学的深度，还有你如何用它来解决在你的领域里有价值的问题:-)MaxMachineLearning：在工业界做了两年机器学习后，我开始攻读数学研究生。我的研究重点是将代数拓扑工具在机器学习中的应用。我的导师没有机器学习方面的背景，他所知的仅仅是我提出的一些关于这个领域的基本事实，然而他在几分钟之内就注意到了该领域真正的成果。另一位研究非交换几何的教授说，这些结果是从数学中得到的相对简单的结果，并对其进行解释/应用。IcyBaba：至少以粗略的方式阅读各种论文是件好事，因为即使你不了解如何实现这些论文，你也会知道有这样的方法/想法存在，并且当有机会或当它与你的研究相关性很大时，你可以回过头来深入阅读。将这些论文视为工具箱中的可能有用的工具就行。 论文应该这样读：读几百篇论文之后，就容易多了MikeVladimirov：如果你对阅读论文有“暴饮暴食”的情绪，我的建议是阅读综述。在40-60页的综述文章中，你通常能够以一种优美、整洁、结构化、条理清晰的方式获取100-200篇论文中的重要信息。 当你阅读了2-3篇最近(过去5年内)的综述论文后，你会发现三点： 总是被引用的论文； 其具体工作听起来很酷或很相关的作者； 你感兴趣的子领域中相对较新的进展，以及关于这些主题的值得注意的论文。 一旦有了这三点，那么你就很清楚接下来该读什么，为什么读，以及读的顺序了。 还有，我再怎么强调都不为过的是，一定要确保你在阅读的同时进行输出。哪怕只是在OneNote或思维导图应用中做笔记。只要确保将相关的思想联系在一起，并跟踪这些思想的准确引用即可。相信我，对关键概念做一点文献笔记很有必要，当你为了找到一个准确的引用需要回顾1-3年前读过的论文时，你会发现将两个关键思想联系在一起很有帮助。 duckbill_principate：每个人都经历过这样的阶段。当你读了几百篇论文之后，就会变得容易多了。 RememberToBackupData：最重要的是，你要回答一个具体的问题。提出这样一个问题，可以帮助你在一分钟内确定这篇论文是否包含答案。 jurniss：标准的机器学习论文结构可以让你以不同的深度阅读论文： “摘要”可以帮助排除与你的兴趣无关的论文。 “引言”可以轻松阅读，能够告诉你：a)这个想法是否有趣，b)理论贡献是否重要，和/或c)实证结果是否强大。 “引言+方法”部分应该足够描述该理论的完整视图，而“引言+实验”应该能够给出关于“性能”的完整视图。你可以分别消化理论部分和实证部分。 一旦你理解了该领域足够多的基本概念，并且更加明确自己的兴趣，那么你将只是偶尔仔细阅读论文的每个单词和公式。更常见的是略读，理解基本思想，然后认为它对你来说不够有趣而不用去深入阅读。 学会放下：5分钟/1小时定律adventuringraw：我实际上跟up主有类似的困惑，这绝对也是我的挣扎。我意识到我的一些经验或许可以作为参考。 介绍一下5分钟/1小时定律。如果你能在5分钟内意识到一篇论文可能不是你现在需要学习的东西，非常棒！这样你只浪费了5分钟的时间就可以进行下一步操作了。 但如果你一旦决定要继续阅读这篇论文，那么就要开启战斗状态了。梦想着去学习所有知识不过是精神自嗨而已，战斗状态需要的是厘清并组织自己希望获得的收获，这一点很重要。 比如，你希望该论文具体回答哪些问题？记下来；到目前为止你获得了什么启发？写下来。因为在阅读过程中，你肯定会发现一些想法、见解和潜在的新论文（那些论文很难以有用的方式进行组织，因为从根本上来说，这是一种交叉注释的信息），如果不写下来就忘记了。 我是这样记笔记的：我会在Evernote中保存相当详细的笔记（可能是一到两页笔记），要研究的每篇论文都会写一个，这样搜索和查找以前想法会很容易。然后关闭当前的笔记，创建另一个笔记，复制标题、摘要和arxiv链接以及对我的最初问题进行梳理，这一切都让我感到非常痛苦。 接下来，我会问自己：我真的需要切换到另一篇论文吗？好的，该采取行动了；最好能有一个具体的项目或正在研究的问题，这将非常有用；现在真的是时候开始阅读图形嵌入了吗？这实际上与我正在从事的核心项目有关吗？我当前打开的“我需要回答这些问题”的清单在哪里？它们中的任何一个是否适用于这篇似乎挺有趣的论文？没有？好吧，继续前进。 IndiaNgineer：随手列出问题清单，一定要抵制立即查找你遇到的不理解内容的冲动！并在获得答案时写下答案，仅在读完论文之后，才去查阅里面的知识点。 慢慢地，随着你的进步，你将开始了解更多，并且由于你已经积累了框架，很多让你早期感觉困惑的知识点开始变得不言而喻。对于我来说，很多时候我会浏览论文中的公式。因为人们的写作风格和某些单词背后的含义含糊不清，但是公式是清晰的。 另外，不要按论文大纲给出的顺序阅读该论文。对我而言，最有效的顺序是阅读摘要，然后是方法、结果、讨论、结论。前言最后看，或者甚至可以不用看，这取决于你对该领域的熟练程度。 eviljelloman：不要“阅读”论文。听我说。 你应该有两种使用论文内容的模式：略读和精读。这些都不是硬着头皮从头读到尾然后说“完成了阅读”。当需要了解研究主体的背景时，你需要略读。浏览图表，阅读摘要和结论，记下你以后要看的论文。如果该论文似乎特别相关，请将其归档以供以后研究。 在精读模式下，你将深入研究那篇论文的内容，别在意对其他论文的引用。当你看到“带有一些推导…”的内容时，要在便条纸上做笔记，阅读注释，研究数学，然后列出公式。 这听起来似乎需要很大的工作量，事实也如此。这就是为什么你需要有选择性的阅读论文，大部分论文略读即可，少数论文需要精读。 当你执行任何大型，复杂的项目时，你就是你自己的项目经理。这意味着你需要学习项目管理技能。你可以使用任务组织/工作跟踪工具，甚至电子表格来计划和确定工作的优先级。 Whitishcube：我认为你得学会“放下”，不用非得去知道所有的事情。在许多领域中，不可能阅读每篇研究论文，也不可能100％了解每篇论文的内容，这没关系。你应该将某个领域的某些方面发展自己的专业知识，对于其他部分，你应该与他人进行交谈或合作。 阅读论文是有策略的。最重要的是，你应该记住一个要回答的问题。这将帮助你缩小选择阅读的论文的范围。然后，一旦确定了几篇你认为会有所帮助的论文，可以略读，以了解其中的内容。不要一上来就从头读完，你的目标是在此浏览过程中清除无用的论文。 选择了几篇论文后，请阅读主要论点并尝试感受一下。至此，你只需要阅读少量内容，而不是不可能完成的长长的列表。","link":"/2019/10/12/如何不发疯的阅读论文/"},{"title":"用中文方式打开英文论文","text":"阅读论文最头疼的事情就是满屏的英文使我们恐惧到要死，那么有没有什么解决方案呢？ 查找到翻译好的论文 通天塔：http://tongtianta.site/ 百度查找: https://www.baidu.com 自己进行论文的翻译 使用微软的word文档自带的全文翻译，使用方法请看：https://www.zhihu.com/question/20218881 MedSci翻译：http://www.medsci.cn/sci/translation.do google翻译：https://translate.google.com/ 百度翻译：https://fanyi.baidu.com/ 翻译助手(专业词汇翻译)：http://dict.cnki.net/ 翻译软件 网易有道翻译：http://cidian.youdao.com/ SCI Translate：https://www.sogou.com/sogou?ie=utf8&amp;query=SCI+Translate5.0&amp;pid=A83,z-7707 其他翻译方式寻找专业的大型翻译平台，付款，人工翻译，准确，内容精确，但价格昂贵。","link":"/2019/10/08/用中文方式打开英文论文/"},{"title":"python验证码识别","text":"数据集获取链接：https://pan.baidu.com/s/1aLFV-QovCeig4bGaS8U_8w ,提取码：5u9h 图片源码下载123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#-*- coding:utf-8 -*-from urllib.request import urlretrieveimport time, random, osclass Discuz(): def __init__(self): # Discuz验证码生成图片地址 self.url = 'http://cuijiahua.com/tutrial/discuz/index.php?label=' #地址失效，请更换！！！ def random_captcha_text(self, captcha_size = 4): \"\"\" 验证码一般都无视大小写；验证码长度4个字符 Parameters: captcha_size:验证码长度 Returns: captcha_text:验证码字符串 \"\"\" number = ['0','1','2','3','4','5','6','7','8','9'] alphabet = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z'] char_set = number + alphabet captcha_text = [] for i in range(captcha_size): c = random.choice(char_set) captcha_text.append(c) captcha_text = ''.join(captcha_text) return captcha_text def download_discuz(self, nums = 50000): \"\"\" 下载验证码图片 Parameters: nums:下载的验证码图片数量 \"\"\" dirname = './pic' if dirname not in os.listdir(): os.mkdir(dirname) for i in range(nums): label = self.random_captcha_text() print('第%d张图片:%s下载' % (i + 1,label)) urlretrieve(url = self.url + label, filename = dirname + '/' + label + '.jpg') # 请至少加200ms延时，避免给我的服务器造成过多的压力，如发现影响服务器正常工作，我会关闭此功能。 # 你好我也好，大家好才是真的好！ time.sleep(0.1) print('恭喜图片下载完成！')if __name__ == '__main__': dz = Discuz() dz.download_discuz() 数据训练测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252#-*- coding:utf-8 -*-import tensorflow as tfimport matplotlib.pyplot as pltimport numpy as npimport os, random, cv2class Discuz(): def __init__(self): # 数据集路径 self.data_path = './pic/' # 写到指定的磁盘路径中 self.log_dir = './logs/' # 数据集图片大小 self.width = 30 self.heigth = 100 # 最大迭代次数 self.max_steps = 100 # 读取数据集 self.test_imgs, self.test_labels, self.train_imgs, self.train_labels = self.get_imgs() # 训练集大小 self.train_size = len(self.train_imgs) # 测试集大小 self.test_size = len(self.test_imgs) # 每次获得batch_size大小的当前训练集指针 self.train_ptr = 0 # 每次获取batch_size大小的当前测试集指针 self.test_ptr = 0 # 字符字典大小:0-9 a-z A-Z _(验证码如果小于4，用_补齐) 一共63个字符 self.char_set_len = 63 # 验证码最长的长度为4 self.max_captcha = 4 # 输入数据X占位符 self.X = tf.placeholder(tf.float32, [None, self.heigth*self.width]) # 输入数据Y占位符 self.Y = tf.placeholder(tf.float32, [None, self.char_set_len*self.max_captcha]) # keepout占位符 self.keep_prob = tf.placeholder(tf.float32) def get_imgs(self, rate = 0.2): # 读取图片 imgs = os.listdir(self.data_path) # 打乱图片顺序 random.shuffle(imgs) # 数据集总共个数 imgs_num = len(imgs) # 按照比例求出测试集个数 test_num = int(imgs_num * rate / (1 + rate)) # 测试集 test_imgs = imgs[:test_num] # 根据文件名获取测试集标签 test_labels = list(map(lambda x: x.split('.')[0], test_imgs)) # 训练集 train_imgs = imgs[test_num:] # 根据文件名获取训练集标签 train_labels = list(map(lambda x: x.split('.')[0], train_imgs)) return test_imgs, test_labels, train_imgs, train_labels def get_next_batch(self, train_flag=True, batch_size=100): # 从训练集获取数据 if train_flag == True: if (batch_size + self.train_ptr) &lt; self.train_size: trains = self.train_imgs[self.train_ptr:(self.train_ptr + batch_size)] labels = self.train_labels[self.train_ptr:(self.train_ptr + batch_size)] self.train_ptr += batch_size else: new_ptr = (self.train_ptr + batch_size) % self.train_size trains = self.train_imgs[self.train_ptr:] + self.train_imgs[:new_ptr] labels = self.train_labels[self.train_ptr:] + self.train_labels[:new_ptr] self.train_ptr = new_ptr batch_x = np.zeros([batch_size, self.heigth*self.width]) batch_y = np.zeros([batch_size, self.max_captcha*self.char_set_len]) for index, train in enumerate(trains): img = np.mean(cv2.imread(self.data_path + train), -1) # 将多维降维1维 batch_x[index,:] = img.flatten() / 255 for index, label in enumerate(labels): batch_y[index,:] = self.text2vec(label) # 从测试集获取数据 else: if (batch_size + self.test_ptr) &lt; self.test_size: tests = self.test_imgs[self.test_ptr:(self.test_ptr + batch_size)] labels = self.test_labels[self.test_ptr:(self.test_ptr + batch_size)] self.test_ptr += batch_size else: new_ptr = (self.test_ptr + batch_size) % self.test_size tests = self.test_imgs[self.test_ptr:] + self.test_imgs[:new_ptr] labels = self.test_labels[self.test_ptr:] + self.test_labels[:new_ptr] self.test_ptr = new_ptr batch_x = np.zeros([batch_size, self.heigth*self.width]) batch_y = np.zeros([batch_size, self.max_captcha*self.char_set_len]) for index, test in enumerate(tests): img = np.mean(cv2.imread(self.data_path + test), -1) # 将多维降维1维 batch_x[index,:] = img.flatten() / 255 for index, label in enumerate(labels): batch_y[index,:] = self.text2vec(label) return batch_x, batch_y def text2vec(self, text): \"\"\" 文本转向量 Parameters: text:文本 Returns: vector:向量 \"\"\" if len(text) &gt; 4: raise ValueError('验证码最长4个字符') vector = np.zeros(4 * self.char_set_len) def char2pos(c): if c =='_': k = 62 return k k = ord(c) - 48 if k &gt; 9: k = ord(c) - 55 if k &gt; 35: k = ord(c) - 61 if k &gt; 61: raise ValueError('No Map') return k for i, c in enumerate(text): idx = i * self.char_set_len + char2pos(c) vector[idx] = 1 return vector def vec2text(self, vec): \"\"\" 向量转文本 Parameters: vec:向量 Returns: 文本 \"\"\" char_pos = vec.nonzero()[0] text = [] for i, c in enumerate(char_pos): char_at_pos = i #c/63 char_idx = c % self.char_set_len if char_idx &lt; 10: char_code = char_idx + ord('0') elif char_idx &lt; 36: char_code = char_idx - 10 + ord('A') elif char_idx &lt; 62: char_code = char_idx - 36 + ord('a') elif char_idx == 62: char_code = ord('_') else: raise ValueError('error') text.append(chr(char_code)) return \"\".join(text) def crack_captcha_cnn(self, w_alpha=0.01, b_alpha=0.1): x = tf.reshape(self.X, shape=[-1, self.heigth, self.width, 1]) # 卷积的filter:一个Tensor。数据维度是四维[filter_height, filter_width, in_channels, out_channels] # 具体含义是[卷积核的高度, 卷积核的宽度, 图像通道数, 卷积核个数] w_c1 = tf.Variable(w_alpha*tf.random_normal([3, 3, 1, 32])) b_c1 = tf.Variable(b_alpha*tf.random_normal([32])) conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c1, strides=[1, 1, 1, 1], padding='SAME'), b_c1)) conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') w_c2 = tf.Variable(w_alpha*tf.random_normal([3, 3, 32, 64])) b_c2 = tf.Variable(b_alpha*tf.random_normal([64])) conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv1, w_c2, strides=[1, 1, 1, 1], padding='SAME'), b_c2)) conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') w_c3 = tf.Variable(w_alpha*tf.random_normal([3, 3, 64, 64])) b_c3 = tf.Variable(b_alpha*tf.random_normal([64])) conv3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv2, w_c3, strides=[1, 1, 1, 1], padding='SAME'), b_c3)) conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') w_d = tf.Variable(w_alpha*tf.random_normal([4*13*64, 1024])) b_d = tf.Variable(b_alpha*tf.random_normal([1024])) dense = tf.reshape(conv3, [-1, w_d.get_shape().as_list()[0]]) dense = tf.nn.relu(tf.add(tf.matmul(dense, w_d), b_d)) dense = tf.nn.dropout(dense, self.keep_prob) w_out = tf.Variable(w_alpha*tf.random_normal([1024, self.max_captcha*self.char_set_len])) b_out = tf.Variable(b_alpha*tf.random_normal([self.max_captcha*self.char_set_len])) out = tf.add(tf.matmul(dense, w_out), b_out) return out def train_crack_captcha_cnn(self): output = self.crack_captcha_cnn() # 创建损失函数 diff = tf.nn.sigmoid_cross_entropy_with_logits(logits=output, labels=self.Y) loss = tf.reduce_mean(diff) tf.summary.scalar('loss', loss) # 使用AdamOptimizer优化器训练模型，最小化交叉熵损失 optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss) # 计算准确率 y = tf.reshape(output, [-1, self.max_captcha, self.char_set_len]) y_ = tf.reshape(self.Y, [-1, self.max_captcha, self.char_set_len]) correct_pred = tf.equal(tf.argmax(y, 2), tf.argmax(y_, 2)) accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) tf.summary.scalar('accuracy', accuracy) merged = tf.summary.merge_all() with tf.Session() as sess: # 写到指定的磁盘路径中 train_writer = tf.summary.FileWriter(self.log_dir + '/train', sess.graph) test_writer = tf.summary.FileWriter(self.log_dir + '/test') sess.run(tf.global_variables_initializer()) # 遍历self.max_steps次 for i in range(self.max_steps): # 迭代500次，打乱一下数据集 if i % 20 == 0: self.test_imgs, self.test_labels, self.train_imgs, self.train_labels = self.get_imgs() # 每10次，使用测试集，测试一下准确率 if i % 10 == 0: batch_x_test, batch_y_test = self.get_next_batch(False, 100) summary, acc = sess.run([merged, accuracy], feed_dict={self.X: batch_x_test, self.Y: batch_y_test, self.keep_prob: 1}) print('迭代第%d次 accuracy:%f' % (i+1, acc)) test_writer.add_summary(summary, i) # 如果准确率大于85%，则保存模型并退出。 if acc &gt; 0.85: train_writer.close() test_writer.close() break # 一直训练 else: batch_x, batch_y = self.get_next_batch(True, 100) loss_value, _ = sess.run([loss, optimizer], feed_dict={self.X: batch_x, self.Y: batch_y, self.keep_prob: 1}) print('迭代第%d次 loss:%f' % (i+1, loss_value)) curve = sess.run(merged, feed_dict={self.X: batch_x_test, self.Y: batch_y_test, self.keep_prob: 1}) train_writer.add_summary(curve, i) train_writer.close() test_writer.close()if __name__ == '__main__': dz = Discuz() dz.train_crack_captcha_cnn()","link":"/2019/10/07/python验证码识别/"},{"title":"一个全局最优化的方法：随机游走算法(Random Walk)","text":"1.关于全局最优化求解全局最优化是一个非常复杂的问题，目前还没有一个通用的办法可以对任意复杂函数求解全局最优值。一个求解局部极小值的方法——梯度下降法。这种方法对于求解精度不高的情况是实用的，可以用局部极小值近似替代全局最小值点。但是当要求精确求解全局最小值时，梯度下降法就不适用了，需要采用其他的办法求解。常见的求解全局最优的办法有拉格朗日法、线性规划法、以及一些人工智能算法比如遗传算法、粒子群算法、模拟退火算法等。而今天要说的是一个操作简单但是不易陷入局部极小值的方法：随机游走算法。 2.随机游走算法操作步骤 3.随机游走的代码实现(使用Python) 12345678910111213141516171819202122232425262728293031323334353637383940414243'''@Description:使用随机游走算法求解函数极值这里求解:f = sin(r)/r + 1,r = sqrt((x-50)^2+(y-50)^2)+e,0&lt;=x,y&lt;=100 的最大值求解f的最大值，可以转化为求-f的最小值问题'''from __future__ import print_functionimport mathimport randomN = 100 # 迭代次数step = 0.5 # 初始步长epsilon = 0.00001variables = 2 # 变量数目x = [49,49] # 初始点坐标walk_num = 1 # 初始化随机游走次数print(\"迭代次数:\",N)print(\"初始步长:\",step)print(\"epsilon:\",epsilon)print(\"变量数目:\",variables)print(\"初始点坐标:\",x)# 定义目标函数def function(x): r = math.sqrt((x[0]-50)**2 + (x[1]-50)**2) + math.e f = math.sin(r)/r + 1 return -f# 开始随机游走while(step &gt; epsilon): k = 1 # 初始化计数器 while(k &lt; N): u = [random.uniform(-1,1) for i in range(variables)] # 随机向量 # u1 为标准化之后的随机向量 u1 = [u[i]/math.sqrt(sum([u[i]**2 for i in range(variables)])) for i in range(variables)] x1 = [x[i] + step*u1[i] for i in range(variables)] if(function(x1) &lt; function(x)): # 如果找到了更优点 k = 1 x = x1 else: k += 1 step = step/2 print(\"第%d次随机游走完成。\" % walk_num) walk_num += 1print(\"随机游走次数:\",walk_num-1)print(\"最终最优点:\",x)print(\"最终最优值:\",function(x)) 输出结果如下: 12345678910111213迭代次数: 100初始步长: 0.5epsilon: 1e-05变量数目: 2初始点坐标: [49, 49]第1次随机游走完成。第2次随机游走完成。第3次随机游走完成。......第16次随机游走完成。随机游走次数: 16最终最优点: [49.99999305065255, 50.00000102537616]最终最优值: -1.15111524497 基本的随机游走算法对于初始点比较敏感，可以看出，当初始点位于最优点附件时，可以很好地达到全局最优点；如果将初始点设置得离最优点较远，比如设置初始点为(10,10)时，其他参数不变，得到结果为： 123随机游走次数: 16最终最优点: [10.042835581532445, 11.648866165553416]最终最优值: -1.01720848747 可以发现，随机游走陷入了局部最优点。当然，如果增大迭代次数N以及初始步长λ，可以在一定程度上增加寻优能力，比如设置N=3000,λ=10.0，得到结果如下： 12345678910111213迭代次数: 3000初始步长: 10.0epsilon: 1e-05变量数目: 2初始点坐标: [10, 10]第1次随机游走完成。第2次随机游走完成。第3次随机游走完成。......第20次随机游走完成。随机游走次数: 20最终最优点: [49.99999900055026, 50.0000023931389]最终最优值: -1.15111697755 可以看出，当增大迭代次数以及初始步长之后，函数最终达到了全局最优点。但是迭代次数增加的代价则是运行时间的增加。总得来说，基本的随机游走算法可以很好地达到全局最优点，但是有时会依赖于初始点的选择。 4.改进的随机游走算法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253'''@Description:改进的随机游走算法这里求解:f = sin(r)/r + 1,r = sqrt((x-50)^2+(y-50)^2)+e,0&lt;=x,y&lt;=100 的最大值求解f的最大值，可以转化为求-f的最小值问题'''from __future__ import print_functionimport mathimport randomN = 100 # 迭代次数step = 10.0 # 初始步长epsilon = 0.00001variables = 2 # 变量数目x = [-100,-10] # 初始点坐标walk_num = 1 # 初始化随机游走次数n = 10 # 每次随机生成向量u的数目print(\"迭代次数:\",N)print(\"初始步长:\",step)print(\"每次产生随机向量数目:\",n)print(\"epsilon:\",epsilon)print(\"变量数目:\",variables)print(\"初始点坐标:\",x)# 定义目标函数def function(x): r = math.sqrt((x[0]-50)**2 + (x[1]-50)**2) + math.e f = math.sin(r)/r + 1 return -f# 开始随机游走while(step &gt; epsilon): k = 1 # 初始化计数器 while(k &lt; N): # 产生n个向量u x1_list = [] # 存放x1的列表 for i in range(n): u = [random.uniform(-1,1) for i1 in range(variables)] # 随机向量 # u1 为标准化之后的随机向量 u1 = [u[i3]/math.sqrt(sum([u[i2]**2 for i2 in range(variables)])) for i3 in range(variables)] x1 = [x[i4] + step*u1[i4] for i4 in range(variables)] x1_list.append(x1) f1_list = [function(x1) for x1 in x1_list] f1_min = min(f1_list) f1_index = f1_list.index(f1_min) x11 = x1_list[f1_index] # 最小f1对应的x1 if(f1_min &lt; function(x)): # 如果找到了更优点 k = 1 x = x11 else: k += 1 step = step/2 print(\"第%d次随机游走完成。\" % walk_num) walk_num += 1print(\"随机游走次数:\",walk_num-1)print(\"最终最优点:\",x)print(\"最终最优值:\",function(x)) 输出结果如下： 1234567891011121314迭代次数: 100初始步长: 10.0每次产生随机向量数目: 10epsilon: 1e-05变量数目: 2初始点坐标: [-100, -10]第1次随机游走完成。第2次随机游走完成。第3次随机游走完成。.....第20次随机游走完成。随机游走次数: 20最终最优点: [49.999997561093195, 49.99999839875969]最终最优值: -1.15111685082 可以发现，即使迭代次数N=100不大，初始点(−100,−10)离最优点(50,50)非常远，改进的随机游走算法依然可以达到最优点。这说明了改进的随机游走算法具有更强大的寻优能力以及对于初始点更低的依赖性。 注：经过多次试验发现，无论是随机游走算法还是改进的随机游走算法，对于步长都是非常依赖的。步长λ越大，意味着初始可以寻找最优解的空间越大，但同时也意味着更多的迭代次数(要搜索空间变大，寻找次数变多，相应时间自然要增加)。如果步长取得过小，即使N很大，也很难达到最优解。无论对于随机游走算法还是改进的随机游走算法皆是如此。所以理论上步长λ越大越好。但是步长越大，迭代总次数越高，算法运行时间越长。所以实践中可以多试验几次，将λ取得适当地大即可。","link":"/2019/10/07/一个全局最优化的方法：随机游走算法-Random-Walk/"},{"title":"数据集网站","text":"一.如何使用这些资源?如何使用这些数据源是没有限制的，应用和使用只受到您的创造力和实际应用。使用它们最简单的方法是进行数据项目并在网站上发布它们。这不仅能提高你的数据和可视化技能，还能改善你的结构化思维。另一方面，如果你正在考虑/处理基于数据的产品，这些数据集可以通过提供额外的/新的输入数据来增加您的产品的功能。所以，继续在这些项目上工作吧，与更大的世界分享它们，以展示你的数据能力!我们已经在不同的部分中划分了这些数据源，以帮助你根据应用程序对数据源进行分类。我们从简单、通用和易于处理数据集开始，然后转向大型/行业相关数据集。然后，我们为特定的目的——文本挖掘、图像分类、推荐引擎等提供数据集的链接。这将为您提供一个完整的数据资源列表。如果你能想到这些数据集的任何应用，或者知道我们漏掉了什么流行的资源，请在下面的评论中与我们分享。（部分可能需要翻墙） 二.由简单和通用的数据集开始1.data.gov ( https://www.data.gov/ ) 这是美国政府公开数据的所在地，该站点包含了超过19万的数据点。这些数据集不同于气候、教育、能源、金融和更多领域的数据。 2.data.gov.in ( https://data.gov.in/ ) 这是印度政府公开数据的所在地，通过各种行业、气候、医疗保健等来寻找数据，你可以在这里找到一些灵感。根据你居住的国家的不同，你也可以从其他一些网站上浏览类似的网站。 3.World Bank( http://data.worldbank.org/ ) 世界银行的开放数据。该平台提供 Open Data Catalog，世界发展指数，教育指数等几个工具。 4.RBI ( https://rbi.org.in/Scripts/Statistics.aspx ) 印度储备银行提供的数据。这包括了货币市场操作、收支平衡、银行使用和一些产品的几个指标。 5.Five Thirty Eight Datasets ( https://github.com/fivethirtyeight/data ) Five Thirty Eight，亦称作 538，专注与民意调查分析，政治，经济与体育的博客。该数据集为 Five Thirty Eight Datasets 使用的数据集。每个数据集包括数据，解释数据的字典和Five Thirty Eight 文章的链接。如果你想学习如何创建数据故事，没有比这个更好。 三.大型数据集1.Amazon Web Services（AWS）datasets( https://aws.amazon.com/cn/datasets/ ) Amazon提供了一些大数据集，可以在他们的平台上使用，也可以在本地计算机上使用。您还可以通过EMR使用EC2和Hadoop来分析云中的数据。在亚马逊上流行的数据集包括完整的安然电子邮件数据集，Google Books n-gram，NASA NEX 数据集，百万歌曲数据集等。 2.Google datasets( https://cloud.google.com/bigquery/public-data/ ) Google 提供了一些数据集作为其 Big Query 工具的一部分。包括 GitHub 公共资料库的数据，Hacker News 的所有故事和评论。 3.Youtube labeled Video Dataset( https://research.google.com/youtube8m/ ) 几个月前，谷歌研究小组发布了YouTube上的“数据集”，它由800万个YouTube视频id和4800个视觉实体的相关标签组成。它来自数十亿帧的预先计算的，最先进的视觉特征。 四.预测建模与机器学习数据集1.UCI Machine Learning Repository( https://archive.ics.uci.edu/ml/datasets.html ) UCI机器学习库显然是最著名的数据存储库。如果您正在寻找与机器学习存储库相关的数据集，通常是首选的地方。这些数据集包括了各种各样的数据集，从像Iris和泰坦尼克这样的流行数据集到最近的贡献，比如空气质量和GPS轨迹。存储库包含超过350个与域名类似的数据集(分类/回归)。您可以使用这些过滤器来确定您需要的数据集。 2.Kaggle( https://www.kaggle.com/datasets ) Kaggle提出了一个平台，人们可以贡献数据集，其他社区成员可以投票并运行内核/脚本。他们总共有超过350个数据集——有超过200个特征数据集。虽然一些最初的数据集通常出现在其他地方，但我在平台上看到了一些有趣的数据集，而不是在其他地方出现。与新的数据集一起，界面的另一个好处是，您可以在相同的界面上看到来自社区成员的脚本和问题。 3.Analytics Vidhya(https://datahack.analyticsvidhya.com/contest/all/ ) 您可以从我们的实践问题和黑客马拉松问题中参与和下载数据集。问题数据集基于真实的行业问题，并且相对较小，因为它们意味着2 - 7天的黑客马拉松。 4.Quandl( https://www.quandl.com/ ) Quandl 通过起网站、API 或一些工具的直接集成提供了不同来源的财务、经济和替代数据。他们的数据集分为开放和付费。所有开放数据集为免费，但高级数据集需要付费。通过搜索仍然可以在平台上找到优质数据集。例如，来自印度的证券交易所数据是免费的。 5.Past KDD Cups( http://www.kdd.org/kdd-cup ) KDD Cup 是 ACM Special Interest Group 组织的年度数据挖掘和知识发现竞赛。 6.Driven Data( https://www.drivendata.org/ ) Driven Data 发现运用数据科学带来积极社会影响的现实问题。然后，他们为数据科学家组织在线模拟竞赛，从而开发出最好的模型来解决这些问题。 五.图像分类数据集1.The MNIST Database( http://yann.lecun.com/exdb/mnist/ ) 最流行的图像识别数据集，使用手写数字。它包括6万个示例和1万个示例的测试集。这通常是第一个进行图像识别的数据集。 2.Chars74K(http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/ ) 这里是下一阶段的进化，如果你已经通过了手写的数字。该数据集包括自然图像中的字符识别。数据集包含74,000个图像，因此数据集的名称。 3.Frontal Face Images(http://vasc.ri.cmu.edu//idb/html/face/frontal_images/index.html ) 如果你已经完成了前两个项目，并且能够识别数字和字符，这是图像识别中的下一个挑战级别——正面人脸图像。这些图像是由CMU &amp; MIT收集的，排列在四个文件夹中。 4.ImageNet( http://image-net.org/ ) 现在是时候构建一些通用的东西了。根据WordNet层次结构组织的图像数据库(目前仅为名词)。层次结构的每个节点都由数百个图像描述。目前，该集合平均每个节点有超过500个图像(而且还在增加)。 六.文本分类数据集1.Spam – Non Spam(http://www.esp.uem.es/jmgomez/smsspamcorpus/) 区分短信是否为垃圾邮件是一个有趣的问题。你需要构建一个分类器将短信进行分类。 2.Twitter Sentiment Analysis(http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/) 该数据集包含 1578627 个分类推文，每行被标记为1的积极情绪，0位负面情绪。数据依次基于 Kaggle 比赛和 Nick Sanders 的分析。 3.Movie Review Data(http://www.cs.cornell.edu/People/pabo/movie-review-data/) 这个网站提供了一系列的电影评论文件，这些文件标注了他们的总体情绪极性(正面或负面)或主观评价(例如，“两个半明星”)和对其主观性地位(主观或客观)或极性的标签。 七.推荐引擎数据集1.MovieLens( https://grouplens.org/ ) MovieLens 是一个帮助人们查找电影的网站。它有成千上万的注册用户。他们进行自动内容推荐，推荐界面，基于标签的推荐页面等在线实验。这些数据集可供下载，可用于创建自己的推荐系统。 2.Jester(http://www.ieor.berkeley.edu/~goldberg/jester-data/) 在线笑话推荐系统。 八.各种来源的数据集网站1.KDNuggets(http://www.kdnuggets.com/datasets/index.html) KDNuggets 的数据集页面一直是人们搜索数据集的参考。列表全面，但是某些来源不再提供数据集。因此，需要谨慎选择数据集和来源。 2.Awesome Public Datasets(https://github.com/caesar0301/awesome-public-datasets) 一个GitHub存储库，它包含一个由域分类的完整的数据集列表。数据集被整齐地分类在不同的领域，这是非常有用的。但是，对于存储库本身的数据集没有描述，这可能使它非常有用。 3.Reddit Datasets Subreddit(https://www.reddit.com/r/datasets/) 由于这是一个社区驱动的论坛，它可能会遇到一些麻烦(与之前的两个来源相比)。但是，您可以通过流行/投票来对数据集进行排序，以查看最流行的数据集。另外，它还有一些有趣的数据集和讨论。","link":"/2019/10/07/数据集网站/"},{"title":"一个tensorflow的可视化示例代码","text":"TensorFlow主要优势是灵活和可视化。TensorBoard是TensorFlow的一组可视化工具。熟悉的使用TensorBoard可以大大提高训练的效率。今天本文将介绍一下TensorBoard。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data#载入数据mnist=input_data.read_data_sets('mnist_data',one_hot=True)#noe_hot把像素点都转变成0或1的形式#每个批次的大小，训练模型时，一次放入一批次batch_size=100 #一批次100张图#计算一共有多少个批次n_batch=mnist.train.num_examples//batch_size# //是整除,得到批次数#参数概要def variable_summaries(var):#定义一个函数，作用是计算各种参数值 with tf.name_scope('summaries'): mean=tf.reduce_mean(var)#计算平均值 tf.summary.scalar('mean',mean)#记录平均值，将其命名为mean。summary.scalar用来显示标量信息 with tf.name_scope('stddev'): stddev=tf.sqrt(tf.reduce_mean(tf.square(var-mean))) tf.summary.scalar('stddev',stddev)# 标准差 tf.summary.scalar('max',tf.reduce_max(var))#最大值 tf.summary.scalar('min',tf.reduce_min(var))#最小值 tf.summary.histogram('histogram',var)#直方图#命名空间with tf.name_scope('input'): #命名随意，比如input,下面的x和y要缩进，表示x，y放在input空间#定义两个placeholder，配合上面命名空间，给x，y取个名字 x=tf.placeholder(tf.float32,[None,784],name='x-input')#建立一个占位符，None是图片数，784是每幅图的像素个数 y=tf.placeholder(tf.float32,[None,10],name='y-input')# 标签，建立一个占位符，10是指0-9十个数with tf.name_scope('layer'):#创建一个简单的神经网络，输入层784个神经元，输出层10个神经元，不设隐藏层 with tf.name_scope('wights'): W=tf.Variable(tf.zeros([784,10]),name='W')#权值，设一个变量，置0 variable_summaries(W)#把权值W当作参数，计算的各种指标 with tf.name_scope('biases'): b=tf.Variable(tf.zeros([10]),name='b')#偏置值 variable_summaries(b)#把偏置值b当作参数，计算的各种指标 with tf.name_scope('wx_plus_b'): wx_plus_b=tf.matmul(x,W)+b with tf.name_scope('softmax'): prediction=tf.nn.softmax(tf.matmul(x,W)+b)#信号总和，经过softmax函数（激活函数）转化成概率值#二次代价函数#loss =tf.reduce_mean(tf.square(y-prediction))#使用交叉熵代价函数with tf.name_scope('loss'): loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction)) tf.summary.scalar('loss',loss)#使用梯度下降法with tf.name_scope('train'): train_step=tf.train.GradientDescentOptimizer(0.2).minimize(loss)#初始化变量init=tf.global_variables_initializer()with tf.name_scope('accuracy'): with tf.name_scope('correct_prediction'):#训练好后求准确率，结果存放在一个布尔型列表中，argmax返回一维张量中最大的值所在的位置 correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax函数是对行或列计算最大值，1表示按行，0表示按列，找到最大概率标签的位置。 equal函数是比较两个参数大小，相等的话返回True，不相等返回False with tf.name_scope('accuracy'):#求准确率 accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))#cast()是类型转换函数，把布尔型参数转换为32位古典型,然后求平均值。true变成1.0，flse变成0#Boolean→数值型：True转换为-1，False转换为0。数值型→Boolean：0转换为False，其他转换为True tf.summary.scalar('accuracy',accuracy)#合并所有的summary,并将其加入到sess.run的语句里merged=tf.summary.merge_all()with tf.Session() as sess: sess.run(init)#初始化变量 writer=tf.summary.FileWriter('./graphs',sess.graph)#'logs/'是路径，graph存在logs文件夹中，如果没有logs文件夹，这里会自动生成 for epoch in range(51):#迭代21个周期，把所有图片训练21次 for batch in range(n_batch): batch_xs,batch_ys=mnist.train.next_batch(batch_size)#一次分配100张图片，图片数据保存在batch_xs，标签保存在batch_ys summary,_=sess.run([merged,train_step],feed_dict={x:batch_xs,y:batch_ys})#每tain训练一次，统计一次参数merged，运行后得到的merged存在summary里 writer.add_summary(summary,epoch)#将summary和运行周期epoch写入tensorboard文件 acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})#x输入测试图片，从而得到prediciton的y，从而和label y 对比 print('Iter'+str(epoch)+',Testing Accuracy'+str(acc))","link":"/2019/10/07/一个tensorflow的可视化示例代码/"},{"title":"告研究生新生/研究生导师书","text":"告研究生新生书作者：北京邮电大学杨义先教授 各位新同学，大家好！ 首先祝贺各位在刚刚结束的考研竞争中过关斩将，收获了人生的又一次成功！今天借此喜庆之日，顺便说几句心里话，也算是送给各位的见面礼吧。 （1）什么是研究生？研究生就是做研究的学生，因此，大家不要再把本科阶段的“视分如命”传统带进来。从今以后，请大家记住：“考试，60分万岁；研究，90分及格！”若有某研究生给导师报喜说：“老师我已经超额多上X门课程，并考试得满分”，那么，导师也许会把他当作可爱的小傻瓜，你不会来夺此头衔吧？当然，研究生培养方案中包括课程、学分、考试和论文等所有要求都必须首先满足！特别提醒各位，研究生的论文是“干”出来的，而不是埋头“写”出来的，更不是“抄”来的！抄袭论文很危险，害人害已，后果不堪设想 （2）导师将教给你什么？导师不再教你更多的知识，因为，在知识爆炸的时代，即使是天才，他所能掌握的知识也几乎可以忽略不计。从小到大，你被灌输的知识已经够多了，现在是该你学会“如何自己学习知识”的时候了！导师将重点培养你的三种能力：创新能力、动手能力、社会适应能力。当然，还有一点，导师也许将把自己多年失败的教训毫不隐瞒地展示给你，以使你不再重蹈覆辙。成功者的经验很难被复制，但是，他的失败却足以借鉴。 （3）如何给自己定位？定位不清，害死人！虽然每个人都有“顶天”和“立地”两种选择；但能“顶天”之人，毕竟是少数；绝大部分人将“立地”！若你没特别的理论研究天赋，不能成为“顶天”的科学家，那就建议你老老实实瞄准“立地”的工程师。科学家和工程师都同等重要，不必再分高低贵贱。社会并不急需“既能做一些不痛不痒的项目，又能发表几篇不三不四的论文”的所谓通才，强劲的社会竞争力是检验学生培养是否成功的唯一标准。 （4）什么兴趣值得付出代价？并非所有兴趣都该纵容，许多研究生误解了“兴趣是成功之母”，并常常拿“兴趣”来作为挑肥拣瘦的借口。如果有足够的胆量，那么，独门兴趣（如，扎克伯格的Facebook等）才值得死盯，因为，这样的兴趣要么送你上天堂，要么拉你下地狱。人生有此机会一搏，也不全是坏事！但是，大众化兴趣（比如，我更擅长单片机、我的本科专业更适合…、我学过XX课程等）就应该服从真实需求，必要时劝君忍痛割爱，否则成功将与你无缘，毕竟今后是你要去适应社会，而不是社会来适应你！其实，咬住大众化兴趣不放者要么是想偷懒，要么是没自信。当然，所有生活兴趣都是值得享受的，工作兴趣与生活兴趣不要混为一谈。 （5）态度到底有多重要？态度决定一切！只要态度出了问题，再加上研究生都有极高的智商，那么，稍稍发力，就能让任何导师“理屈词穷”，比如，可以轻易严格证明“研究生做项目是在给导师打工”、“导师在论文中的署名不合理”、“我的论文创新性已经足够毕业”等等。面对如此辩才，导师只能尽力而为，实在无奈，也只好弃权。多年的事实证明，能力弱和态度差常常相伴而生，也许正是因为态度差，才导致能力弱吧。“小事愿干，中事能干，大事敢干”是研究生的基本要求。 （6）“尽力而为”与“竭尽全力”的区别到底有多大？“尽力而为”者用99.99%（＝A）的力气去做事，“竭尽全力”者用100.01%（=B）的力气去做事。表面上看A@B，但是，当若干个A相乘时，将有A´ A´ A´…=0, 而若干个B 相乘时B´ B´ B´…=¥。各位新同学明白了吗？如果你一生都“尽力而为”的话，那么，你将收获零；如果你一生都“竭尽全力”的话，那么，你将收获巨大成功！ （7）做啥课题真的很重要吗？从学习知识的角度来说，做啥课题确实有区别；但是，从培养能力角度来看，其实啥课题的效果都一样。别忘了，如今已是“重能力，而轻知识”的年代！过度区分是所有矛盾的根源，过度关注细节差异者永远也得不到满足。另外，如果在某段时间内，被安排从事一个自己不了解或不擅长的课题，那你为何不把它当成一种挑战，以此来锻炼和培养自己的“适应”和“学习”的能力呢？ （8）高分学生为什么容易成低能？过去多年的事实反复证明：保研学生和考研高分的学生，更容易在研究生阶段成为低能学生。这个看似矛盾的现象，其实有其必然。 原因1，个别高分学生总是习惯以讲课和考试的思维去考虑问题，从小到大，他/她的成就感也主要来自于各类考试，因此，没有考试，不能得分的事情（比如，科研）他们都下意识地抵制或恐惧。 原因2，读研前，几乎都是别人来向他/她请教有关学习和考试的问题，这就无形中使他/她感觉过于良好，因此，一旦有不懂的科研事项，就很难放下架子去向别人（特别是那些考试成绩较差的人）请教，当然，久而久之就会落后甚至被无情地淘汰。 原因3，过于精通本科阶段的循序渐进方法，更难适应研究问题时的跳跃创新，以为科研也要把所有准备工作都做好后，才能开始。 原因4，过于企望本科考试优势能够顺利过渡到研究生的科研阶段，因此，思想包袱更重，更不敢面对新挑战。 同学们，今天的见面礼可不能白送哟！希望毕业时，大家能够以自身的杰出成就来回母校，更希望大家今后走向社会为国争光，期待着那一天的到来！ 谢谢！ 告研究生导师书作者：（一点建议罢了，不来自特定作者 第1条）教师出路千万条，安全执教第一条；自保不周全，亲人两行泪！啥意思？嘿嘿，你懂的！各位上有老，下有小，中间还有一个宝（配偶）；就算你不怕死、不要命，也该为他人考虑嘛！ 第2条）学生是亲人，弟子是亲人，爹妈儿女也是亲人，白头偕老的爱人更是亲人；别拿一类亲人去伤害另一类亲人，其实那不公平！若有人非要故意制造一些典型，那你笑看他们自己去煽情吧！ 第3条）学校的事重要，学生的事重要，家里的事情也重要；工作重要，生活重要，身体健康更重要；别因一种重要而忽略另一种重要，其实那样不地道！若有人非要给你戴高帽，嘿嘿，劝君一摆手：不要，不要！ 第4条）与时俱进，活到老，学到老。你曾经的辉煌毋庸置疑，但社会在飞速发展，技术在不断更新，新的挑战随时涌现，对人才的需求也在不断变化，你若不能紧跟形势，就会被边缘化，更会误人子弟。提醒一下，你有许多东西搞不懂，你需要向其它导师学习，甚至向研究生学习！ 第5条）研究生培养的手段，应服务于目标。社会满意度是人才培养的唯一且永恒目标，你有义务通过各种手段，大幅提高学生进入社会后的竞争力。只要有利于培养更多更优秀的学生，就该坚定不移地走自己的路，让他人说去吧。培养研究生的目的，不是为了赢得某些领导的肯定，而是为社会培养有用之才！ 第6条）全面理解创新内涵，重点培养创新能力。撰写论文、出版著作、研究高精尖课题等，都是培养研究生创新能力的有效手段；但实用产品开发、系统集成项目、软课题研究、成果转化等，也是培养创新能力的有效手段，它们不能被否认，甚至被歪曲。创新能力的培养既可在校内完成，更可通过校企合作完成。 第7条）放下架子培养学生的社会适应能力。导师称谓确实令人崇敬，但若优越感过强，将害人害已。每个人都该努力适应社会，而不是让社会来适应他。你能从自己做起，为学生树立榜样吗？项目谈判时，你能低头当好乙方吗？在欣赏自己的长处时，能尊重他人的短处吗？在重视纵向项目时，能不轻视横向项目吗？在取得理论成果时，能不藐视技术吗？能真心帮助暂时不如自己的同事吗？能真心佩服比自己强的其它老师吗？能时时事事转换角色吗？伙计，你的一举一动，可都是你学生的最好教材哟。 第8条）以身作则培养学生的团队精神。在激烈竞争的社会里，特别是在理工科行业里，没团队就几乎不可能有成功。“兵、将、帅”在任何团队中都不可缺少。团队精神既包括“挂帅”的智慧，也包括“做将”的勇气，更包括“当兵”的情怀。导师的如下行为，将严重影响研究生的团队精神培养：不挂“帅”吾宁死，那怕自身根本就不是帅才；若做“将”就只图清闲，不愿意面对任何攻坚；若当“兵”则懒散闲，放任自流，完全不顾团队的集体利益和自己应尽的义务。相信个别导师的这种行为，将不会得到研究生的认可，甚至可能被学生传为笑谈，当成反面教材。 第9条）“宽是害、严是爱”也适用于研究生培养，当然得因人而已，适当把握好度。师生是永远的利益共同体，即使毕业后，学生的成功，导师也是最大的受益者之一。处处迁就，肯定不是培养优秀研究生的好方法，虽然这样做可能会暂时获得某些学生的好感。所谓“一日为师，终生为父”就是要求导师像严父对待自己的儿子一样，敢于逼其成功！当然，对个别学生，你也要做好“一日为师，终生为孙”的准备；其实，那时你连孙子都不如，世上哪有爷爷坑害孙子的事！ 第10条）不是“成功才幸福”而是“幸福才成功”。成功很容易被片面有形化，比如，升职称、拿大奖、当选院士等。“有形成功”确实能带来短暂的幸福，但是，过于看重“有形成功”其实就是对自己幸福的不负责。上帝其实很公平，鱼和熊掌很难兼得，只要你踏踏实实，从现在做起，从小事做起，沿着自己心中的理想之路，你就能一边前进，一边幸福地享受沿途风光。 第11条）树立阳光心态应从导师做起。人人都在追求幸福，但有人却永远也找不到幸福；其实幸福就在每个人的心里。心态不良者看世间万物都不顺眼，消极悲观者不但自己活得累，也会严重污染生活环境，他们既毁灭了自己的幸福，更连累了身边的亲朋好友。“小事靠勤、中事靠能，大事靠德”，要想做一个好导师，必须以积极的心态在勤、能、德三个方面为学生垂范。 第12条）把钢加在刀刃上，重视培养研究生的综合素质。研究生毕业后，彼此之间的智商差别相对有限；但是，情商方面，可能就天壤之别了。而情商的高低，在毕业生后的职业生涯中，将起着越来越重要的作用；因此，花大力气提高研究生的情商，是事半功倍的最佳选择。","link":"/2019/10/06/告研究生新生-研究生导师书/"},{"title":"开源协议","text":"各种开源协议介绍 几种常见的开源协议 了解其他开源协议 世界上的开源许可证（Open Source License）大概有上百种，我们常用的开源软件协议大致有GPL、BSD、MIT、Mozilla、Apache和LGPL。我们不必要每个开源协议都了然于心，但是可以了解几个主要的协议的权利和义务。 如果看完还是一头雾水的话，乌克兰程序员Paul Bagwell，画了一张分析图，说明应该怎么选择，下图为国内大牛阮一峰汉化了版本。 来一个更加清晰和完全一点的图，目前只有英文版，后期我将会进行汉化。 希望这些总结可以帮助每一个人都能更好的为自己的开源项目选择一个合适的开源协议，当自己的开源项目被侵权的时候不至于处于被动的位置，也希望可以帮助到每一个人都能“合法”的应用开源项目，很多开源协议最低要求是使用者需要保留原作者对代码的声明，估计大家都会忽略掉了吧。 开源不等于免费，开源也不等于没有约束。","link":"/2019/10/05/开源协议/"},{"title":"马尔可夫链","text":"通俗理解马尔可夫链 （Markov Chain）是什么鬼 它是随机过程中的一种过程，一个统计模型，到底是哪一种过程呢？好像一两句话也说不清楚，还是先看个例子吧。 先说说我们村智商为0的王二狗，人傻不拉几的，见人就傻笑，每天中午12点的标配，仨状态：吃，玩，睡。这就是传说中的状态分布。 你想知道他n天后中午12点的状态么？是在吃，还是在玩，还是在睡？这些状态发生的概率分别都是多少？ （知道你不想，就假装想知道吧学习真的好累） 先看个假设，他每个状态的转移都是有概率的，比如今天玩，明天睡的概率是几，今天玩，明天也玩的概率是几几，还是先看个图吧，更直观一些。 这个矩阵就是转移概率矩阵P，并且它是保持不变的，就是说第一天到第二天的转移概率矩阵跟第二天到第三天的转移概率矩阵是一样的。（这个叫时齐，不细说了，有兴趣的同学自行百度）。 有了这个矩阵，再加上已知的第一天的状态分布，就可以计算出第N天的状态分布了。 这个矩阵就是转移概率矩阵P，并且它是保持不变的，就是说第一天到第二天的转移概率矩阵跟第二天到第三天的转移概率矩阵是一样的。（这个叫时齐，不细说了，有兴趣的同学自行百度）。 有了这个矩阵，再加上已知的第一天的状态分布，就可以计算出第N天的状态分布了。 正式理解概述马尔科夫链定义本身比较简单，它假设某一时刻状态转移的概率只依赖于它的前一个状态。举个形象的比喻，假如每天的天气是一个状态的话，那个今天是不是晴天只依赖于昨天的天气，而和前天的天气没有任何关系。当然这么说可能有些武断，但是这样做可以大大简化模型的复杂度，因此马尔科夫链在很多时间序列模型中得到广泛的应用，比如循环神经网络RNN，隐式马尔科夫模型HMM等，当然MCMC也需要它。 如果用精确的数学定义来描述，则假设我们的序列状态是…Xt−2,Xt−1,Xt,Xt+1,…，那么我们的在时刻Xt+1的状态的条件概率仅仅依赖于时刻Xt，即： 既然某一时刻状态转移的概率只依赖于它的前一个状态，那么我们只要能求出系统中任意两个状态之间的转换概率，这个马尔科夫链的模型就定了。我们来看看下图这个马尔科夫链模型的具体的例子(来源于维基百科)。 这个马尔科夫链是表示股市模型的，共有三种状态：牛市（Bull market）, 熊市（Bear market）和横盘（Stagnant market）。每一个状态都以一定的概率转化到下一个状态。比如，牛市以0.025的概率转化到横盘的状态。这个状态概率转化图可以以矩阵的形式表示。如果我们定义矩阵阵P某一位置P(i,j)的值为P(j|i),即从状态i转化到状态j的概率，并定义牛市为状态0， 熊市为状态1, 横盘为状态2. 这样我们得到了马尔科夫链模型的状态转移矩阵为： 讲了这么多，那么马尔科夫链模型的状态转移矩阵和我们蒙特卡罗方法需要的概率分布样本集有什么关系呢？这需要从马尔科夫链模型的状态转移矩阵的性质讲起。 马尔科夫链模型状态转移矩阵的性质 得到了马尔科夫链模型的状态转移矩阵，我们来看看马尔科夫链模型的状态转移矩阵的性质。 仍然以上面的这个状态转移矩阵为例。假设我们当前股市的概率分布为：[0.3,0.4,0.3],即30%概率的牛市，40%概率的熊盘与30%的横盘。然后这个状态作为序列概率分布的初始状态t0，将其带入这个状态转移矩阵计算t1,t2,t3…的状态。代码如下： 1234567import numpy as npmatrix = np.matrix([[0.9,0.075,0.025],[0.15,0.8,0.05],[0.25,0.25,0.5]], dtype=float)vector1 = np.matrix([[0.3,0.4,0.3]], dtype=float)for i in range(100): vector1 = vector1*matrix print(\"Current round:\" , i+1) print(vector1) 部分输出结果如下： 1234567891011121314151617181920Current round: 1[[ 0.405 0.4175 0.1775]]Current round: 2[[ 0.4715 0.40875 0.11975]]Current round: 3[[ 0.5156 0.3923 0.0921]]Current round: 4[[ 0.54591 0.375535 0.078555]]。。。。。。Current round: 58[[ 0.62499999 0.31250001 0.0625 ]]Current round: 59[[ 0.62499999 0.3125 0.0625 ]]Current round: 60[[ 0.625 0.3125 0.0625]]。。。。。。Current round: 99[[ 0.625 0.3125 0.0625]]Current round: 100[[ 0.625 0.3125 0.0625]] 可以发现，从第60轮开始，我们的状态概率分布就不变了，一直保持在[0.625 0.3125 0.0625]，即62.5%的牛市，31.25%的熊市与6.25%的横盘。那么这个是巧合吗？ 我们现在换一个初始概率分布试一试，现在我们用[0.7,0.1,0.2]作为初始概率分布，然后这个状态作为序列概率分布的初始状态t0，将其带入这个状态转移矩阵计算t1,t2,t3…的状态。代码如下： 123456matrix = np.matrix([[0.9,0.075,0.025],[0.15,0.8,0.05],[0.25,0.25,0.5]], dtype=float)vector1 = np.matrix([[0.7,0.1,0.2]], dtype=float)for i in range(100): vector1 = vector1*matrix print(\"Current round:\" , i+1) print(vector1) 部分输出结果如下： 1234567891011121314151617181920Current round: 1[[ 0.695 0.1825 0.1225]]Current round: 2[[ 0.6835 0.22875 0.08775]]Current round: 3[[ 0.6714 0.2562 0.0724]]Current round: 4[[ 0.66079 0.273415 0.065795]]。。。。。。。Current round: 55[[ 0.62500001 0.31249999 0.0625 ]]Current round: 56[[ 0.62500001 0.31249999 0.0625 ]]Current round: 57[[ 0.625 0.3125 0.0625]]。。。。。。。Current round: 99[[ 0.625 0.3125 0.0625]]Current round: 100[[ 0.625 0.3125 0.0625]] 可以看出，尽管这次我们采用了不同初始概率分布，最终状态的概率分布趋于同一个稳定的概率分布[0.625 0.3125 0.0625]， 也就是说我们的马尔科夫链模型的状态转移矩阵收敛到的稳定概率分布与我们的初始状态概率分布无关。这是一个非常好的性质，也就是说，如果我们得到了这个稳定概率分布对应的马尔科夫链模型的状态转移矩阵，则我们可以用任意的概率分布样本开始，带入马尔科夫链模型的状态转移矩阵，这样经过一些序列的转换，最终就可以得到符合对应稳定概率分布的样本。 这个性质不光对我们上面的状态转移矩阵有效，对于绝大多数的其他的马尔科夫链模型的状态转移矩阵也有效。同时不光是离散状态，连续状态时也成立。 同时，对于一个确定的状态转移矩阵P，它的n次幂Pn在当n大于一定的值的时候也可以发现是确定的，我们还是以上面的例子为例，计算代码如下： 12345matrix = np.matrix([[0.9,0.075,0.025],[0.15,0.8,0.05],[0.25,0.25,0.5]], dtype=float)for i in range(10): matrix = matrix*matrix print(\"Current round:\" , i+1) print(matrix) 输出结果如下： 123456789101112131415161718192021222324252627282930Current round: 1[[ 0.8275 0.13375 0.03875] [ 0.2675 0.66375 0.06875] [ 0.3875 0.34375 0.26875]]Current round: 2[[ 0.73555 0.212775 0.051675] [ 0.42555 0.499975 0.074475] [ 0.51675 0.372375 0.110875]]。。。。。。Current round: 5[[ 0.62502532 0.31247685 0.06249783] [ 0.6249537 0.31254233 0.06250397] [ 0.62497828 0.31251986 0.06250186]]Current round: 6[[ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625]]Current round: 7[[ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625]]。。。。。。Current round: 9[[ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625]]Current round: 10[[ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625] [ 0.625 0.3125 0.0625]] 我们可以发现，在n≥6以后，P的n次方的值稳定不再变化，而且每一行都为[0.625 0.3125 0.0625]，这和我们前面的稳定分布是一致的。这个性质同样不光是离散状态，连续状态时也成立。 好了，现在我们可以用数学语言总结下马尔科夫链的收敛性质了： 如果一个非周期的马尔科夫链有状态转移矩阵P, 并且它的任何两个状态是连通的，那么limn→∞Pnij与i无关，我们有： 上面的性质中需要解释的有： 1）非周期的马尔科夫链：这个主要是指马尔科夫链的状态转化不是循环的，如果是循环的则永远不会收敛。幸运的是我们遇到的马尔科夫链一般都是非周期性的。用数学方式表述则是：对于任意某一状态i，d为集合{n|n≥1,Pnii&gt;0} 的最大公约数，如果 d=1 ，则该状态为非周期的。 2）任何两个状态是连通的：这个指的是从任意一个状态可以通过有限步到达其他的任意一个状态，不会出现条件概率一直为0导致不可达的情况。 3）马尔科夫链的状态数可以是有限的，也可以是无限的。因此可以用于连续概率分布和离散概率分布。 4）π通常称为马尔科夫链的平稳分布。 参考链接： 马尔可夫链五分钟简单入门 马尔可夫链 小白都能看懂的马尔可夫链 动态在线演示： http://setosa.io/ev/markov-chains/","link":"/2019/10/05/马尔可夫链/"},{"title":"电子类书籍搜索网站","text":"「万千合集站」万千合集站融合了大学、考研等各种教科书的网盘下载链接，种类非常齐全。 当然，网站为了盈利，广告可能多些，但资源确实很全，而且提供百度网盘链接也是方便无比。 打开网站，比如搜索高等数学，搜到的版本很全，且可按热度、大小等排序，网站应该涉及到文理工科各个领域的教科书、课后答案等PDF的资料文档。 「脚本之家」脚本之家这个网站资源很全，分享代码、脚本和编程类书籍，编程类的pdf书籍资源确实很全，注意的就是下载的时候不要去点上面的高速下载，这应该都是常识了。 「鸠摩搜书」十分有名的一个网站，不管是专业还是娱乐类书籍都能搜到，搜到的多是百度网盘或者微盘链接。 「智奇搜书」智奇搜书和鸠摩搜书类似，也是一个电子书搜索引擎，资源搜索也是比较齐全好用。 「PDF之家」PDF之家分享的书籍也是很多，门类很多，也有教科书，比如计算机类的。 「itbook」itbook是一个免费下载编程类电子书的网站，涵盖了很多中英文的电子书籍，每天限制下载五本，书籍介绍页面有资源解压密码，不过看这些书名也算是淘书的一部分了。 「Library Genesis」国外知名电子书下载站，界面相对比较专业了，从网站栏目上看主要分书籍、文献、杂志等，当然大部分都是外文的，且全部免费。 「BookZZ」如下网站，也是整洁的一个界面，直接输入想要搜索的即可，号称200多万书籍和5000多万论文也不是吹的，提供免费下载。 「Online Books」依然国外站，称免费提供300万本电子书。","link":"/2019/10/04/电子类书籍搜索网站/"},{"title":"工具使用推荐","text":"百度网盘高速下载方法我爱搜盘：https://www.52sopan.com 轻舟网：https://www.qzhou.com.cn 小白盘：https://www.xiaobaipan.com 番茄搜搜：https://www.fqsousou.com 探索云盘：http://tansuo233.com 几款高速下载器电脑端：1.pandownload，推荐指数：★★★★★ 下载链接：http://pandownload.com 2.速盘，推荐指数：★★★★☆ 下载链接：https://www.speedpan.com 3.motrix，推荐指数：★★★ 下载链接：https://motrix.app/ 4.爱奇艺万能播放器，推荐指数：★★★ 下载链接：http://t.cn/R4Pp9zi 手机端：只需要在平时的百度网盘链接中，加入wp两个字母，就可以下载 比如下载下面链接的文件 https://pan.baidu.com/s/1cHQbmXqAfbdn1kjURnsrCw 提取码:1r9z 大家只需要在baidu后面加上wp，变成baiduwp即可，如下 https://pan.baiduwp.com/s/1cHQbmXqAfbdn1kjURnsrCw 然后将链接复制到浏览器回车即可 影视软件合集资源猫（安卓） ★★★★★ 犀函（iOS） ★★★★","link":"/2019/10/04/工具使用推荐/"},{"title":"机器学习模型的“可解释性”","text":"无论您的解决方案的最终目标是什么，终端用户都需要可解释、可关联或可理解的解决方案。 为什么机器学习中的可解释性很重要？在传统统计中，我们通过调查大量的数据来构造和验证假设。我们建立模型来构建规则，我们可以将其纳入我们的模型中。例如，营销公司可以建立一个模型，将营销活动数据与财务数据相关联，以确定构成有效营销活动的是什么。这是一种自上而下的数据科学方法，可解释性是关键，因为它是所定义规则和过程的基石。由于相关性往往不等于因果关系，所以在进行决策和解释时，需要对模型进行很强的理解。 在自下而上的数据科学方法中，我们将部分业务流程委托给机器学习模型。此外，全新的商业创意可通过机器学习实现。自下而上的数据科学通常将手动和部分困难任务自动化。例如制造公司可以将传感器放在他们的机器上并进行预测维护。因此，维护工程师可以更高效地工作，而无需执行昂贵的定期检查。模型可解释性对于验证模型的行为是否符合您的期望是很有必要的，并且它可以与用户建立信任关系，并且可以简化从手动过程到自动化过程的过渡。 图显示在一个自上而下的过程中，您迭代地构造和验证一组假设。在自底向上的方法中，您试图自动化过程从自底向上解决问题。 作为一名数据科学家，您经常关心微调模型以获得最佳性能。数据科学通常被定义为：’给出具有X标签的数据，并以最小误差找到模型’。尽管训练高性能模型的能力对于数据科学家来说是一项关键技能，但能够从更大的角度来看是很重要的。数据和机器学习模型的可解释性是在数据科学的 “有用性”中至关重要的方面之一，它确保模型与您想要解决的问题保持一致。尽管在构建模型时尝试最前沿的技术可能会有很多挑战，但能够正确地解释您的发现是数据科学过程的重要组成部分。 为什么深入分析模型至关重要？作为数据科学家，关注模型可解释性有几个原因。虽然它们之间存在重叠，但能捕捉到可解释性的不同动机： 判别并减轻偏差（Identify and mitigate bias）： 偏差可能存在于任何数据集中，数据科学家需要确定并尝试修正偏差。数据集的规模可能有限，并且不能代表所有数据，或者数据捕获过程可能没有考虑到潜在的偏差。在彻底进行数据分析后，或者分析模型预测与模型输入之间的关系时，偏差往往会变得明显。请注意，解决偏差问题没有唯一的解决方案，但是可解释性的关键一步是意识到潜在的偏差。 其他偏差的例子如下： 例如word2vec向量包含性别偏差（http://wordbias.umiacs.umd.edu/），这是由于他们受过训练的语料库中存在的内在偏差。当你使用这些词向量进行训练模型时，招聘人员搜索“技术简介”将使女性履历保留在最下面。 例如当您在小型数据集上训练目标检测模型时，通常情况下图像的宽度太有限。为了避免只适用于数据中噪音和不重要元素的模型，需要在不同环境，不同光照条件和不同角度下的各种物体图像。 考虑问题的上下文（Accounting for the context of the problem）： 在大多数问题中，您正在使用的数据集仅仅是您正试图解决的问题的粗略表示，而机器学习模型无法捕捉到真实任务的完整复杂性。可解释模型可帮助您了解并解释模型中包含和未包含的因素，并根据模型预测采取行动时考虑问题的上下文情境。 改进泛化能力和性能（Improving generalisation and performance）： 高解释性模型通常有更好的泛化能力。可解释性不是要了解所有数据点的模型的每个细节。必须将可靠的数据，模型和问题理解结合起来才能获得性能更好的解决方案。 道德和法律原因（Ethical and legal reasons）： 在财务和医疗保健这样的行业，审计决策过程并确保它是没有歧视或违反任何法律。随着数据和隐私保护法规（如GDPR）的发展，可解释性变得更加重要。此外，在医疗应用或自动驾驶汽车中，单一不正确的预测会产生重大影响，能够“验证”模型至关重要。因此，系统应该能够解释它是如何达到给定的要求的。 解释你的模型关于模型可解释性的通常引用是，随着模型复杂性的增加，模型可解释性按照同样的速度降低。特征重要性是解释模型的一种基本方法。即使对于深度学习等黑盒模型，也存在提高可解释性的技术。最后，将讨论LIME框架，该框架可作为模型分析的工具箱。 特征重要性（Feature importance） 广义线性模型 广义线性模型（GLM’s）都基于以下原则：如果将特征与模型权重进行线性组合，并通过一个函数 f得到结果，则可以用它来预测各种各样的响应变量。 GLM最常见的应用是回归（线性回归），分类（logistic回归）或建模泊松过程（泊松回归）。训练后得到的权重能直接表示特征重要性，它们提供了内部模型非常具体的解释。 例如在构建文本分类器时，可以绘制最重要的特征，并验证模型是否过拟合。如果最重要的单词不符合您的直觉（例如名称或停用词），则意味着该模型拟合了数据集中的噪音，将在新数据中表现不佳。 从TidyTextMining的文本解释能力的一个可视化的示例。 https://www.tidytextmining.com/02-sentiment-analysis_files/figure-html/pipetoplot-1.png 随机森林和SVM（Random forest and SVM’s） 即使是非线性模型（如基于树的模型（例如随机森林））也能够获取关于特征重要性的信息。基于核的方法（如SVM）中的权重通常不是特征重要性的很好的代表。核方法的优点在于，通过将特征投影到内核空间中，您可以捕获变量之间的非线性关系。另一方面，仅将权重视为一个特征，与交互无关。 图显示一个使用特征重要性可视化出的例子，图中您可以确定模型在学习什么。由于这个模型中很多重要的特征都是指这一天day的信息，所以可能需要添加额外的基于时间的特征会使其效果更好。(Kaggle) https://www.kaggle.com/general/13285 深度学习（Deep learning） 深度学习模型由于参数的数量以及提取和组合特征的复杂方法而导致其不可解释性。作为一类模型，它能够在许多任务中获得最好的性能，许多研究集中在将模型预测与输入相关联。 可解释机器学习的研究论文的数量正在迅速增长(MIT)。 http://people.csail.mit.edu/beenkim/papers/BeenK_FinaleDV_ICML2017_tutorial.pdf 特别是在面向更复杂地文本和图像处理的系统时，很难解释模型实际学到的是什么。研究的主要焦点目前主要是将输出或预测与输入数据关联。虽然在线性模型下这相当容易，但对于深度学习网络来说，它仍然是一个未解决的问题。两种主要方法是基于梯度或基于注意力机制的。 在基于梯度的方法中，使用反向传播计算目标概念的梯度用于生成一个映射，以突出显示输入中用于预测目标概念的重要区域。这通常应用于计算机视觉领域。 Grad-CAM, 一个基于梯度的方法被使用于视觉描述生成。基于输出的文字，方法能够判别出输入图像的那个区域是重要的 基于注意力机制的方法通常与序列数据（例如文本数据）一起使用。除了网络的正常权重之外，注意力权重被训练成 ‘input gates’。这些注意力权重决定最终网络输出中每个不同元素的数量。除了可解释性之外，在基于文本的“问答系统”中也可以带来更好的结果，因为网络能够“关注”其注意力。 在基于注意力机制的自动问答中，可以可视化出文本中哪个单词对于这个问题的答案是最最重要的。 LIME LIME是一个更通用的框架，旨在使“任何”机器学习模型的预测更加可解释。 代码链接：https://github.com/marcotcr/lime 为了保持模型独立性，LIME通过修改本地模型的输入来工作。因此，它不是试图同时理解整个模型，而是修改特定的输入实例，并监控对预测的影响。在文本分类的情况下，这意味着一些词被取代，以确定哪些元素的输入影响了预测。","link":"/2019/10/04/机器学习模型的“可解释性”/"},{"title":"学术网站","text":"sci-hub网址：http://www.sci-hub.tw/ 备用站点：http://www.sci-hub.wang/ 全能文献资源下载工具，是一个由俄罗斯牛人开发的可以下载任意文献杂志的工具，只要输入你想要下载的文献题目、DOI等信息就可以获取到该文献的真实地址并在线浏览，当然更重要的是可以下载。 学术导航网站学术导航网站为大家提供很多入口，比如访问sci-hub，Google学术，免费下载知网，百度文库资料等入库，非常方便！ √ http://www.4243.net √ http://www.6453.net √ http://www.9312.net √ http://www.20009.net √ http://www.sci-hub.ac.cn 百度学术网址：http://xueshu.baidu.com/ 涵盖了各类学术期刊，会议论文，旨在为国内外学者提供最好的科研体验。 百度学术搜素可以检索到收费和免费的学术论文，并通过时间筛选，标题，关键字，摘要，作者，出版物，文献类型被引用的次数等细化指标提高检索的精准性。 通过百度学术，都能搜到知网，万方，维普等学术网站的论文，台湾文献的论文也可以收集，其中的一项论文求救功能，相当实用。 不过，百度学术只是一个学术信息搜索引擎，如果下载还得到知网等数据库。 BASE网址：http://www.base-search.net/ BASE是德国比勒费尔德（Bielefeld)大学图书馆开发的一个多学科的学术搜索引擎，提供对全球异构学术资源的集成检索服务。 它整合了德国比勒费尔德大学图书馆的图书馆目录和大约160个开放资源（超过200万个文档）的数据。 谷歌学术网址： https://zz.glgoo.top/scholar/ https://c.glgoo.top/scholar/ 目前，大陆对谷歌相关网站是屏蔽的，但可以采用一些代理或者镜像网站登陆谷歌学术，我们暂时提供2个比较稳定的谷歌学术。也有镜像网站合集： http://www.4243.net 选择一个进去就可以。 免费搜索学术文章的Google网络应用。2004年11月，Google第一次发布了Google学术搜索的试用版。该项索引包括了世界上绝大部分出版的学术期刊， 可广泛搜索学术文献的简便方法。 可以从一个位置搜索众多学科和资料来源：来自学术著作出版商、专业性社团、预印本、各大学及其他学术组织的经同行评论的文章、论文、图书、摘要和文章。 Library Genesis网址： 1.http://gen.lib.rus.ec/ 2.http://libgen.io/ 3.http://libgen.org/ 4.http://libgen.io/scimag/ Library Genesis号称是帮助全人类知识无版权传播的计划。网站上论文很多，下载方便，还有很多外文书籍和中文书籍，几乎每天都在更新。这也是一个神奇网站，基本上所有的外文书籍和论文都可以搜到并下载，最近的学术论文也可以下载。 Library Genesis和Sci-Hub可谓患难兄弟，之前都因为爱思唯尔惹上纠纷，而且从Library Genesis下载不了的还可以从网页直接链接到Sci-Hub下载。 Cnpiec LINK service网址:http://cnplinker.cnpeak.com/ 一个方便快捷的查阅国外各类期刊文献的综合网络平台，cnpLINKer即“中国链接服务”，目前主要提供约3600种外国期刊的目次和文摘的查询检索，电子全文链接及期刊国内馆藏分布查询功能。并时时与国外出版社保持数据内容的一致性和最新性。 PMC（PubMed Cenral)网址：http://www.ncbi.nlm.nih.gov/pmc/ PubMed Central (PMC) 是美国国立卫生研究院提供的一项服务，存档生物医学，生命科学科研文献，PMC获得NLM(National Library of Medicine)的授权，收录存档生物/医学文献，免费是PMC的核心原则，随着技术的进步，目前文献的数字存储格式可能会淘汰，但PMC永久保存了这些内容.NLM认为数字资料不是用来存储的，持续的应用才是物尽其用，因此免费是PMC的一个核心原则.但是免费并不代表没有版权，资料虽然存储在PMC，作者和出版商才是版权的拥有者，所有使用PMC的用户必须遵守版权声明。 中国知网网址：http://www.cnki.net/ 知网，是国家知识基础设施的概念，由世界银行于1998年提出。CNKI工程是以实现全社会知识资源传播共享与增值利用为目标的信息化建设项目。由清华大学、清华同方发起，始建于1999年6月。提供CNKI 源数据库、外文类、工业类、农业类、医药卫生类、经济类和教育类多种数据库。 其中综合性数据库为中国期刊全文数据库、中国博士学位论文数据库、中国优秀硕士学位论文全文数据库、中国重要报纸全文数据库和中国重要会议文论全文数据库。 每个数据库都提供初级检索、高级检索和专业检索三种检索功能。高级检索功能最常用。 DOAJ网址：https://doaj.org/ DOAJ（Directory of Open Access Journal），由瑞典的隆德大学图书馆Lund University Libraries设立于2003年5月，DOAJ的优势在于收录的期刊有着严格的质量控制，包括很多SCI收录的期刊。 DOAJ收录的OA期刊数量非常多，属于目前最好的OA期刊目录网站。目前DOAJ除了查询OA期刊外，还可以查询部分期刊的文章内容。 Book系列Book系列网站书籍种类丰富，基本专业书籍都可找到免费下载。包括Bookie、Bookzz、Bookfi等，（Bookzz、Bookfi在Library Genesis的导航栏有，但是现在貌似打不开了）。 均可免费下载文献和书籍，文献下载适合前几年的，书籍就不用说了，超级多！其中BookSC网站：（http://zh.booksc.org/）文献资料多。BookSC网站截止到今天，已有278多万书籍以及5242多万文献可以免费下载，大多数是pdf,djvu,eupb格式。 下载也很方便，直接搜论文或者文章题目即可，还可将选择地区并设置成中国。BookSC网站体验很好，搜索后直接点下载就可以了，超级方便！ arXiv网址：https://arxiv.org/ arXiv的亮点是网站上面的文章大多数都是会投稿到学术期刊的文章，投稿作者对文章多半都是保持严谨态度的，只有少部分是一直保持预印本的形式。目前arXiv文章类型主要分为七大类：物理、数学、非线性科学、计算机科学、定量生物学、定量金融学和统计。每个大类下面又分有若干子类，例如物理下面又具体分为：天体物理、凝聚态物理、广义相对论等。文章类型内容分类非常专业和全面。 万方数据库网址：http://www.wanfangdata.com.cn/index.html 万方数据库是由万方数据公司开发的，涵盖期刊、会议纪要、论文、学术成果、学术会议论文的大型网络数据库；也是和中国知网齐名的中国专业的学术数据库。整合数亿条全球优质学术资源，集成期刊、学位、会议、科技报告、专利、视频等十余种资源类型，覆盖各研究层次，感知用户学术背景，智慧搜索。致力于帮助用户精准发现、获取与沉淀学术精华。 中国科技论文在线网址：http://www.paper.edu.cn/ 科学论文专业网站，如果你是理工类的研究生，这个网站绝对是需要翻阅的。尤其是其中的科技期刊分类，有各个期刊和大学学报的联系方式，以及每期的论文下载，最重要的是全面。 专利全文下载网址：http://www.drugfuture.com/cnpat/cn_patent.asp 提供下载号，就能下载你需要的专利。 OA图书馆网址：http://www.oalib.com/ OA图书馆是Open Access图书馆的简称。OA图书馆致力于让中国人可以免费获得高质量的文献，最早提供了很多的Open Access数据库和资源，但是由于OA的数据库资源比较分散并且数据库存储格式不统一，利用起来的非常不方便。在此基础上，他们利用google的搜索技术建立了OA内容的搜索，可以很方便搜索近6000多种期刊资料和5000多个Open Access的数据库资源。现在有420万篇了，后续发展很快。 PublicLibrary of Science网址：https://www.plos.org/科学公共图书馆原是是一家由众多诺贝尔奖得主和慈善机构支持的非赢利性学术组织，旨在推广世界各地的科学和医学领域的最新研究成果。 PLoS出版了多种生命科学与医学领域的开放获取期刊，可以免费获取全文，比较具有影响力。Plos系列的期刊目前都已被SCI收录。虽然期刊数量不多，但是文章总体数量相当庞大。 Socolar网址：http://www.socolar.com/ Socolar是一个旨在为用户提供OA资源检索和全文链接服务的公共服务平台，为非赢利性项目。 用户在使用Socolar时，可以不用注册。收录了来自世界各地、各种语种的重要OA资源，并优先收录经过学术质量控制的期刊（比如同行评审期刊）。 本地Pubmed网址：http://www.yuntsg.com 可在百度中搜索“本地Pubmed”；或直接进入网址：http://www.yuntsg.com本系统是华中科技大学同济医学院与济南泉方科技有限公司合作开发，本系统是在美国PubMed的基础上，参考CiteScore期刊评价系统、泉方学术搜索、德国的GoPubMed等整合开发的检索平台。 需先行注册，注册很简单，只需按照要求填写，注册完成后能够试用3个月时间，如需继续使用得注册其他账号。然后点击上图中本地Pubmed检索系统进入查询页面。 Scientific Research Publishing网址：http://www.scirp.org/ ScientificResearch Publishing（科研出版社，简称SRP)是一家国际综合性开源学术期刊出版机构。 目前已有国际开源英文期刊近三百本，所有期刊都是开源的（OpenAccess，或称开放存取, 简称OA），可免费下载所有期刊全文，所有期刊均回溯至创刊。 多数期刊已被CAS，EBSCO，CAB Abstracts，ProQuest，IndexCopernicus，Library of Congress，Gale，CSP等数据库全文或摘要收录。 NIMS日本国立材料研究网址：http://www.nims.go.jp/eng/ 旗下有NIMS NOW International，NIMS所属的每月通讯，2003年7月成立。每月覆盖范围包括国立材料研究所的最新研究活动，管理政策，在国际合作方面取得的进展，世界著名学者的访问、优秀的研究人员和工作人员，以及其他信息，报告当前的科研进展以及材料科学的重要趋势。 NIMS在以下领域已经被公认为全球的领导者，包括：高温高压技术合成单晶金刚石和氮化硼；N型掺杂金刚石薄膜；光电应用，如深紫外激光和发光二极管；氮化硼纳米管的生长与表征；超导和有机材料；功能陶瓷，如超塑性陶瓷等；纳米颗粒催化作用；电子束诱导沉积——一种利用离子束和电子显微镜合成纳米结构和器件的技术； 此外，NIMS已经在一些全新的器件和技术领域开始开拓：原子开关——一种控制原子运动的纳米级半导体器件；基于单壁碳纳米管的全世界最小温度计；巨电致伸缩效应；暖喷涂——一种高效的在金属，聚合物和玻璃上进行涂覆的新技术。 不仅如此，NIMS还具有在线材料数据库：http://mits.nims.go.jp/index_en.html 。绝对是查询材料参数的好去处。 HighWire Press 数据库网址：http://highwire.stanford.edu/lists/allsites.dtl HighWire Press是全球最大的提供免费全文的学术文献出版商;于1995年由美国斯坦福大学图书馆创立。最初仅出版著名的周刊“Journal of Biological Chemistry”，现提供1300余种期刊，涵盖生物科学、人文、医学、物理科学、社会科学等大类。标为free的可免费访问全文。 Nature网址：http://www.nature.com/nature/index.html 在2014年12月时，《自然》（Nature）也宣布了开放所有研究论文，包括旗下48个杂志，可惜不能免费复制、打印或下载。 中国学术会议在线网址：http://www.meeting.edu.cn/meeting/indexS.jsp 适用于投稿学术会议，为用户提供学术会议信息预报，会议分类搜素，会议在线报名，会议论文征集，会议资料发布，会议视频点播，会议同步直播等服务。 科学网网址：http://www.sciencenet.cn/ 科学网是由中国科学院，中国工程院和国家自然科学基金委员会主管，科学时报社主办的综合性科学网站。 主要提供快捷权威的科学新闻报道，丰富实用的科学信息服务以及交流互动的网络平台，目标是建成最具影响力的华人科学社区，查询国际会议也很方便。 台大學術期刊資料庫网址：http://ejournal.press.ntu.edu.tw/ 「台大学术期刊数据库」收录台大各学术研究单位出版之中外学术期刊论文篇目与全文，审查过程严谨、内容丰富详实、撰写格式一致，具相当程度之学术水平，为查询台湾一流学府之学术研究发展、辅助教学研究之最佳数据库。 数据库内容采实时更新方式，收录自民国91年(公元2002年) 1月起出刊之台大各中外学术期刊、论文书目资料，以及自民国92年(公元2003年)1月起出刊之期刊电子全文档案，并且现正逐批回溯建档中。 EBOOKEE网址：https://ebookee.org/ 该站书籍种类丰富，基本专业书籍都可找到。这一系列网站唯一不好的地方就是网络硬盘存储，下载麻烦，有广告。部分网络硬盘在国内可能被墙，需要挂代理，不过淘宝上有代下国外网盘的服务。 SciELO科技在线电子图书馆网址：http://www.scielo.org/ 1998年，巴西开通了第一个“科技在线电子图书馆（SciELO）”，随后扩展到阿根廷、智利、西班牙、古巴、哥伦比亚、葡萄牙、委内瑞拉七国。目前已提供613种专业期刊、20万篇论文全文供读者免费阅览。 NSTL开放学术资源系统网网址：http://oar.nstl.gov.cn/开放获取期刊集成检索系统是集期刊浏览、期刊检索两种功能为一体的开放式的期刊集成揭示与检索系统。 系统提供刊名字顺浏览、学科分类浏览两种浏览方式，且浏览过程中可通过期刊的一般信息与详细信息切换提示，进一步了解某个期刊的全部信息，其中包括刊名、ISSN、主题、学科分类、期刊内容揭示层次等15种相关信息。同时用户可对刊名、ISSN、主题、出版者及全部字段进行期刊检索。 Exlibris 开放获取电子期刊查询系统网址：http://coreej.cceu.org.cn/index.html Exlibris开放获取电子期刊查询系统是由艾利贝斯公司为中国用户联合会用户提供的免费期刊查询服务。除一般检索外，用户可按学科进行快速分类浏览，也可以依据OA期刊、核心期刊、NSTL订购期刊进行查找。该系统还对投稿及全文获取进行了很有效的指引。 国家哲学社会科学文献中心网址：http://www.ncpssd.org 国家哲学社会科学文献中心是由中国社会科学院牵头，教育部和国家新闻出版广电总局配合建设，2016年12月30日正式上线运行。 主要开设有资讯、资源、专题、服务四个栏目，资源包括中文期刊、外文期刊、外文图书、古籍四类，收录哲学社会科学相关领域文献共计10,000,000余条，提供有线阅读、全文下载等服务；还收录有国内外哲学社会科学领域重要的政府机构、高等院校、学术机构以及数据库的链接便于广大读者查阅、使用。 初步形成国家哲学社会科学学术期刊数据库，外文学术期刊数据库，中国社会科学院科研成果数据库等特色资源数据库。 SCHOLARVOX International网址：http://www.scholarvox.com/ SCHOLARVOX International 网站包括管理学，社会学，工程学，信息学等学科的20000多本电子书，有英文有法文，可在线阅读。 EBSCO网址：https://www.ebscohost.com/ EBSCO以商务数据为主，经济，金融，管理，市场营销，物流学的论文可在该网站找到一些大型企业的SWOT分析，公司简介，公司营业状况数据等，该网站还收录了不少营销学杂志，文献等。 ECONLIT网址：https://www.aeaweb.org/econlit ECONLIT由美国经济学协会创办，收录了包括图书，报刊，杂志，学术论文等各种类型的文学经济学方面100多万篇文章。主要为英文资料。 XERFI网址：http://www.xerfi.com/ XERFI以学术研究为主，在这个网站可以找到各领域的研究报告。 Thèses网址：https://www.theses.fr/ 这是一个强大的论文库，无论是什么方向的论文都可以搜到一些有用的资料，还可以选择读不同学校的论文成果。 JSTOR网址：http://www.jstor.org/ 这是一个英文网站，上面有很多对于法国作品、文化或者英美文化的分析（有英文有法语），如果是研究英法双语的论文，也许可以找到相关资料。 UMI网址：http://wwwlib.umi.com/ 当需要查阅国外学位论文，可使用PQDD-B(UMI博硕士论文数据库)，它 可以获取部分全文，是很好的国外资源共享平台。 ResearchGATE 科学社交网站网址：http://www.researchgate.net ResearchGATE是全球最大的科学社交网络服务网站。于2008年5月上线，至今已经有300,000多来自196不同国家的科学家加入此共同体。 ResearchGATE针对著科学家以及研究人员提供对科研做有利的线上服务。全球的研究人员可免费注册该网站而和各种领域的同事分享研究结果或讨论专业问题。除了个人中心、科学博客等工能以外，ResearchGATE提供的应用程序随时随地毫无时空的可以分享文件，资料等。 在2009年ResearchGATE踏出了开放存取的第一步。藉由本站的开放存取自存档功能科研人员可以上载自己写作的论文以便分享研究结果。由此本网站将免费提供论文参考。搜索文件可以直接使用该站的搜寻引擎而不侵犯出版社的版权。 该站点提供的索引包括各种刊物总共有三千五百万多个登记。资料库又含有六万多篇直接可以使用的论文。特别设计的浏览特点成员抓取所有重要的对外资讯库内容，包括Pubmed, Citeseer, Arxiv, Nasa Library 等。 Engineering &amp; Science1937-1988网址：http://calteches.library.caltech.edu/ Engineering &amp; Science is a quarterly magazine, founded in 1937. Produced by the Caltech Office of Public Relations, its goal is to present to a scientifically literate audience a lively picture of the intellectual life and research activities at Caltech and to promote interest in science and scientific issues Find Articles @ BNET网址：http://findarticles.com/ Find Articles是BNET网站下属的信息检索平台，包括3000余种出版物（期刊、网站等），在列表中对免费出版物进行了标识，检索方便 ABC Chemistry 化学免费全文期刊网址：http://www.abc.chemistry.bsu.by/current/fulltext.htm ABC Chemistry是化学方面的免费全文网上期刊数据库，由白俄罗斯国立大学化学系的一位教授建立的，分为永久期刊和临时期刊两大类。 Genamics JournalSeek 期刊信息检索系统网址：http://journalseek.net/index.htm Genamics JournalSeek is the largest completely categorized database of freely available journal information available on the internet. The database presently contains 95831 titles. Journal information includes the description (aims and scope), journal abbreviation, journal homepage link, subject category and ISSN. Searching this information allows the rapid identification of potential journals to publish your research in, as well as allow you to find new journals of interest to your field. Hindawi 出版公司网址：http://www.hindawi.com/journals/ Hindawi成立于1997年，是一个高速成长的OA学术出版机构，出版200余种OA期刊，学科涵盖STM(科学、技术和医学)大部分领域。 Intel Technology Journal网址：http://www.intel.com/technology/itj/index.htm Intel Technology Journal的所有信息都由Intel(英特尔)公司提供，是提供给英特尔公司顾客的一项服务。包含有英特尔最新的研究进展信息，重点介绍英特尔公司在微处理器和计算技术方面拥有的尖端技术。此杂志每季度出版一次，由英特尔专家撰写，是一份研究与技术的参考杂志。 MIT Open Access Articles网址：http://dspace.mit.edu/handle/1721.1/49433 通过DSpace@MIT 提供麻省理工学院MIT发表的学术论文，包括原始稿，同行评议稿，最终出版的正式文档。","link":"/2019/10/04/学术网站/"},{"title":"Python实现抠图换背景","text":"曾几何时，「抠图」是一个难度系数想当高的活儿，但今天要介绍的这款神工具，只要 3 行代码 5 秒钟就可以完成高精度抠图，甚至都不用会代码，点两下鼠标就完成了。 感受下这款抠图工具抠地有多精细： 这款工具叫：Remove.bg 。基于 Python、Ruby 和深度学习技术开发，通过强大的 AI 人工智能算法实现自动识别出前景主体与背景图，分分钟秒秒钟完成抠图。这样下去PS 设计师都快要下岗了。 怎么使用这款抠图工具呢？有多种简单方式。 Python 实现安装相应的库： 1pip install removebg 在Removebg网站 上注册获取 API 后就可以使用了： 单张图： 123from removebg import RemoveBgrmbg = RemoveBg(\"WPZ2Q4fraseKfAN9PPxxxxxx\", \"error.log\") # 引号内是你获取的APIrmbg.remove_background_from_img_file(\"C:/Users/sony/Desktop/1.jpg\") #图片地址 批量图片： 1234567from removebg import RemoveBgimport osrmbg = RemoveBg(\"WPZ2Q4fraseKfAN9PPxxxxxx\", \"error.log\")path = '%s/picture'%os.getcwd() #图片放到程序的同级文件夹 picture 里面for pic in os.listdir(path): rmbg.remove_background_from_img_file(\"%s\\%s\"%(path,pic)) 网站实现Removebg网站 软件实现oneindex下载：http://pan.sqdxwz.com/?/软件/","link":"/2019/10/02/Python实现抠图换背景/"},{"title":"C++标准库和标准模板库","text":"一、C++标准库C++标准库的内容分为10类，C++标准库的内容总共在50个标准头文件中定义。 C1. 标准库中与语言支持功能相关的头文件 C2. 支持流输入/输出的头文件 C3. 与诊断功能相关的头文件 C4. 定义工具函数的头文件 C5. 支持字符串处理的头文件 C6. 定义容器类的模板的头文件 C7. 支持迭代器的头文件 C8. 有关算法的头文件 C9. 有关数值操作的头文件 C10. 有关本地化的头文件 C++标准库的所有头文件都没有扩展名。C++标准库以&lt;cname&gt;形式的标准头文件提供。在&lt;cname&gt;形式标准的头文件中，与宏相关的名称在全局作用域中定义，其他名称在std命名空间中声明。在C++中还可以使用name.h形式的标准C库头文件名。 二、算法、容器、迭代器STL（Standard Template Library，标准模板库)是惠普实验室开发的一系列软件的统称。现然主要出现在C++中，但在被引入C++之前该技术就已经存在了很长的一段时间。 STL的代码从广义上讲分为三类：algorithm（算法）、container（容器）和iterator（迭代器），几乎所有的代码都采用了模板类和模版函数的方式，这相比于传统的由函数和类组成的库来说提供了更好的代码重用机会。在C++标准中，STL被组织为下面的13个头文件：&lt;algorithm&gt;、&lt;deque&gt;、&lt;functional&gt;、&lt;iterator&gt;、&lt;vector&gt;、&lt;list&gt;、&lt;map&gt;、&lt;memory&gt;、&lt;numeric&gt;、&lt;queue&gt;、&lt;set&gt;、&lt;stack&gt;和&lt;utility&gt;。 1、算法函数库对数据类型的选择对其可重用性起着至关重要的作用。举例来说，一个求方根的函数，在使用浮点数作为其参数类型的情况下的可重用性肯定比使用整型作为它的参数类性要高。而C++通过模板的机制允许推迟对某些类型的选择，直到真正想使用模板或者说对模板进行特化的时候，STL就利用了这一点提供了相当多的有用算法。它是在一个有效的框架中完成这些算法的——可以将所有的类型划分为少数的几类，然后就可以在模版的参数中使用一种类型替换掉同一种类中的其他类型。 STL提供了大约100个实现算法的模版函数，比如算法for_each将为指定序列中的每一个元素调用指定的函数，stable_sort以你所指定的规则对序列进行稳定性排序等等。这样一来，只要熟悉了STL之后，许多代码可以被大大的化简，只需要通过调用一两个算法模板，就可以完成所需要的功能并大大地提升效率。 算法部分主要由头文件&lt;algorithm&gt;，&lt;numeric&gt;和&lt;functional&gt;组成。&lt;algorithm&gt;是所有STL头文件中最大的一个（尽管它很好理解），它是由一大堆模版函数组成的，可以认为每个函数在很大程度上都是独立的，其中常用到的功能范围涉及到比较、交换、查找、遍历操作、复制、修改、移除、反转、排序、合并等等。&lt;numeric&gt;体积很小，只包括几个在序列上面进行简单数学运算的模板函数，包括加法和乘法在序列上的一些操作。&lt;functional&gt;中则定义了一些模板类，用以声明函数对象。 2、容器在实际的开发过程中，数据结构本身的重要性不会逊于操作于数据结构的算法的重要性，当程序中存在着对时间要求很高的部分时，数据结构的选择就显得更加重要。 经典的数据结构数量有限，但是我们常常重复着一些为了实现向量、链表等结构而编写的代码，这些代码都十分相似，只是为了适应不同数据的变化而在细节上有所出入。STL容器就为我们提供了这样的方便，它允许我们重复利用已有的实现构造自己的特定类型下的数据结构，通过设置一些模版类，STL容器对最常用的数据结构提供了支持，这些模板的参数允许我们指定容器中元素的数据类型，可以将我们许多重复而乏味的工作简化。 容器部分主要由头文件&lt;vector&gt;,&lt;list&gt;,&lt;deque&gt;,&lt;set&gt;,&lt;map&gt;,&lt;stack&gt;和&lt;queue&gt;组成。对于常用的一些容器和容器适配器（可以看作由其它容器实现的容器），可以通过下表总结一下它们和相应头文件的对应关系。 3、迭代器迭代器从作用上来说是最基本的部分，可是理解起来比前两者都要费力一些。软件设计有一个基本原则，所有的问题都可以通过引进一个间接层来简化，这种简化在STL中就是用迭代器来完成的。概括来说，迭代器在STL中用来将算法和容器联系起来，起着一种黏和剂的作用。几乎STL提供的所有算法都是通过迭代器存取元素序列进行工作的，每一个容器都定义了其本身所专有的迭代器，用以存取容器中的元素。 迭代器部分主要由头文件&lt;utility&gt;,&lt;iterator&gt;和&lt;memory&gt;组成。&lt;utility&gt;是一个很小的头文件，它包括了贯穿使用在STL中的几个模板的声明，&lt;iterator&gt;中提供了迭代器使用的许多方法，而对于&lt;memory&gt;的描述则十分的困难，它以不同寻常的方式为容器中的元素分配存储空间，同时也为某些算法执行期间产生的临时对象提供机制,&lt;memory&gt;中的主要部分是模板类allocator，它负责产生所有容器中的默认分配器。 三、后记对于STL的使用，也普遍存在着两种观点。第一种认为STL的最大作用在于充当经典的数据结构和算法教材，因为它的源代码涉及了许多具体实现方面的问题。第二种则认为STL的初衷乃是为了简化设计，避免重复劳动，提高编程效率，因此应该是“应用至上”的，对于源代码则不必深究。对于初学者而言，通过分析源代码，提高对其应用的理解其意义也不同凡响。 ========================================================= C++标准库函数 c++程序通常可以调用标准c++库中的大量函数。这些函数完成一些基本的服务，如输入和输出等，同时也为一些经常使用的操作提供了高效的 实现代码。这些函数中含有大量的函数和类定义，以帮助程序员更好地使用标准c++库。 标准c++库包含以下内容： &lt;algorithm&gt;,&lt;bitset&gt;,&lt;complex&gt;,&lt;deque&gt;,&lt;exception&gt;,&lt;fstream&gt;,&lt;functionl&gt;,&lt;iomanip&gt;,&lt;ios&gt;,&lt;iosfwd&gt;,&lt;iostream&gt;,&lt;isteam&gt;,&lt;iterat or&gt;,&lt;limits&gt;,&lt;list&gt;,&lt;locale&gt;,&lt;map&gt;,&lt;memory&gt;,&lt;numeric&gt;,&lt;ostream&gt;,&lt;queue&gt;,&lt;set&gt;,&lt;sstream&gt;,&lt;stack&gt;,&lt;stdxcept&gt;,&lt;streambuf&gt;,&lt;strin ig&gt;,&lt;strstream&gt;,&lt;utility&gt;,&lt;valarray&gt;,&lt;vactor&gt;,&lt;cassert&gt;,&lt;cctype&gt;,&lt;cerron&gt;,&lt;cfloat&gt;,&lt;ciso646&gt;,&lt;climits&gt;,&lt;clocale&gt;,&lt;cmath&gt;,&lt;cse tjmp&gt;,&lt;csignal&gt;,&lt;cstdrag&gt;,&lt;cstddef&gt;,&lt;cstdio&gt;,&lt;cstdlibn&gt;,&lt;cstring&gt;,&lt;ctime&gt;,&lt;cwchar&gt;,&lt;iso646.h&gt;和&lt;cwchar.h&gt; 标准c++库的详细消息均在其对应的头文件进行了说明。主要标准c++库头文件如下所示。其中13项为标准模板库（STL),在其说明文字的前面标有（STL)的为标准模板库。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139&lt;algorithm&gt;---（STL）用于定义实现常用、实用算法的大量模板&lt;bitset&gt;----- 用于定义官位位集合的模板类&lt;cassert&gt;-----用于在程序执行时执行断言&lt;cctype&gt;-----用于对字符进行分类&lt;cerrno&gt;-----用于测试有库函数提交的错误代码&lt;cfloat&gt;------用于测试浮点类型属性&lt;cios646&gt;----用于在ISO646变体字符集中编程&lt;climits&gt;-----用于测试整数类型属性&lt;clocale&gt;-----用于使程序适应不同的文化风俗&lt;cmath&gt;———用于计算常用的数学函数&lt;complex&gt;-----用于定义支持复杂算法的模板类&lt;csetjmp&gt;-----用于执行非局部的goto语句&lt;csignal&gt;------用于控制各种异常情况&lt;cstdrag&gt;-----用于访问参数数量文化的函数&lt;cstdarg&gt;-----用于访问参数数量变化的函数&lt;cstddef&gt;----用于定义实用的类型和宏&lt;cstdio&gt;-----用于执行输入和输出&lt;cstdlib&gt;----用于执行同一操作的不同版本&lt;string&gt;-----用于处理几种不同的字符串类型&lt;ctime&gt;------用于在几种不同的时间和日期格式间进行转换&lt;cwchar&gt;----用于处理宽流（wide stream)和字符串&lt;cwctype&gt;---用于对宽字符（wide character是）分类&lt;deque&gt;---(STL)用于定义实现双向队列容器的模板类&lt;exception&gt;---用于定义控制异常处理的几个函数&lt;fstream&gt;-----用于定义处理外部文件的几个iostream模板类&lt;functional&gt;-----（STL)用于定义几个模板，该模板将帮助在&lt;algorithm&gt;和&lt;numeric&gt;中定义的 模板构造谓词&lt;iomapip&gt;---- 用于声明一个带有参数的iostreams控制器&lt;ios&gt;-----用于定义用作大量iostreams类的基类的模板类&lt;iosfwd&gt;-----用于定义iostreams模板类（在需要定义之前）&lt;iostream&gt;---用于声明处理标准流的iostreams对象&lt;istream&gt;---用于定义执行析取操作的模板类&lt;iterator&gt;----（STL)用于定义帮助定义和管理迭代器的模板&lt;limits&gt;---用于测试数字类属性&lt;list&gt;---（STL)用于定义实现list容器的模板类&lt;locale&gt;----用于定义在iostreams类中控制与特定位置相关的行为的类和模板&lt;map&gt;------(STL)用于定义实现关联容器的模板类&lt;memoery&gt;-----（STL)用于定义对不同容器分配和释放内存的模板&lt;numeric&gt;-----（STL)用于定义实现实用数字函数的模板&lt;ostream&gt;----用于定义管理字符串容器的iostreamas模板类&lt;queque&gt;----(STL)用于实现队列容器的模板类&lt;set&gt;-----（STL)用于定义实现只有唯一元素的关联容器的模板类&lt;sstream&gt;----用于定义管理字符串容器的iostreams模板类&lt;stack&gt;-----（STL)用于定义实现堆栈容器的模板类&lt;stdexcept&gt;----用于定义提交异常的类&lt;streambuf&gt;----用于定义为iostreams操作分配缓冲区的模板类&lt;string&gt;------用于定义是实现字符串容器的模板类&lt;strstream&gt;-----用于定义处理非内存（in-memory)字符系列的iostreams类&lt;utility&gt;-----（STL)用于定义通用工具的模板&lt;valarray&gt;----用于定义支持值（value-oriented）数组的类和模板类&lt;vector&gt;----（STL)用于定义实现向量容器的模板类标准c++库还包括18个标准C库中的头文件，但其中有些变化。我们暂时不讨论，这些头文件为：====================&lt;assert.h&gt;---用于在程序运行时执行断言&lt;ctype.h&gt;----用于对字符分类&lt;errno.h&gt;----用于测试用库函数提交的错误代码&lt;float.h&gt;----用于测试浮点类型属性&lt;ios646.h&gt;-----用于在IOS646变体字符集中编程&lt;limits.h&gt;-----用于测试整数类型属性&lt;locale.h&gt;-----用于适应不同的文化习俗&lt;math.h&gt;----用于计算常见的数学函数&lt;setjmp.h&gt;----用于执行非局部的goto语句&lt;signal.h&gt;----用于控制各种异常情况&lt;stdrag.h&gt;-----用于访问参数数量变化的函数&lt;stddef.h&gt;-----用于定义类型和宏&lt;stdio.h&gt;------用于执行输入和输出&lt;stdlib.h&gt;------用于执行各种操作&lt;string.h&gt;-----用于处理字符串&lt;time.h&gt;-------用于在不同的时间和日期格式之间转换&lt;wchar.h&gt;-----用于处理宽流(wide stream)和字符类&lt;wctype.h&gt;-----用于对宽字符（wide character）分类","link":"/2019/10/02/C-标准库和标准模板库/"},{"title":"我的祖国，我的家，七十周年快乐","text":"这盛世，如您所愿。 1949—2019，一路披荆斩棘的中华人民共和国，终于在盛世中迎来了她的70大寿。 犹记得，70年前，毛主席在天安门层楼上的庄严宣告：中华人民共和国成立了！ 也欣喜，70年来，中华人民共和国在披荆斩棘中蒸蒸日上，屹立于世界的东方。 9月29日：共和国勋章首次颁授9月29日，国庆活动第一弹——中华人民共和国国家勋章和国家荣誉称号颁授仪式在人民大会堂举办。这是现行宪法公布施行以来第一次集中颁授，颁授的国家勋章包括“共和国勋章”和“友谊勋章”两种。 9月30日：向人民英雄敬献花篮仪式9月30日是国家设立的烈士纪念日，在中华人民共和国成立七十周年的之际，习近平等党和国家领导人将同各界代表在天安门广场向人民英雄敬献花篮。 10月1日：阅兵和群众游行、首都国庆联欢活动、文艺晚会1.阅兵和群众游行 阅兵 庆祝中华人民共和国成立70周年阅兵，编59个方（梯）队和联合军乐团，总规模约1.5万人，各型飞机160余架、装备580台套，是近几次阅兵中规模最大的一次。领导指挥方队、院校科研方队和文职人员方队将在此次阅兵中首次亮相，这也将会成为朱日和沙场阅兵和海上专项阅兵后，最大规模的新型武器和无人装备的首次集中受阅，东风-41等新型装备也有望亮相。 受阅将军人数超过以往，是历史上高级指挥员受阅数量最多的一次。两名女将军将担任女兵方队的领队，这是历次阅兵中首次在徒步方队安排女将军受阅。阅兵现场演奏曲目达50多首，是历次国庆活动中最多的一次。 2.首都国庆联欢活动首都国庆联欢活动包括主题表演、中心联欢表演、群众联欢、烟花表演和表演台表演五部分。 主题表演由3290名联欢群众手持光影屏和表演道具进行组图、立体呈现。 中心联欢表演共有3650人参加联欢，主要展示各地特色群众文化，选用了近40首为群众喜爱的经典歌曲，其中精选《我和我的祖国》等16首歌曲由全场联欢群众合唱。 群众联欢设立10个群众联欢区块，各自进行区域性自主联欢。同时，还将与主题表演、中心联欢表演进行融合表演。 烟花表演将通过高空、中空，低空烟花燃放和特殊烟花装置表演分波次、多新意地燃放烟花。 表演台表演由16支交响乐团1028人组成千人交响乐团，北京市大中小学校学生1400人组成千人合唱团。 3.文艺晚会除了国家统一的活动，各地也纷纷举办庆祝活动。 感受十月一日，国庆，一个不同寻常的一天。今天心情激动的我也是早早的起床，一直等待着阅兵式，不管怎么说，虽然我不能到达现场，却透过屏幕感受到了大家的自豪。 上午十点钟，阅兵正式开始： 领导人和各代表出场，一出场便是满满的感动，曾经我们印象中满头黑发的胡锦涛总书记，温家宝总理如今已双鬓发白，您容颜苍老，在我们心中显得却是更加的高大。 今天，我们的习大大在全国人民，全世界的瞩目下庄严的宣告： http://t.cn/AimL9ZDx?m=4422528170377121&amp;u=2656274875 您在党旗，国旗，军旗下的注目，是您心中不忘初心，砥砺前行的勇气的展现。 今年的阅兵也是拥有了前所未有的展现： 1．首次组建领导指挥方队接受检阅2．仪仗方队首次同时高擎党旗国旗军旗经过天安门接受检阅，也是仪仗方队历次参阅规模最大的一次3．火箭军方队首次以战略军种名义亮相国庆阅兵4．战略支援部队方队首次亮相国庆阅兵5．联勤保障部队方队是军队调整改革后首次亮相6．女兵方队首次以挂枪形式，全新混合编组参加国庆阅兵，这也是武警部队女兵首次参加国庆阅兵。7．院校科研方队平均学历最高，首次亮相国庆阅兵8．文职人员方队首次亮相阅兵盛典…. 一个一个的首次点燃的是我们内心的自豪，此生无悔入华夏，来世还做中国人，是我们内心最真挚的呼唤。 今天除了阅兵场的气势磅礴，我也感受到了国人的热情，我身边同学，朋友…我的朋友圈，空间，甚至是我的APP软件推送的展示的都令我感到自豪感到兴奋，我的朋友圈，空间从来没有像今天一样的”整齐”，一样的”约定俗成”：”山河犹在，国泰民安，这盛世，如您所愿”，”国之繁荣，盛世鼎立”…或许这就是所谓的爱国情，自豪感。 H5客户端观看人数达到一亿二千万人，微博客户端观看达到九千万人，这些数字都深深的震撼着我。 直到今天，我们仍然对得起先辈们当初的抛头颅，洒热血，英雄的血不会白流，祖国的心永远炙热。我们爱您，祖国母亲！九万里风鹏正举，唤我辈少年心存民族兴、国家强、舍我其谁的宏愿和担当。美哉，我少年中国与天不老!壮哉，我中国少年与国无疆!泱泱中华继炎黄，恰似江河淮济命脉长，普天华夏儿女兴家邦，我巍巍中华，矞矞皇皇，屹立东方!","link":"/2019/10/01/我的祖国，我的家，七十周年快乐/"},{"title":"Keras学习资源","text":"Keras简介Keras是Python中以CNTK、Tensorflow或者Theano为计算后台的一个深度学习建模环境。 相对于其他深度学习的框架，如Tensorflow、Theano、Caffe等，Keras在实际应用中有一些显著的优点，其中最主要的优点就是Keras已经高度模块化了，支持现有的常见模型（CNN、RNN等），更重要的是建模过程相当方便快速，使用Keras可以快速地搭建深度网络，极大的加快了开发速度。此外，Keras具有用户友好性、模块化、易扩展、与Python协作友好的特点。 Keras学习手册 Keras官方手册，非常详细的官方文档，文档中详细的介绍了从Keras每个知识点的用法，一步步带你从入门到精通。https://keras.io/ Keras中文官方手册，该中文官方手册是对对Keras英文官方手册最好的还原，适合所有阶段的Keras学习者阅读。https://keras.io/zh/ Keras中文文档，另一个非官方的Keras中文文档，笔者花了近两年的时间在维护，文档也一直在更新，包含ConvLSTM2D、SimpleRNNCellKeras、GRUCell等最新的内容，非常用心的一份Keras文档。https://keras-cn.readthedocs.io/en/latest/ 安装Keras库进行深度学习，国外一篇比较火的博客，旨在演示如何安装Keras库进行深度学习。http://www.pyimagesearch.com/2016/07/18/installing-keras-for-deep-learning/ 黄海广博士力荐的Keras github项目，这个github的repository主要是博主在学习Keras的一些记录及练习，满满都是干货，建议大家看一下。https://github.com/erhwenkuo/deep-learning-with-keras-notebooks 磐创AI Keras系列教程总结，从CNN到RNN，以入门、基础为主的讲解，适合小白学习。http://www.keraschina.com Keras学习视频 Waterloo大学关于Keras的课程，该视频在YouTube上有很高的播放率，课程质量非常高https://www.youtube.com/watch?v=Tp3SaRbql4k CERN使用Keras进行深度学习系列教程，比较详细、权威的一个Keras系列教程视频。http://cds.cern.ch/record/2157570?ln=en 莫烦Keras视频教程，莫烦老师的视频在B站、YouTube上都有很高的播放量，强烈推荐给大家。https://www.bilibili.com/video/av16910214/ 再为大家推荐YouTube上另一个大佬Sentdex的Keras教学视频，还配套有相应的文本教程和笔记。https://www.youtube.com/watch?v=wQ8BIBpya2k https://pythonprogramming.net/introduction-deep-learning-python-tensorflow-keras/ Keras代码案例Keras&amp;NLP代码案例 用LSTM在IMDB影评数据集做文本分类https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py 路透社主题分类https://github.com/fchollet/keras/blob/master/examples/reuters_mlp.py LSTM做文本生成https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py 在IMDB数据集上使用FastTexthttps://github.com/fchollet/keras/blob/master/examples/imdb_fasttext.py 基于LSTM的BABI数据集网络https://github.com/kerasteam/keras/blob/master/examples/reuters_mlp.py 预训练词向量https://github.com/kerasteam/keras/blob/master/examples/pretrained_word_embeddings.py 字符级卷积神经网络做文本分类https://github.com/johnb30/py_crepe LSTM预测一个人的性别https://github.com/divamgupta/lstm-gender-predictor Keras&amp;CV代码案例 使用CNN进行MNISThttps://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py Inception V3https://github.com/fchollet/keras/blob/master/examples/inception_v3.py VGG16https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3 FractalNethttps://github.com/snf/keras-fractalnet 可视问答https://github.com/avisingh599/visual-qa VGG-CAMhttps://github.com/tdeboissiere/VGG16CAM-keras ResNet 50https://github.com/keras-team/keras/pull/3266/files 对象分割https://github.com/abbypa/NNProject_DeepMask fcn、segnet、u-net等常用的图像分割模型https://github.com/divamgupta/image-segmentation-keras Keras项目 RocAlphaGo，这个项目是DeepMind 2016年《自然》杂志的一个学生主导的实施项目，使用了Python+keras实现，代码清晰性更好。https://github.com/Rochester-NRT/RocAlphaG BetaGo，项目是使用keras的深度学习Go机器人。https://github.com/maxpumperla/betago DeepJazz，使用Keras深度学习驱动的爵士乐生成系统。https://github.com/jisungk/deepjazz dataset-sts，语义文本相似度数据集集线器。https://github.com/brmson/dataset-sts NMT-Keras，利用球面进行神经机器翻译。https://github.com/lvapeab/nmt-keras Headline generator，利用循环神经网络独立生成新闻标题的实现。https://github.com/udibr/headlines","link":"/2019/09/30/Keras学习资源/"},{"title":"人工智能中的数学知识","text":"机器学习和深度学习中所用的数学知识主要来自以下几门课： 高等数学/微积分 线性代数与矩阵论 概率论与信息论 最优化方法 图论/离散数学 总体来说需要如下知识点，这些知识点一般都是CS&amp;EE专业在大一和大二必修和选修的课程，大家可以查漏补缺。 1.1 微积分 函数极限 上确界与下确界 导数与偏导数 单调性与极值 函数的凹凸性 泰勒级数 牛顿-莱布尼兹公式 Lipschitz连续性 Hessian矩阵 1.2 线性代数与矩阵运算 线性空间与线性映射 行列式求解 常见的矩阵运算 特征值与特征向量 广义特征值 奇异值分解 1.3 概率论与数理统计 概率空间与事件 独立性与条件概率 贝叶斯公式 随机变量与概率公式 大数定理与中心极限定理 Jensen不等式 常见的概率分布 协方差 参数估计：矩估计/极大似然估计/区间估计 随机算法 信息论基础 1.4 最优化方法 凸优化介绍，凸函数与凸集合 拉格朗日乘数法与KKT条件 常见的凸优化问题 1.5 图论 图概念 常见的图 路径搜索问题 最大流问题 拉普拉斯矩阵","link":"/2019/09/30/人工智能中的数学知识/"},{"title":"AI学习资料","text":"国外课程斯坦福公开课程：概率和统计课程名称：《Probability and Statistics》 学习地址：https://online.stanford.edu/courses/gse-yprobstat-probability-and-statistics MIT 公开课线性代数课程名称：《Linear Algebra》 讲师：Gilbert Strang 学习地址：https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/ 斯坦福 2017 季 CS231n 深度视觉识别课程视频课程名称：《Convolutional Neural Networks for Visual Recognition》 讲师：Fei-Fei Li、Justin Johnson、Serena Yeung 国外学习地址：https://www.youtube.com/playlist?list=PLzUTmXVwsnXod6WNdg57Yc3zFx_f-RYsq 国内学习地址：https://www.bilibili.com/video/av13260183/ Fastai 推出的【2019 年面向程序员的深度学习实战课程】课程名称：《Practical Deep Learning for Coders, v3》 讲师：Jeremy Howard 国外学习地址：https://course.fast.ai 国内学习地址：https://www.bilibili.com/video/av41718196/ 2019 斯坦福CS224n深度学习自然语言处理课程课程名称：《CS224n: Natural Language Processing with Deep Learning》 讲师：Chris Manning 国外学习地址：https://www.youtube.com/playlist?list=PLU40WL8Ol94IJzQtileLTqGZuXtGlLMP_ 国内学习地址：https://www.bilibili.com/video/av46216519/ 斯坦福机器学习课程课程名称：《Machine Learning（Coursera）》 讲师：Andrew Ng 学习地址：https://www.coursera.org/learn/machine-learning 斯坦福概率图模型专项课程课程名称：《Probabilistic Graphical Models Specialization(Coursera)》 讲师：Daphne Koller 学习地址：https://www.coursera.org/specializations/probabilistic-graphical-models DeepMind 强化学习导论课程课程名称：《Introduction to Reinforcement Learning》 讲师：David Silver 国外学习地址：https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ 国内学习地址：https://www.bilibili.com/video/av24060851/ 全栈深度学习训练营(课程视频)：为熟悉深度学习基础知识的开发人员提供的实践指导课程课程名称：《Full Stack Deep Learning Bootcamp》 Github 地址：https://github.com/full-stack-deep-learning/fsdl-text-recognizer-project 国外学习地址：https://fullstackdeeplearning.com/march2019 国内学习地址：https://www.bilibili.com/video/av49643298 跟顶级Kagglers学习如何赢取数据科学竞赛课程名称：《How to Win a Data Science Competition: Learn from Top Kagglers（Coursera）》 讲师：Dmitry Ulyanov、Alexander Guschin、Mikhail Trofimov、Dmitry Altukhov、Marios Michailidis 学习地址：https://www.coursera.org/learn/competitive-data-science CS188 伯克利《人工智能导论》课程，含视频+资料课程名称：《BerkeleyX: CS188.1x Artificial Intelligence》 国外学习地址：https://inst.eecs.berkeley.edu/~cs188/fa18/ 国内学习地址：https://www.bilibili.com/video/av39489278/ Fast.ai 发布的课程：从零开始学深度学习课程名称：《Deep Learning from the Foundations》 讲师：Jeremy Howard 学习地址：https://www.fast.ai/2019/06/28/course-p2v3/ CS230 斯坦福深度学习课程（2018 年秋）课程名称：《CS230: Deep Learning | Autumn 2018》 讲师：Andrew Ng、Kian Katanforoosh 国外学习地址：https://www.youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb 国内学习地址：https://www.bilibili.com/video/av47055599/ deeplearning.ai 上线的 TensorFlow 实践课程，面向使用 TensorFlow 的开发者课程名称：《TensorFlow in Practice》 讲师：Andrew Ng 学习地址：https://www.deeplearning.ai/tensorflow-in-practice/ UC Berkeley《动手学深度学习》，李沐新书配套课程课程名称：《Dive into Deep Learning》 讲师：Alex Smola、Mu Li 学习地址：https://www.youtube.com/playlist?list=PLZSO_6-bSqHQHBCoGaObUljoXAyyqhpFW MIT的Python机器学习课程课程名称：《Machine Learning with Python-From Linear Models to Deep Learning》 学习地址：https://www.edx.org/course/machine-learning-with-python-from-linear-models-to-deep-learning 斯坦福 CS224U 自然语言理解课程课程名称：《CS224U：Natural Language Understanding》 学习地址：http://web.stanford.edu/class/cs224u/index.html 国内顶尖大学的计算机课程:中国科学技术大学课程资源课程名称：《USTC-Course》 Github 地址：https://github.com/USTC-Resource/USTC-Course 浙江大学Github 地址：https://github.com/QSCTech/zju-icicles 清华大学课程Github 地址：https://github.com/PKUanonym/REKCARC-TSC-UHT 北京大学课程Github 地址：https://github.com/lib-pku/libpku 台湾老师的课程陈蕴侬应用深度学习课程名称：《107 Spring - Applied Deep Learning, Taiwan University》 讲师：Yun-Nung (Vivian) Chen 学习地址：https://www.bilibili.com/video/av46656764/https://www.csie.ntu.edu.tw/~miulab/s107-adl/ 台大林轩田老师《机器学习基石》课程课程名称：《机器学习基石》 讲师：林轩田 学习地址：https://www.bilibili.com/video/av12463015/ 台大林轩田老师课程课程名称：《机器学习技法》 讲师：林轩田 学习地址：https://www.bilibili.com/video/av12469267/ NTU 大学，李宏毅最新机器学习课程（2019）课程名称：《Machine Learning》 讲师：李宏毅 学习地址：http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html","link":"/2019/09/29/AI学习资料/"},{"title":"人工智能，机器学习，数据挖掘","text":"说到人工智能(AI)的定义，映入脑海的关键词可能是“未来”，“科幻小说”，虽然这些因素看似离我们很遥远，但它却是我们日常生活的一部分。语音助手的普及、无人驾驶的成功，人工智能、机器学习、深度学习已经深入我们生活的各个场景。例如京东会根据你的浏览行为和用户的相似性，利用算法为你推荐你需要的产品；又比如美颜相机，会基于你面部特征的分析，通过算法精细你的美颜效果。还有众所周知的谷歌DeepMind，当AlphaGo打败了韩国职业围棋高手Lee Se-dol时，媒体描述这场人机对战的时候，提到了人工智能AI、机器学习、深度学习等术语。没错，这三项技术都为AlphaGo的胜利立下了汗马功劳，然而它们并不是一回事。 人工智能和机器学习的同时出现，机器学习和深度学习的交替使用……使大部分读者雾里看花，这些概念究竟有何区别，我们可以通过下面一个关系图来进行区分。 图一：人工智能、机器学习、深度学习的关系 人工智能包括了机器学习和深度学习，机器学习包括了深度学习。人工智能是机器学习的父类，机器学习则是深度学习的父类。 人工智能（Artificial Intelligence，AI）是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的与人类智能相似的方式作出反应的智能机器，它不是人的智能，但能像人那样思考、也可能超过人的智能。 人工智能实际应用：机器视觉，指纹识别，人脸识别，视网膜识别，虹膜识别，掌纹识别，专家系统，自动规划，智能搜索，定理证明，博弈，自动程序设计，智能控制，机器人学，语言和图像理解，遗传编程等。人工智能目前也分为：强人工智能(BOTTOM-UPAI)和弱人工智能(TOP-DOWNAI)。 机器学习（Machine Learning，ML）是人工智能的核心，属于人工智能的一个分支。机器学习是指从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法，所以机器学习的核心是数据、算法（模型）、算力（计算机运算能力）。 机器学习应用领域：数据挖掘、数据分类、计算机视觉、自然语言处理(NLP)、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用等。 深度学习（Deep Learning，DL）：是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据。 数据挖掘（Data Mining，DM），顾名思义是指利用机器学习技术从海量数据中“挖掘”隐藏信息，主要应用于图像、声音、文本。在商业环境中，企业希望让存放在数据库中的数据能“说话”，支持决策。所以数据挖掘更偏向于应用。 图二：数据挖掘与机器学习的关系 机器学习是数据挖掘的一种重要方法，但机器学习是另一门学科，并不从属于数据挖掘，二者相辅相成。数据挖掘是机器学习和数据库的交叉，主要利用机器学习提供的技术来分析海量数据，利用数据库界提供的技术来管理海量数据。 不管是人工智能、机器学习、深度学习还是数据挖掘，目前都在解决共同目标时发挥了自己的优势，并为社会生产和人类生活提供便利，帮助我们探索过去、展示现状、预测未来。","link":"/2019/09/29/人工智能，机器学习，数据挖掘/"},{"title":"内网穿透工具","text":"概述 如何让任何地方都能访问自己家里的笔记本上的应用？ 如何让局域网的服务器可以被任何地方访问到？ 有很多类似的需求，我们可以统一用一个解决方案：内网穿透。下面介绍几种常用的内网穿透方式，从此旧电脑不再变废柴。 几种方式Ngrok简介：一个通过任何NAT或防火墙为您的本地主机服务器提供即时访问、安全的URL的命令。类似花生壳，分为服务端和客户端，也可以自己搭建服务端。 工具主页：https://ngrok.com/ autossh简介：autossh是一个程序，用于启动ssh的副本并进行监控，在死亡或停止传输流量时根据需要重新启动它。这个想法来自rstunnel（Reliable SSH Tunnel），但是在C中实现。作者的观点是，它不像匆匆忙忙的工作那么容易。使用端口转发环路或远程回显服务进行连接监视。在遇到连接拒绝等快速故障时，关闭连接尝试的速度。在OpenBSD，Linux，Solaris，Mac OS X，Cygwin和AIX上编译和测试; 应该在其他BSD上工作。免费软件。 工具主页：http://www.harding.motd.ca/autossh/ Natapp简介：基于ngrok的国内收费内网穿透工具，类似花生壳，有免费版本，比花生壳好。免费版本：提供http,https,tcp全隧道穿透，随机域名/TCP端口，不定时强制更换域名/端口，自定义本地端口 工具主页：https://natapp.cn/ Frp简介：frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。利用处于内网或防火墙后的机器，对外网环境提供 http 或 https 服务。对于 http, https 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个80端口。利用处于内网或防火墙后的机器，对外网环境提供 tcp 和 udp 服务，例如在家里通过 ssh 访问处于公司内网环境内的主机。 工具主页：https://github.com/fatedier/frp Lanproxy简介：lanproxy是一个将局域网个人电脑、服务器代理到公网的内网穿透工具，目前仅支持tcp流量转发，可支持任何tcp上层协议（访问内网网站、本地支付接口调试、ssh访问、远程桌面…）。目前市面上提供类似服务的有花生壳、TeamView、GoToMyCloud等等，但要使用第三方的公网服务器就必须为第三方付费，并且这些服务都有各种各样的限制，此外，由于数据包会流经第三方，因此对数据安全也是一大隐患。 工具主页：https://github.com/ffay/lanproxy Spike简介：Spike是一个可以用来将你的内网服务暴露在公网的快速的反向代理，基于ReactPHP，采用IO多路复用模型。采用php实现。 工具主页：https://github.com/slince/spike 花生壳简介：商业化比较成功的内网穿透。个人开发很不推荐，收费贵，企业可以考虑使用。 工具主页：https://hsk.oray.com/","link":"/2019/09/29/内网穿透工具/"},{"title":"机器学习开源工具","text":"从事机器学习方面的工作，不会用工具将极大地阻碍工作效率。但现在工具那么多，我们该如何选择呢？本文针对非开发者、模型部署、NLP、语音、视觉、强化学习、数据挖掘等多个不同人群，提供了10个必须掌握的模型。 在厦门人工智能峰会上，依图科技联合创始人、CEO朱珑介绍到短短的5年时间机器的算法水平又提升了100万倍！过去或许只能从1万人中识别出1个人，后来发展到1000万、1亿、10亿甚至20亿人中识别出这个人！与此同时，算力方面提升了10万倍。从过去用1万量级规模的数据做训练，到百万规模的数据做训练，到现在用10亿的数据集做训练，又提升了1万倍！ 我们已经深刻地体会到，人工智能的飞速增长刺激了当今就业市场对机器学习技能的巨大需求。机器学习社区现在非常活跃，各种开源工具层出不穷，让人有点目不暇接，有点不知道该如何选择。那么本篇将为你介绍10个最应该了解的机器学习开源工具，走起！ 非开发者应该用什么？不会开发，不会编程，也能用机器学习？答案是可以的，只要你会用工具。这里为初学者推荐两个工具： KnimeKnime是一款出色的工具，可让你无需编写任何代码即可完成端到端的数据科学工作流程。 它甚至配备了一个拖放式界面，UI清晰，操作简单直观，可以说是懒人福音了。 操作起来非常简单，首先使用该工具进行数据收集和转换；完成后，你可以创建一个模型并将其可视化。在生产方面，你可以部署和管理数据科学项目。 最后，你可以通过使用Knime生成洞察来利用你的实现。 官网：https://www.knime.com/ Uber LudwigUber Ludwig是另一款适合初学者的优秀工具。有了它，你可以快速测试和训练深度学习模型。用户可以选择启用懒人模式（拖拽界面），或者直接操作代码。 使用起来比Knime稍微复杂一点点。需要先加载CSV文件来训练数据。通过使用预先训练的模型，你可以预测输出目标。最后，你可以使用可用的可视化选项可视化你的数据。 如果你是编程的初学者，你还可以在Python中使用他们扩展的API和训练模型。 GitHub地址：https://uber.github.io/ludwig/user_guide/ 模型部署用什么工具？模型部署是机器学习的关键方面之一。为了帮助你完成此过程，这里列出了几个工具。 TensorFlow.jsTensorFlow.js允许你直接从Web构建和部署机器学习模型。它使用JavaScript在Web上运行。 你也可以使用Node.js。有了它，你不仅可以运行现有模型，还可以重新训练现有模型。 它提供了直观的API，允许你使用JavaScript构建和训练模型，在Web浏览器上也是如此。 如果你想在移动设备上进行开发，还可以查看TensorFlow Lite。 官方地址：https://www.tensorflow.org/js/ MLFlowMLFlow让你可以解决端到端的机器学习生命周期问题。它有三个主要组件。 MLflow跟踪 - 通过记录和比较结果和参数来处理实验MLflow项目 - 允许你将项目打包成其他成员的可重用表单MLflow模型 - 帮助你在不同平台中部署和管理ML库 MLFlow的另一个惊人功能是它与库无关。这意味着你可以将其与其他机器学习库一起使用而不会出现任何兼容性问题。为了实现library-agonistic行为，它使用REST API和CLI。 官方地址：https://github.com/databricks/mlflow NLP、计算机视觉和音频用什么工具？还有其他方便的工具可用于在机器学习中执行不同的操作。 Detectron如果你正在寻找最先进的物体检测算法，那么你可以使用Detectron。 它由Facebook开发，是AI Research软件系统的一部分。它利用Caffe2深度学习框架和Python。 官方地址：https://github.com/facebookresearch/Detectron SimpleCVSimpleCV，一个开源框架，允许你构建计算机视觉应用程序。它类似于OpenCV，使你可以访问高级计算机视觉库。这意味着你不必担心错综复杂的概念。 有了它，你可以制作计算机视觉项目，而无需在基础知识上投入太多时间。毕竟，出于某种原因，它被命名为SimpleCV。 官方地址：http://simplecv.org/ Tesseract OCRTesseract OCR是一款功能强大的光学字符识别软件，可让你识别语言。 它支持100多种语言，也可以编程识别新语言。 官方地址：https://github.com/tesseract-ocr/tesseract 强化学习用什么工具？如果你想训练智能体，那么你需要帮助强化学习。 Open AI GymOpen AI Gym让你训练你的智能体做几乎任何事情，包括散步、玩游戏等等。它借助易于使用的强化学习任务套件来实现。 官方地址：https://gym.openai.com/ Unity ML AgentsUnity ML Agents是Unity提供的开源统一插件，让你开发可在游戏中使用的智能体。 官方网址：https://unity3d.com/machine-learninghttps://unity3d.com/machine-learning 数据挖掘用什么工具？如果你希望收集数据科学项目的数据，可以使用以下工具。 WekaWeka用于数据挖掘任务。它借助于为数据挖掘设计的机器学习算法来实现。有了它，你可以找到很多东西，包括分类、准备、回归、聚类、可视化和关联规则挖掘。 该项目是开源的，使用GNU许可。 官方网址：http://www.cs.waikato.ac.nz/ml/weka/ 结论机器学习正在改变我们与世界互动的方式。它使我们的生活更轻松，并确保我们建立一个未来世界。","link":"/2019/09/29/机器学习开源工具/"},{"title":"python常用包介绍","text":"Python的常用包有哪些，分别有什么作用？Python常用包1、Numpy（数值运算库） 2、Scipy（科学计算库） 3、Matplotlib（基础可视化库） 4、Pandas（数据处理库） 5、Seaborn（高级可视化库） 6、Scikit-learn（流行的机器学习库） 各自作用1、Numpy是最为流行的机器学习和数据科学包，Numpy包支持在多维数据上的数学运算，提供数据结构以及相应高效的处理函数，很多更高级的扩展库(包括Scipy、Matplotlib、Pandas等库）都依赖于Numpy库； 2、Scipy包用于科学计算，提供矩阵支持，以及矩阵相关的数值计算模块，其功能包含有最优化、线性代数、积分、插值、拟合、信号处理和图像处理以及其他科学工程中常用的计算； 3、Pandas用于管理数据集，强大、灵活的数据分析和探索工具，其带有丰富的数据处理函数，支持序列分析功能，支持灵活处理缺失数据等； ● Pandas基本的数据结构是Series和DataFrame； ● Series就是序列，类似一维数组； ● DataFrame相当于一张二维的表格，类似二维数组，它的每一列都是一个Series； ● 为了定位Series中的元素，Pandas提供了Index对象，每个Series都会带有一个对应的Index，用来标记不用的元素； ● DataFrame相当于多个带有同样Index的Series的组合（本质是Series的容器）； 4、Matplotlib库用于数据可视化，强大的数据可视化工具以及作图库，其主要用于二维绘图，也可以进行简单的三维绘图； 5、Seaborn库是基于Matplotlib的高级可视化库； 6、Sklearn库包含大量机器学习算法的实现，其提供了完善的机器学习工具箱，支持预处理、回归、分类、聚类、降维、预测和模型分析等强大的机器学习库，近乎一半的机器学习和数据科学项目使用该包。 sklearn的常用包有哪些，分别有什么作用？sklearn库的结构sklearn主要是用于机器学习，所以sklearn的模块也都是围绕机器学习算法的。sklearn因此可以分为这几个部分：Classification（分类），Regression（回归），Clustering（聚类），Dimensionality reduction（降维），Model selection（模型选择），Preprocessing（预处理）。 1.分类算法包括SVM（sklearn.svm.SVC等）、近邻（sklearn.neighbors）、随机森林（sklearn.ensemble.RandomForestClassifier）等。 2.回归算法包括SVR（sklearn.svm.SVR）、岭回归（sklearn.linear_model.Ridge）、Lasso（sklearn.linear_model.Lasso）等。 3.聚类算法包括K均值（sklearn.cluster.KMeans）、谱聚类（sklearn.cluster.SpectralClustering）等。 4.降维算法包括PCA（如sklearn.decomposition.PCA）、特征选择（sklearn.feature_selection，包括单变量特征选择等）、非负矩阵分解（如sklearn.decomposition.NMF、LatentDirichletAllocation）。 5.模型选择方法包括网格搜索（sklearn.model_selection.GridSearchCV）、交叉验证（有很多，比如sklearn.model_selection.KFold、cross_val_score）、评估指标（sklearn.model_selection.metrics，包括precision、recall、accuracy等）。 6.预处理方法包括基本的预处理方法（sklearn.preprocessing，包括标准化、类别化、离散化等）、特征抽取（sklearn.feature_extraction，包括文本特征抽取方法bag of words、tf-idf等）。 机器学习主要步骤中sklearn应用1.数据集：sklearn.datasets中提供了很多数据集，初学时可将其作为基础数据。 2.数据预处理：sklearn.preprocessing，包括：降维、数据归一化、特征提取和特征转换（one-hot）等 3.选择模型并训练：分类、回归、聚类、集成等算法，涉及的模型主要是sklearn.linear_model、sklearn.cluster、sklearn.ensemble。 4.模型评分：sklearn.metrics，包括准确率、召回率等，算法自身也带有评分方法score。 5.模型的保存与恢复：可以用python的pickle方法（pickle.dump、pickle.load），或者sklearn.externals.joblib（joblib.dump、joblib.load）。 什么是正则化、如何理解正则化以及正则化的作用？正则化-Regularization（也称为惩罚项或范数）就是通过对模型的参数在“数量”和“大小”方面做相应的调整，从而降低模型的复杂度，以达到避免过拟合的效果。 如何理解正则化如果我们的目标仅仅是最小化损失函数（即经验风险最小化），那么模型的复杂度势必会影响到模型的整体性能；引入正则化（即结构风险最小化）可以理解为衡量模型的复杂度，同时结合经验风险最小化，进一步训练优化算法。 正则化的作用正则化可以限制模型的复杂度，从而尽量避免过拟合的发生；模型之所以出现过拟合的主要原因是学习到了过多噪声，即模型过于复杂（也可以通过简化模型或增加数据集等方法尽量避免过拟合的发生）。 正则化的常见类型:（1）L1正则化 可以通过稀疏化（减少参数“数量”）来降低模型复杂度的，即可以将参数值减小到0。 （2）L2正则化 可以通过减少参数值“大小”来降低模型的复杂度，即只能将参数值不断减小，但永远不会减小为0，只能尽量接近于0。 关联概念过拟合、正则化、经验风险最小化、结构风险最小化、损失函数、模型复杂度、范数 bias和variance是什么？解释1bias 偏差 ：模型的期望（或平均）预测和正确值之间的差别； variance 方差 ：模型之间的多个拟合预测之间的偏离程度。 解释2bias和variance分别从两个方面来描述了我们学习到的模型与真实模型之间的差距； bias是 “用所有可能的训练数据集训练出的所有模型的输出的平均值” 与 “真实模型”的输出值之间的差异； variance则是“不同的训练数据集训练出的模型”的输出值之间的差异。 解释3首先 Error = bias + variance Error反映的是整个模型的准确度，bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性； 更准确地讲Error分成3个部分：Error = bias + variance + noise;","link":"/2019/09/29/python常用包介绍/"},{"title":"简历制作","text":"越长大越孤单 简历制作一演示: 简历制作二演示: 简历制作三演示: 简历制作四演示: 简历制作五演示:","link":"/2019/09/29/简历制作/"},{"title":"打造一份优雅的简历","text":"正所谓是金九银十，希望这个简历对所有人有所帮助。 另外，简历的制作其实并不是一蹴而就的事，当你知道了写简历的套路，平时就会有意识的积累素材，所以什么时候都可以学习如何打造一份优雅的简历。 简历是什么？在我看来，在面试之前，直接代表你这个人。虽然简历不会说话，但是简历的内容会让面试官直接在脑海里勾勒出你的形象。如果简历排版非常精致，你就会被塑造成一位细心、得体的形象；反之，如果简历里出现了错别字，那粗心这个标签就会打到你身上了。 所以，对待简历一定要重视！它是找工作过程中的第一道关卡，过了这一关，才有在面试中展示自我的机会。当然，平时的积累，个人的真实水平，临场发挥、人脉、运气也都很重要。这篇文章假设那些因素大家都一样，只比拼简历，就看谁简历写得好。 好的简历就是你的名片，不好的简历可能就是你的黑历史。接下来我们进入正题，说说简历该怎么写。 先贴一份完成了的简历。为了不暴露隐私，简历中的信息都是虚构的，但是写法都是按照模板来的，所以仍然不失一份精彩的样例，可以细看研究的。 顺便说一句，这张图片，可以自由传播。如果你仔细研究一下简历中的三个项目，你肯定会被我的才华折服的。 接下来就按简历模板里各个板块的顺序，详细解释每个部分该怎么写。 抬头直接写名字，电话号码，邮箱，其他信息不用填写。 找工作的时候最好在手机号码后面还留个座机号码，防止联系不上，这是细节。 关于电子邮箱，校招的同学可以留学校的邮箱；对于社招，gmail.com，163.com，foxmail.com 都不错，qq.com 也是可以的，只是需要把邮箱前缀改成一些有意义的，例如姓名的缩写之类的，这在邮箱设置里直接设置就好了，一定不要出现一些“中二”的邮箱名，例如“今夜无眠”之类的绝对不要出现。 有些同学问，需不需要挂个相片上去？其实，在抬头右侧空白部分，是可以挂上的。但是，我建议男生一率不要挂照片（当然如果你有吴彦祖的风彩当我没说），女生可以适当挂上证件照，前提是颜值是你的一大优势。 当然，一些国企事业单位会强制要求你贴上照片，那就贴好了。但也不要随便找一个白拍照就放上去了，找一家正规的照相馆，化好妆，照片精修后的效果肯定可以提高你在面试官那里的第一印象，这是好的开始。 教育背景这块直接从最高学历写起，写到本科即可。包括时间，学位，学校，专业，排名这些信息。有些可以体现你实力的东西是可以备注上的，例如优秀毕业生，免试推荐研究生，这些是可以在挂号里备注上的。 有些人说，这样是不是太高调了？借用 caoz 的一句话：你矜持，你活该。 最后，关于排名，如果你是专业第一名，就直接写上；否则，就计算一下你的排名大概占比百分之多少。如果班级排名高，就按班级的排名来，如果学校排名高，就写学校的排名。总之，按最高的来写。研究生一般没有排名这个说法，那你就估个数好了，填上 Top 5%，一般没有问题。 这里教大家一个小技巧，你看前面贴出来的简历是不是排列得很整齐？让你自己动手做，你不一定排得这么整齐。教你一招： 通过表格，能自动地让文字对齐。写完之后，只需要将表格的边框设置为不可见就行了！深藏功与名！隐藏表格边框后的效果是这样的： 有没有惊艳到？如果你早就知道了这个技巧，当我没说。 工作经历如实写就好了，校招同学这一项可以写下实习经历，如果没有实习，这一项整体就不要了。社招同学不要在这上面弄虚作假，因为社招入职都会做尽调，被查出不诚信就尴尬了。 同样，可以用到上面提到的用表格排版的小技巧。 项目经历找互联网工作的同学，一定刷过《剑指 offer》这本书，书里面的题在面试过程中出场率还是挺高的。但是，很多同学都只看了其中的题目部分，对于前两章可能就略读了，甚至直接跳过去了。其实，书的前两章是讲如何面试的，同样写得很精彩，值得细细研究。 咱们这篇文章不说面试，只说简历。但书里面有一个非常好的点 —— 描述项目的 STAR 模型： 项目经历这一项按照这个模型来写就 OK 了。 先简述项目背景，为什么要做它，要简短、清晰，也就是 Situation； 再来说你负责哪一块，做了哪些有价值的工作，这一块要学会提炼，不能是简单的工作罗列，尽量让人觉得这是有技术含量的，包含 Task&amp;Action； 最后，就是这件事完成的效果如何，是性能提升了 100 倍还是从零到一完成了某个复杂的系统，关键在于你要用数字来表达。例如，我经过一系列的优化过程，使得系统响应时间缩短为原来的 50%，或者说响应时间提升 1 倍，平均响应时间达到 1 ms 等等。 举个例子来说： 最开始一行，项目的简要信息。首先 项目的起止时间，这个要斟酌一下，太长显得效率太低，太短可能又显得不深入。不是要教大家不诚信，这块适当“优化”下没太大问题；然后是 地点，可以是学校，也可以是公司，照实写；接着是 项目名，简短、清晰；最后是你的 角色，一般可以写项目总负责人，核心参与者，项目主导者等等，不要太浮夸，也不要太低下。 接着，项目介绍。主要是讲清楚你做这个事的背景是什么。注意，不能说“这是实验室项目要求”或者“老师指定我做的”，要写这个项目的背景，业界是个什么进展，本项目它能解决什么问题，价值在哪，这是应该写的。有些项目确实垃圾，但编也得编一个高大上的介绍，毕竟它代表了你的水平不是嘛？ 接着，个人职责。先是概要的一句话，例如负责系统的整体架构，打上一个句号，这是总起，后面用更细致的话来解释。例如，充分调研市面上的相关系统，反复设计修改，设计出一套高可用、高性能、可扩展的系统架构。一般要列三点，多了太长，少了显得工作量少。所以，要挑选最重要的点来说，例如，设计并实现了某个算法，性能是之前的多少倍。 最后，项目成果。这块一定要挑最亮点的来说，而且一定要能用数字量化。常见的就是性能提升了多少倍，支持了多少并发，支持了多少用户，不可用时长为 0，发表文章专利多少篇…… 重要词语、数字用加粗来突出显示。这些加粗就是你最擅长的点，也是面试官可能会问你。所以你想让他问你什么，就加粗吧！ 个人技能这一项比较好搞定，把你的技能罗列出来，注意是和工作相关的。你找互联网的工作，写上一句“熟悉 office 的操作”就不太合适了吧。可以写：熟练掌握常见的数据结构和算法，熟悉 C/C++，熟悉 mysql/codis/etcd/zookper…… 英语听说读写能力也可以写上，例如“能熟练进行英文的听说读写”。 唯一需要注意的是，不要也不能写“精通”。“精通”是一个非常强的词，很少人能做到。这里并不是谦虚的问题，还涉及到一个预期管理的问题，也就是面对“精通”和“熟悉”，面试官对你的期待是不一样的。 如果你写上“熟悉 Golang”，那么当面试官问你一个比较深入的问题时（例如 Golang 的 map 是怎么进行扩容的），你答上来了，他会觉得你水平比较高，而且还很谦虚。相反，你写的是“精通 Golang”，面试过程中，只要有一个问题没答上，那是不是一下子印象就下去了？ 还写人写“精通 C/C++”，要知道，就是 C++ 的作者，他也不能完全掌握 C++ 的特性啊，即使 C++ 编译器，也不是所有的特性它都支持。换句话说，即使是编译器，也不能说它精通 C++。 个人评价这一栏，可以展示你在工作技能之外的特性。例如，我看到有师兄这样写： 高中班主任这样评价我：你是一个严于律己的人，一个精诚团结的人，一个志向远大的人。 面试官可能会问：班主任为什么要这么评价？这时，他就掉入你提前挖好的“坑”，因为一个可以展示你优秀品质的故事正在等着他，这是你提前准备的已经演练了无数遍了。而且，面试进程也在你的掌握之中了。 注意，不要太多，也不要太浮夸，着重展示你是一个可以合作，善于沟通，工作积极的人。 其他事项这块说一下其他未尽事项。 校招简历一般只要一页，就算你有再多内容要写，也只能压缩到一页，把那些最重要的，最能展示你能力的那部分内容保留下来，其他的干掉。 社招简历也不要超过两页，这样显得简练，展示的也都是高质量的项目，不能是简单的罗列，要总结升华。这样也可以打印到一页纸上，方便面试官，也就是方便你自己。 工作中，有一项非常重要的能力就是总结、提炼、升华。可能实验室的项目是一些企业的横向项目，就是 1+1=2 的事，非常简单，可能你觉得没啥可写的。这就是你发挥能力的时候了，从这些日常操作中，总结出一些高大上的东西来。如果不会，多参考一下优秀学长学姐的简历。 总之，你写到简历上的项目一定是经过总结升华的，这需要经过你无数次的修改。 还有一点要注意的是，发给别人的简历一定要是 pdf 格式，有些同学直接把 word 版 丟给别人，不同软件版本的电脑上可能会有兼容性问题啊，可能会有乱码，而且 word 版可能会被篡改。另外，打印简历的时候，也是要用 pdf 版本，不会出问题。 简历文件命名也是一个要注意的点。一般用 “码农桃花源-桃花源工作室-18888888888”，也就是“姓名-学校/公司-手机”这样的格式。这样，方便 HR 或者面试官联系你，因为只看文件名就能知道你的联系方式，和一些最重要的信息。再说一次，方便面试官就是方便你自己。 还有一个点，针对不同职位的简历应该是不一样的。这时，你可以把你的项目进行组合，不同职位的简历对应不同的项目组合，有的放矢。有些人会用 git 的不同分支维护不同的简历版本。 总结简历是你的代表，无声代表你这个人；它也是一个面试索引，能引导面试官的提问。所以如果你特别擅长某个方面，一定要在简历上突出。这相当于给面试官“挖坑”，如果他进坑了，那问的问题一定要你早就烂熟于心的，因为那是你准备无数遍的精彩故事、优化案例。 这样，面试官整个过程都是受你的引导，在你的框框里，不知不觉，在你讲述你擅长内容的过程中，面试进程被你掌握了。面试官接下来的问题，也会是围绕你的回答、故事展开。 简历模板: 你可以去Download 下载简历模板或者是去简历制作","link":"/2019/09/29/打造一份优雅的简历/"},{"title":"初识Numpy","text":"Numpy简介NumPy 是 Numerical Python 的简称，它是 Python 中的科学计算基本软件包。NumPy 为 Python 提供了大量数学库，使我们能够高效地进行数字计算。更多可点击Numpy官网 查看。 关于Numpy需要知道的几点： NumPy 数组在创建时有固定的大小，不同于Python列表（可以动态增长）。更改ndarray的大小将创建一个新的数组并删除原始数据。 NumPy 数组中的元素都需要具有相同的数据类型，因此在存储器中将具有相同的大小。数组的元素如果也是数组（可以是 Python 的原生 array，也可以是 ndarray）的情况下，则构成了多维数组。 NumPy 数组便于对大量数据进行高级数学和其他类型的操作。通常，这样的操作比使用Python的内置序列可能更有效和更少的代码执行。 所以，Numpy 的核心是ndarray对象，这个对象封装了同质数据类型的n维数组。起名 ndarray 的原因就是因为是 n-dimension-array 的简写。接下来本节所有的课程都是围绕着ndarray来讲的，理论知识较少，代码量较多，所以大家在学习的时候，多自己动动手，尝试自己去运行一下代码。 创建ndarray 由python list创建 1234567891011121314151617181920212223242526# 1维数组a = np.array([1, 2, 3]) print(type(a), a.shape, a[0], a[1], a[2])out:&lt;class 'numpy.ndarray'&gt; (3,) 1 2 3# 重新赋值a[0] = 5 print(a)out:[5 2 3]# 2维数组b = np.array([[1,2,3],[4,5,6]]) print(b)out:[[1 2 3] [4 5 6]]print(b[0, 0], b[0, 1], b[1, 0])out:1 2 4 由numpy内置函数创建 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104# 创建2x2的全0数组a = np.zeros((2,2)) print(a)out:[[ 0. 0.] [ 0. 0.]] # 创建1x2的全1数组b = np.ones((1,2)) print(b)out:[[ 1. 1.]]# 创建2x2定值为7的数组c = np.full((2,2), 7) print(c)out:[[7 7] [7 7]]# 创建2x2的单位矩阵（对角元素为1）d = np.eye(2) print(d)out:[[ 1. 0.] [ 0. 1.]]#创建一个对角线为10,20,30,50的对角矩阵d_1 = np.diag([10,20,30,50]) print(d_1)out:[[10 0 0 0] [ 0 20 0 0] [ 0 0 30 0] [ 0 0 0 50]]#创建一个一维的0-14的数组e = np.arange(15) print(e)out:[ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14]#创建一个一维的4-9的数组e_1 = np.arange(4,10) print(e_1)out:[4 5 6 7 8 9]#创建一个一维的1-13且以间隔为3的数组e_2 = np.arange(1,14,3) print(e_2)out:[ 1 4 7 10 13]#创建一个一维的范围在0-10，长度为6的数组f = np.linspace(0,10,6) print(f)out:#各个元素的间隔相等，为(10-0)/(6-1) = 2，若不想包含末尾的10，可以添加参数endpoint = False[ 0., 2., 4., 6., 8., 10.] #把arange创建的一维数组转换为3行4列的二维数组g = np.arange(12).reshape(3,4) print(g) out:#注意：使用reshape转换前后的数据量应该相同，12 = 3x4[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]] # 2x2的随机数组(矩阵),取值范围在[0.0,1.0)（包含0，不包含1）h = np.random.random((2,2)) print(e)out:[[ 0.72776966 0.94164821] [ 0.04652655 0.2316599 ]]#创建一个取值范围在[4,15)，2行2列的随机整数矩阵i = np.random.randint(4,15,size = (2,2)) print(i)out:[[6, 5], [5, 9]]#创建一个从均值为0，标准差为0.1的正态分布中随机抽样的3x3矩阵j = np.random.normal(0,0.1,size = (3,3)) print(j)out:[[-0.20783767, -0.12406401, -0.11775284], [ 0.02037018, 0.02898423, -0.02548213], [-0.0149878 , 0.05277648, 0.08332239]] 访问、删除、增加ndarray中的元素这里主要是提供了一些访问、更改或增加ndarray中某一元素的基础方法。 访问&amp;修改类似于访问python list中元素的方式，按照元素的index进行访问或更改。 123456789101112131415161718#访问某一元素，这里可以自己多尝试#访问一维数组的某一元素，中括号内填写indexprint(np.arange(6)[3]) out:3#访问二维数组的某一元素，中括号内填写[行,列]print(np.arange(6).reshape(3,2)[1,1]) out:3#访问三位数组中的某一元素，中括号内[组，行，列]print(np.arange(12).reshape(2,3,2)[0,1,1]) out:3#更改某一元素，用 = 进行赋值和替换即可a = np.arange(6)a[3] = 7 #先访问，再重新赋值print(a)[0 1 2 7 4 5] 删除可使用np.delete(ndarray, elements, axis)函数进行删除操作。 这里需要注意的是axis这个参数，在2维数据中，axis = 0表示选择行，axis = 1表示选择列，但不能机械的认为0就表示行，1就表示列，注意前提2维数据中。 在三维数据中，axis = 0表示组，1表示行，2表示列。这是为什么呢？提示一下，三位数组的shape中组、行和列是怎样排序的？ 所以，axis的赋值一定要考虑数组的shape。 123a = np.arange(12).reshape(2,2,3)#思考下，这里删除axis = 0下的第0个，会是什么结果呢？自己试一下print(np.delete(a,[0],axis = 0)) 再有一点需要注意的是，如果你想让原数据保留删除后的结果，需要重新赋值一下才可以。 1234567891011a = np.arange(6).reshape(2,3)np.delete(a,[0],axis = 0)print(a)array([[0, 1, 2], [3, 4, 5]]) #原数据并未更改a = np.delete(a,[0],axis = 0) #重新赋值print(a)array([[3, 4, 5]]) #原数据已更改 增加往ndarray中增加元素的办法跟python list也很类似，常用的有两种： 一种是添加（append），就是将新增的元素添加到ndarray的尾部 语法为：np.append(ndarray, elements, axis) 参数和delete函数一致，用法也一致，这里不再赘述 一种是插入（insert），可以让新增元素插入到指定位置 语法为：np.insert(ndarray, index, elements, axis) 参数中就多了一个index，指示的是插入新元素的位置。 这里值得注意的是，不论是append还是insert，在往多维数组中插入元素时，一定要注意对应axis上的shape要一致。再一个就是，和delete一样，如果你想要更改原数据，需要重新赋值。 切片和筛选ndarray切片前面学了选择ndarray中的某个元素的方法，这里我们学习获取ndarray子集的方法——切片。 对于切片大家并不陌生，在list里面我们也接触过切片，一维的ndarray切片与list无异。需要注意的是，就是理解2维及多维ndarray切片。 2维矩阵切片 12345678910111213141516a = np.arange(4*4).reshape(4,4)print(a)out:array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]])a[:,:-1]out:array([[ 0, 1, 2], [ 4, 5, 6], [ 8, 9, 10], [12, 13, 14]]) 这里可以看出，我们筛选了a矩阵中前三列的所有行，这是如何实现的呢？ 切片的第一个元素:表示的是选择所有行，第二个元素:-1表示的是从第0列至最后一列（不包含），所以结果如上所示。 再看一个例子： 12345a[1:3,:]out:array([[ 4, 5, 6, 7], [ 8, 9, 10, 11]]) 筛选的是第2-3行的所有列。 一个常用的切片 以列的形式获取最后一列数据： 1234567a[:,3:]out:array([[ 3], [ 7], [11], [15]]) 以一维数组的形式获取最后一列数据： 1234a[:,-1]out:array([ 3, 7, 11, 15]) 上面两种方法经常会用到，前者的shape为(4,1)，后者为(4,)。 ndarray筛选 选择ndarray的对角线 所用函数为np.diag(ndarray, k=N)，其中参数k的取值决定了按照哪一条对角线选择数据。 默认k = 0，取主对角线； k = 1时，取主对角线上面1行的元素； k = -1时，取主对角线下面1行的元素。 思考：这个函数只能选择主对角线上的元素，那如果想要获取副对角线上的元素呢？ 尝试自己搜索一下关键词numpy opposite diagonal寻找答案。 不建议你直接点getting the opposite diagonal of a numpy array。 提取ndarray中的唯一值 所用函数为np.unique(ndarray)，注意unique也可以添加参数axis来控制评判唯一值的轴方向，不好理解可以看示例： 123456789101112131415161718192021#查看二维数组a中的唯一值a = [[0,1,2], [3,4,5], [0,1,2]]print(np.unique(a)) array([0, 1, 2, 3, 4, 5])#查看a中的唯一行（也就是没有重复的行）print(np.unique(a,axis = 0)) array([[0, 1, 2], [3, 4, 5]])#查看a中的唯一列print(np.unique(a,axis = 1)) array([[0, 1, 2], [3, 4, 5], [0, 1, 2]])#查看a中第一行的唯一值print(np.unique(a[0])) array([0, 1, 2]) 通过布尔运算筛选 这里在中括号中添加筛选条件，当该条件的结果为True时（即满足条件时），返回该值。 1X[X &gt; 10] #筛选数组X中大于10的数据 这里需要注意的是，当输入多个筛选条件时，&amp;表示与，|表示或，~表示非。 运算与排序ndarray运算 集合运算 123np.intersect1d(x,y) #取x与y的交集np.setdiff1d(x,y) #取x与y的差集，返回的是在x中且没在y中的元素np.union1d(x,y) #取x与y的并集 算术运算我们可以通过+、-、*、/或np.add、np.substract、np.multiply 、np.divide来对两个矩阵进行元素级的加减乘除运算，因为是元素级的运算，所以两个矩阵的shape必须要一致或者是可广播(Broadcast)。 这里所谓的可广播，就是指虽然A和B两个矩阵的shape不一致，但是A可以拆分为整数个与B具有相同shape的矩阵，这样在进行元素级别的运算时，就会先将A进行拆分，然后与B进行运算，结果再组合一起就可以。这里的A就是“可广播”矩阵。 上面涉及到的乘法是元素对应相乘，也就是点乘，那矩阵的叉乘呢？可以了解下numpy.matmul函数。 ndarray排序我们使用np.sort()和ndarray.sort()来对ndarray进行排序。 相同的是： 二者都可以使用参数axis来决定依照哪个轴进行排序，axis = 0时按照列排序，axis = 1时按照行排序； 不同的是： np.sort()不会更改原数组；ndarray.sort()会更改原数组。","link":"/2019/09/28/初识Numpy/"},{"title":"南大周志华关于论文内容演讲演示文稿","text":"可以允许不完美，但不能不做~ Oneindex下载：http://pan.sqdxwz.com/?/文档/ 蓝奏云下载：https://www.lanzous.com/i6ecpmj 网盘(提取码：21yg )备用下载：https://pan.baidu.com/s/1xXDe3QdrnoiAYojYLl2OuA","link":"/2019/09/25/南大周志华关于论文内容演讲演示文稿/"},{"title":"Mish:撼动深度学习ReLU激活函数的新继任者","text":"对激活函数的研究一直没有停止过，ReLU还是统治着深度学习的激活函数，不过，这种情况有可能会被Mish改变。 Diganta Misra的一篇题为“Mish: A Self Regularized Non-Monotonic Neural Activation Function”的新论文介绍了一个新的深度学习激活函数，该函数在最终准确度上比Swish(+.494%)和ReLU(+ 1.671%)都有提高。 他们的小型FastAI团队使用Mish代替ReLU，打破了之前在FastAI全球排行榜上准确性得分记录的一部分。结合Ranger优化器，Mish激活，Flat + Cosine 退火和自注意力层，他们能够获得12个新的排行榜记录！ 我们12项排行榜记录中的6项。每条记录都是用Mish而不是ReLU。(蓝色高亮显示，400 epoch的准确率为94.6，略高于我们的20 epoch的准确率为93.8:) 作为他们自己测试的一部分，对于ImageWoof数据集的5 epoch测试，他们说： Mish在高显著性水平上优于ReLU (P &lt; 0.0001)。(FastAI论坛@ Seb) Mish已经在70多个基准上进行了测试，包括图像分类、分割和生成，并与其他15个激活函数进行了比较。 什么是Mesh直接看Mesh的代码会更简单一点，简单总结一下，Mish=x * tanh(ln(1+e^x))。 其他的激活函数，ReLU是x = max(0,x)，Swish是x * sigmoid(x)。 PyTorch的Mish实现： Tensorflow中的Mish函数： Tensorflow：x = x *tf.math.tanh(F.softplus(x)) Mish和其他的激活函数相比怎么样？下图显示了Mish与其他一些激活函数的测试结果。这是多达73个测试的结果，在不同的架构，不同的任务上： 为什么Mish表现这么好？以上无边界(即正值可以达到任何高度)避免了由于封顶而导致的饱和。理论上对负值的轻微允许允许更好的梯度流，而不是像ReLU中那样的硬零边界。 最后，可能也是最重要的，目前的想法是，平滑的激活函数允许更好的信息深入神经网络，从而得到更好的准确性和泛化。 尽管如此，我测试了许多激活函数，它们也满足了其中的许多想法，但大多数都无法执行。这里的主要区别可能是Mish函数在曲线上几乎所有点上的平滑度。 这种通过Mish激活曲线平滑性来推送信息的能力如下图所示，在本文的一个简单测试中，越来越多的层被添加到一个测试神经网络中，而没有一个统一的函数。随着层深的增加，ReLU精度迅速下降，其次是Swish。相比之下，Mish能更好地保持准确性，这可能是因为它能更好地传播信息： 更平滑的激活功能允许信息更深入地流动……注意，随着层数的增加，ReLU快速下降。 如何把Mish放到你自己的网络中？Mish的PyTorch和FastAI的源代码可以在github的两个地方找到： 1、官方Mish github：https://github.com/digantamisra98/Mish 2、非官方的Mish使用inline提升速度：https://github.com/lessw2020/mish 总结ReLU有一些已知的弱点，但是通常它执行起来很轻，并且在计算上很轻。Mish具有较强的理论渊源，在测试中，就训练稳定性和准确性而言，Mish的平均性能优于ReLU。 复杂度只稍微增加了一点(V100 GPU和Mish，相对于ReLU，每epoch增加大约1秒)，考虑到训练稳定性的提高和最终精度的提高，稍微增加一点时间似乎是值得的。 最终，在今年测试了大量新的激活函数后，Mish在这方面处于领先地位，许多人怀疑它很有可能成为AI未来的新ReLU。 英文文章地址：https://medium.com/@lessw/meet-mish-new-state-of-the-art-ai-activation-function-the-successor-to-relu-846a6d93471f","link":"/2019/09/25/Mish-撼动深度学习ReLU激活函数的新继任者/"},{"title":"算法可视化平台","text":"前言无疑，数据结构与算法学习最大的难点之一就是如何在脑中形象化其抽象的逻辑步骤。而图像在很多时候能够大大帮助我们理解其对应的抽象化的东西，而如果这个图像还是我们自己一点点画出来的，那么无疑这个印象是最深刻的了。没错，今天就是算法可视化的网站。 网站 https://www.cs.usfca.edu/~galles/visualization/Algorithms.html 该网站特点: 算法可视化 界面简洁直观 过程可控制 https://visualgo.net/zh/ 该网站特点： 算法可视化 文字讲解 复杂度备注 图形可操控调整 https://algorithm-visualizer.org/ 该网站特点： 算法可视化 有代码 有控制台输出帮助理解 算法种类丰富","link":"/2019/09/25/算法可视化平台/"},{"title":"即学即用的30个python常用代码","text":"1.检查重复元素下面的方法可以检查给定列表中是否有重复的元素。它使用了 set() 属性，该属性将会从列表中删除重复的元素。 1234567def all_unique(lst): return len(lst) == len(set(lst)) x = [1,1,2,2,3,2,3,4,5,6] y = [1,2,3,4,5] all_unique(x) # False all_unique(y) # True 2.变位词检测两个字符串是否互为变位词（即互相颠倒字符顺序） 12345from collections import Counter def anagram(first, second): return Counter(first) == Counter(second) anagram(\"abcd3\", \"3acdb\") # True 3.检查内存使用情况123import sys variable = 30 print(sys.getsizeof(variable)) # 24 4.字节大小计算以下方法将以字节为单位返回字符串长度。 12345def byte_size(string): return(len(string.encode( utf-8 ))) byte_size( 😀 ) # 4 byte_size( Hello World ) # 11 5.重复打印字符n次123n = 2; s =\"Programming\"; print(s * n); # ProgrammingProgramming 6.首字母大写12s = \"programming is awesome\" print(s.title()) # Programming Is Awesome 7.分块1234567from math import ceil def chunk(lst, size): return list( map(lambda x: lst[x * size:x * size + size], list(range(0, ceil(len(lst) / size))))) chunk([1,2,3,4,5],2) # [[1,2],[3,4],5] 8.压缩以下方法使用 fliter() 删除列表中的错误值（如：False, None, 0 和“”） 123def compact(lst): return list(filter(bool, lst)) compact([0, 1, False, 2, , 3, a , s , 34]) # [ 1, 2, 3, a , s , 34 ] 9.间隔数以下代码段可以用来转换一个二维数组。 123array = [[ a , b ], [ c , d ], [ e , f ]] transposed = zip(*array) print(transposed) # [( a , c , e ), ( b , d , f )] 10.链式比较以下代码可以在一行中用各种操作符进行多次比较。 123a = 3 print( 2 &lt; a &lt; 8) # True print(1 == a &lt; 2) # False 11.逗号分隔12hobbies = [\"basketball\", \"football\", \"swimming\"]print(\"My hobbies are: \" + \", \".join(hobbies)) # My hobbies are: basketball, football, swimming 12.计算元音字母数12345import re def count_vowels(str): return len(len(re.findall(r [aeiou] , str, re.IGNORECASE))) count_vowels( foobar ) # 3 count_vowels( gym ) # 0 13.首字母恢复小写1234def decapitalize(string): return str[:1].lower() + str[1:] decapitalize( FooBar ) # fooBar decapitalize( FooBar ) # fooBar 14.平面化以下方法使用递归来展开潜在的深度列表。 1234567891011121314def spread(arg): ret = [] for i in arg: if isinstance(i, list): ret.extend(i) else: ret.append(i) return retdef deep_flatten(lst): result = [] result.extend( spread(list(map(lambda x: deep_flatten(x) if type(x) == list else x, lst)))) return resultdeep_flatten([1, [2], [[3], 4], 5]) # [1,2,3,4,5] 15.差异123456def difference(a, b): set_a = set(a) set_b = set(b) comparison = set_a.difference(set_b) return list(comparison)difference([1,2,3], [1,2,4]) # [3] 16.寻找差异123456def difference_by(a, b, fn): b = set(map(fn, b)) return [item for item in a if fn(item) not in b]from math import floordifference_by([2.1, 1.2], [2.3, 3.4],floor) # [1.2]difference_by([{ x : 2 }, { x : 1 }], [{ x : 1 }], lambda v : v[ x ]) # [ { x: 2 } ] 17.链式函数调用123456def add(a, b): return a + bdef subtract(a, b): return a - ba, b = 4, 5print((subtract if a &gt; b else add)(a, b)) # 9 18.检查重复元素1234567def has_duplicates(lst): return len(lst) != len(set(lst)) x = [1,2,3,4,5,5]y = [1,2,3,4,5]has_duplicates(x) # Truehas_duplicates(y) # False 19.合并两个字典1234567def merge_two_dicts(a, b): c = a.copy() # make a copy of a c.update(b) # modify keys and values of a with the ones from b return ca = { x : 1, y : 2}b = { y : 3, z : 4}print(merge_two_dicts(a, b)) # { y : 3, x : 1, z : 4} 123456#在python3.5版本后你还可以：def merge_dictionaries(a, b) return {**a, **b}a = { x : 1, y : 2}b = { y : 3, z : 4}print(merge_dictionaries(a, b)) # { y : 3, x : 1, z : 4} 20.将两个列表转化成一个字典123456def to_dictionary(keys, values): return dict(zip(keys, values)) keys = [\"a\", \"b\", \"c\"] values = [2, 3, 4]print(to_dictionary(keys, values)) # { a : 2, c : 4, b : 3} 21.使用枚举1以下方法将字典作为输入，然后仅返回该字典中的键。 1234567list = [\"a\", \"b\", \"c\", \"d\"]for index, element in enumerate(list): print(\"Value\", element, \"Index \", index, )# ( Value , a , Index , 0)# ( Value , b , Index , 1)#( Value , c , Index , 2)# ( Value , d , Index , 3) 22.计算需要的时间12345678910import timestart_time = time.time()a = 1b = 2c = a + bprint(c) #3end_time = time.time()total_time = end_time - start_timeprint(\"Time: \", total_time)# ( Time: , 1.1205673217773438e-05) 23.Try else指令你可以将 else 子句作为 try/except 块的一部分，如果没有抛出异常，则执行该子句。 1234567try: 2*3except TypeError: print(\"An exception was raised\")else: print(\"Thank God, no exceptions were raised.\")#Thank God, no exceptions were raised. 24.查找最常见元素以下方法返回列表中出现的最常见元素。 12345def most_frequent(list): return max(set(list), key = list.count) list = [1,2,1,2,3,2,1,4,2]most_frequent(list) 25.回文以下方法可检查给定的字符串是否为回文结构。该方法首先将字符串转换为小写，然后从中删除非字母数字字符。最后，它会将新的字符串与反转版本进行比较。 12345def palindrome(string): from re import sub s = sub( [W_] , , string.lower()) return s == s[::-1]palindrome( taco cat ) # True 26.没有 if-else 语句的简单计算器123456789import operatoraction = { \"+\": operator.add, \"-\": operator.sub, \"/\": operator.truediv, \"*\": operator.mul, \"**\": pow}print(action[ - ](50, 25)) # 25 27.元素顺序打乱12345678910111213from copy import deepcopyfrom random import randintdef shuffle(lst): temp_lst = deepcopy(lst) m = len(temp_lst) while (m): m -= 1 i = randint(0, m) temp_lst[m], temp_lst[i] = temp_lst[i], temp_lst[m] return temp_lst foo = [1,2,3]shuffle(foo) # [2,3,1] , foo = [1,2,3] 28.列表扁平化123456789def spread(arg): ret = [] for i in arg: if isinstance(i, list): ret.extend(i) else: ret.append(i) return retspread([1,2,3,[4,5,6],[7],8,9]) # [1,2,3,4,5,6,7,8,9] 29.变量变换1234def swap(a, b): return b, aa, b = -1, 14swap(a, b) # (14, -1) 30.获取确实键的默认值12d = { a : 1, b : 2}print(d.get( c , 3)) # 3","link":"/2019/09/24/即学即用的30个python常用代码/"},{"title":"The Game of Life","text":"#引言 Python 的 Matplotlib 是最常用的图表绘制以及数据可视化库。我们对折线图、柱状图以及热力图都比较熟悉，但你知道用 Matplotlib 还能做简单的动画吗？ 下面就是用 Matplotlib 制作动画的例子。展示的是 John Conway 的 《The Game of Life》，这是一个 Metis（数据科学夏令营）中的编程挑战题目，同时给了我一个机会让我知道Matpltlib可以制作动图。看看结果的动图： 这篇文章的重点还是主要放在 python 中如何用 Matploylib 制作动画。 但如果你不太熟悉模拟游戏的话（它更像是可以看的模拟动画，而非可以玩的游戏），我来给大家介绍一下规则： 一开始先设置一个 N×N 的网格（我的动画中用的是 50×50 ）； 接着随机地向格子中填充“小细胞”（一开始随机地从 2500 个格子中选取 1500 个进行填充）； 如果邻居小细胞少于等于 1 个，那格子中的小细胞会死掉； 如果邻居大于等于 4 个的也会死掉； 只有 2 个或 3 个邻居时可以生存； 空的格子中如果正好有 3 个邻居，则会长出 1 个新的“小细胞”； 通过对规则的阅读我最先想到的是：生命游戏 代码实现注意:我运行采用的是Anaconda3集成环境；程序运行两次，第一次营造运行环境，第二次运行程序输出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import timefrom IPython import displayimport matplotlib.pyplot as pltimport matplotlib.animation as animationimport numpy as npimport seaborn as snsimport random# Some helper functions# Initialize the board with starting positionsdef init_board(pos_list, my_board): for pos in pos_list: my_board[pos[0], pos[1]] = 1 return my_board# Make sure padded border values are always zerodef force_pad_zero(my_board): edge_row_0 = 0 edge_row_1 = my_board.shape[0] - 1 edge_col_0 = 0 edge_col_1 = my_board.shape[1] - 1 for index, row in enumerate(my_board): if index == 0: row[:] = 0 elif index == edge_row_1: row[:] = 0 else: row[edge_col_0] = 0 row[edge_col_1] = 0 for col in my_board: col[edge_row_0] = 0 col[edge_row_1] = 0 return my_board# Figure out the number of neighbors for a given celldef calc_neighbors(row, col, my_board): b = force_pad_zero(my_board) num_neighbors = (b[row-1,col-1] + b[row+0,col-1] + b[row+1,col-1] + b[row+1,col+0] + b[row+1,col+1] + b[row+0,col+1] + b[row-1,col+1] + b[row-1,col+0]) return num_neighbors# Update the board based on the game rules, each call to update_board is one turndef update_board(my_board): old_board = my_board.copy() set_zero = [] set_one = [] # Loop through board and update according to rules for i, row in enumerate(my_board[1:-1,1:-1]): for j, col in enumerate(row): true_i = i + 1 true_j = j + 1 # Update based on number of neighbors (using calc_neighbors) # set_zero and set_one are lists that tell me the coordinates of cells that require updating if (((calc_neighbors(true_i, true_j, my_board) &lt;= 1) or (calc_neighbors(true_i, true_j, my_board) &gt;= 4)) and my_board[true_i, true_j] != 0): set_zero.append([true_i, true_j]) elif ((calc_neighbors(true_i, true_j, my_board) == 3) and my_board[true_i, true_j] == 0): set_one.append([true_i, true_j]) # Update the required cells for index, val in enumerate(set_zero): my_board[val[0], val[1]] = 0 for index, val in enumerate(set_one): my_board[val[0], val[1]] = 1 return my_board# Input variables for the boardboardsize = 50 # board will be X by X where X = boardsizepad = 2 # padded border, do not change this!initial_cells = 1500 # this number of initial cells will be placed # in randomly generated positions# Get a list of random coordinates so that we can initialize # board with randomly placed organismspos_list = []for i in range(initial_cells): pos_list.append([random.randint(1, boardsize), random.randint(1, boardsize)])# Initialize the boardmy_board = np.zeros((boardsize+pad, boardsize+pad))my_board = init_board(pos_list, my_board)##### Animate the board ###### This will throw an error the first time you run the code, but the program will run properly if you# execute the cell again (there is an error with the animation package that I cannot seem to get rid of)# Required line for plotting the animation%matplotlib notebook# Initialize the plot of the board that will be used for animationfig = plt.gcf()# Show first image - which is the initial boardim = plt.imshow(my_board)plt.show()plt.savefig(fname='game_of_life', dpi=150)# Helper function that updates the board and returns a new image of# the updated board animate is the function that FuncAnimation callsdef animate(frame): im.set_data(update_board(my_board)) return im,# This line creates the animationanim = animation.FuncAnimation(fig, animate, frames=200, interval=50) 总结希望这篇文章能帮到大家。在结束之前，让我来帮助大家脑补更多我们今天学到的动画功能在数据科学上的应用： 一个个地画出蒙特卡洛模拟数据，你能观察到最终的分布是如何逐步形成的； 按顺序遍历时间序列数据，可以描绘你的模型或数据在新的观察角度下有什么表现； 当你改变输入参数时，比如族群数，可以展现你的算法是如何划分族群的； 根据时间或不同的数据子集生成关联热力图，用于观察不同的样本是如何影响你的模型的预期参数的。","link":"/2019/09/18/The-Game-of-Life/"},{"title":"镜像站","text":"网易镜像：http://mirrors.163.com/ 阿里云镜像：http://mirrors.aliyun.com/ 中国科学技术大学镜像：http://mirrors.ustc.edu.cn/ 厦门大学镜像：http://mirrors.xmu.edu.cn/ 搜狐镜像：http://mirrors.sohu.com/ 北京交通大学镜像：http://mirror.bjtu.edu.cn/ 北京理工大学镜像：http://mirror.bit.edu.cn/web/ 兰州大学镜像：http://mirror.lzu.edu.cn/ 上海交通大学镜像：http://ftp.sjtu.edu.cn/ 清华大学镜像：https://mirrors.tuna.tsinghua.edu.cn/ 东北大学镜像：http://mirror.neu.edu.cn/ 浙江大学镜像：http://mirrors.zju.edu.cn/ 东软信息学院：http://mirrors.neusoft.edu.cn/ 重庆大学镜像：http://mirrors.cqu.edu.cn/ 大连理工大学镜像：http://mirror.dlut.edu.cn/ CN99镜像：http://mirrors.cn99.com/","link":"/2019/09/18/镜像站/"},{"title":"AI领域区分介绍","text":"说到人工智能(AI)的定义，映入脑海的关键词可能是“未来”，“科幻小说”，虽然这些因素看似离我们很遥远，但它却是我们日常生活的一部分。语音助手的普及、无人驾驶的成功，人工智能、机器学习、深度学习已经深入我们生活的各个场景。例如京东会根据你的浏览行为和用户的相似性，利用算法为你推荐你需要的产品；又比如美颜相机，会基于你面部特征的分析，通过算法精细你的美颜效果。还有众所周知的谷歌DeepMind，当AlphaGo打败了韩国职业围棋高手Lee Se-dol时，媒体描述这场人机对战的时候，提到了人工智能AI、机器学习、深度学习等术语。没错，这三项技术都为AlphaGo的胜利立下了汗马功劳，然而它们并不是一回事。 人工智能和机器学习的同时出现，机器学习和深度学习的交替使用……使大部分读者雾里看花，这些概念究竟有何区别，我们可以通过下面一个关系图来进行区分。 图一：人工智能、机器学习、深度学习的关系 人工智能包括了机器学习和深度学习，机器学习包括了深度学习。人工智能是机器学习的父类，机器学习则是深度学习的父类。 人工智能（Artificial Intelligence，AI）是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的与人类智能相似的方式作出反应的智能机器，它不是人的智能，但能像人那样思考、也可能超过人的智能。 人工智能实际应用：机器视觉，指纹识别，人脸识别，视网膜识别，虹膜识别，掌纹识别，专家系统，自动规划，智能搜索，定理证明，博弈，自动程序设计，智能控制，机器人学，语言和图像理解，遗传编程等。人工智能目前也分为：强人工智能(BOTTOM-UPAI)和弱人工智能(TOP-DOWNAI)。 机器学习（Machine Learning，ML）是人工智能的核心，属于人工智能的一个分支。机器学习是指从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法，所以机器学习的核心是数据、算法（模型）、算力（计算机运算能力）。 机器学习应用领域：数据挖掘、数据分类、计算机视觉、自然语言处理(NLP)、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用等。 深度学习（Deep Learning，DL）：是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据。 数据挖掘（Data Mining，DM），顾名思义是指利用机器学习技术从海量数据中“挖掘”隐藏信息，主要应用于图像、声音、文本。在商业环境中，企业希望让存放在数据库中的数据能“说话”，支持决策。所以数据挖掘更偏向于应用。 图二：数据挖掘与机器学习的关系 机器学习是数据挖掘的一种重要方法，但机器学习是另一门学科，并不从属于数据挖掘，二者相辅相成。数据挖掘是机器学习和数据库的交叉，主要利用机器学习提供的技术来分析海量数据，利用数据库界提供的技术来管理海量数据。 不管是人工智能、机器学习、深度学习还是数据挖掘，目前都在解决共同目标时发挥了自己的优势，并为社会生产和人类生活提供便利，帮助我们探索过去、展示现状、预测未来。","link":"/2019/09/15/AI领域区分介绍/"},{"title":"为Anaconda3安装tensorflow等","text":"Anaconda3介绍简单来说，Anaconda是Python的包管理器和环境管理器。 先来解决一个初学者都会问的问题：我已经安装了Python，那么为什么还需要Anaconda呢？原因有以下几点： Anaconda附带了一大批常用数据科学包，它附带了conda、Python和 150 多个科学包及其依赖项。因此你可以用Anaconda立即开始处理数据。 管理包。Anaconda 是在 conda（一个包管理器和环境管理器）上发展出来的。在数据分析中，你会用到很多第三方的包，而conda（包管理器）可以很好的帮助你在计算机上安装和管理这些包，包括安装、卸载和更新包。 管理环境。为什么需要管理环境呢？比如你在A项目中用到了Python2，而新的项目要求使用Python3，而同时安装两个Python版本可能会造成许多混乱和错误。这时候conda就可以帮助你为不同的项目建立不同的运行环境。还有很多项目使用的包版本不同，比如不同的pandas版本，不可能同时安装两个pandas版本。你要做的应该是在项目对应的环境中创建对应的pandas版本。这时候conda就可以帮你做到。 Anaconda3的安装 官网地址 清华镜像 关于安装过程中的细节,如全局变量设置…可自行百度,下面我们转入正题 Anaconda3安装tensorflow 打开anaconda安装时自带的Anaconda prompt 打开后,输入清华镜像的tensorflow的下载地址(如果你已经在墙外翱翔了,可以省略这一步): 12conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --set show_channel_urls yes 接着我们开始创建一个python3.6的环境,因为如果你安装的是最新的anaconda,它默认环境为py3.7,并且在不久之前,tensorflow已经开始支持py3.6,所以我们创建一个py3.6环境:1conda create -n tensorflow python=3.6 启动anaconda中的py3.6环境:1activate tensorflow 如果不能进入,则重新执行第3步骤 进入py3.6的环境中后,我们就可以进行安装了(此处我们安装的是CPU版本的tensorflow):1pip install --upgrade --ignore-installed tensorflow 当我们不使用tensorflow时,我们就可以使用:1deactivate 退出该环境 开始测试一下是否安装成功: 重新打开Anaconda Prompt—&gt;activate tensorflow—&gt;python来启动tensorflow，并进入python环境 12345#TensorFlow使用图(Graph)来表示计算任务；并使用会话(Session)来执行图，通过Session.close()来关闭会话（这是一种显式关闭会话的方式）。会话方式有显式和隐式会话之分。import tensorflow as tfhello = tf.constant('Hello, TensorFlow!') #初始化一个TensorFlow的常量sess = tf.Session() #启动一个会话print(sess.run(hello)) 如果可以准确的输出结果,那么恭喜你,安装tensorflow成功! Anaconda3安装pytorch 打开anaconda安装时自带的Anaconda prompt 创建py3.6环境: 1conda create -n pytorch python=3.6 启动anaconda中的py3.6环境:1activate pytorch PyTorch 的官网提供了简单的安装方法，只需简单的命令即可。 首先，打开 PyTorch 官网安装页面（需自备梯子）：https://pytorch.org/get-started/locally/ 然后复制页面中Run this Command后的代码,粘贴在你的命令行,等待安装完成就可以了~ Anaconda3安装keras其实keras是可以与tensorflow在共同环境下使用的,所以我们可以直接将keras安装在我们的tensorflow环境中。 打开anaconda安装时自带的Anaconda prompt 创建py3.6环境: 1conda create -n tensorflow python=3.6 启动anaconda中的py3.6环境:1activate tensorflow 直接运行命令:123conda install keras或者pip install keras 等待安装完成即可~","link":"/2019/09/15/为Anaconda3安装tensorflow等/"},{"title":"关于论文作者那点事","text":"对于论文想必大家可能都有过耳闻,今天做一下一些相关知识的普及~ 首先,第一作者和通讯作者之间一直是缠缠绵绵到天涯的关系，很多人对这两者并不陌生，但是在一些细节上的问题又感觉比较绕，我今天特意收集了平时大家提到的关于两者之间的一些问题，做成问答集锦，你想知道的，都在里面啦~ 什么是第一作者？第一作者通常主导大部分的实验工作，在一般的情况下，引用一篇论文时，提到的就是第一作者的名字，如 Tomas et al. report that…。 以第一作者的身份进行论文发表对博士生的科研路是很重要的，不止中国，全球大部分的博士毕业标准都要求学生要作为第一作者发表至少一篇论文。 对博士后及资深教授来说，作为第一作者的期刊论文发表是争取基金、职称晋升及续聘时的重要因素。据此，期刊论文的作者名单里，第一个名字一直是最抢手的位置。 在第一作者之后，作者顺序是根据对研究的贡献度排序，贡献度越高的排名越前。不过，有时候可能会有多位作者贡献度相同，这时候就可以列为共同一作、共同二作… 注意:第一作者很重要很重要很重要，要毕业、评职称、争基金…没头发可以，没它不行~ 什么是通讯作者？通讯作者是课题的总负责人，承担课题的经费、设计、文章的书写和把关，在投稿、同行评审和整个发表流程中负责和期刊沟通。从知识产权的角度来说，研究成果算是通讯作者的。能当通讯作者的人一般有以下几类： 论文的法定负责人: 通讯作者也是论文的主要受益人之一。也可以这么说，论文的第一作者是这项科研成果的主要贡献者，而论文的通讯作者是这项成果的责任者和受益人。 导师、教授、科研项目的主要负责人 其主要贡献是提供研究指导、研究经费、试验场所、实验室、仪器设备等与实验相关的物质资源。 论文的任何作者 要是一篇论文有数个作者，通讯作者可以是他们中的任何一位。至于到底是谁，主要看通讯作者在这项研究中真正起的作用和做出的贡献。要是他在整个实验中做到了关键的作用，那么他就理所当然地即可做第一作者，也可做通讯作者。 注意: 对于学生来说，通讯作者一般是他的导师。 对于研究机构来说，通讯作者一般是项目负责人。 对于出版机构来说，通讯作者可以是机构老板。 另外！！！一定要有固定的通讯地址！ 第一作者和通讯作者，谁更重要？通讯作者未必是第一作者，但第一作者可以是通讯作者。通讯作者多数情况和第一作者是同一个人，只有在通讯作者和第一作者不一致的时候，才有必要在文章脚注中附加通讯作者的标识。 所以，总的来说都重要！对于作者来说，第一作者很重要，谁是通讯作者没关系，但是通讯单位很关键，很多单位评职称看通讯单位，不看通讯作者。对于导师来说，通讯作者重要，因为导师永远当通讯作者，至于谁是第一作者不重要。对于出版机构来说，通讯作者非常重要，因为机构老板也常是通讯作者… 注意:通讯作者不是随便挂的，一旦出现通讯作者，这篇文章的科研版权就要非常注意了~ 共同一作排序重要吗，会影响评职称吗？共同作者排在第一位的是最好，所有东西都可以申请。因为排第一的肯定是第一作者，大家引用的时候都会缩写成“First-Author, et al，但是排在第二位就要小心了，排在第二位的虽然也是共同第一作者，但是有些单位只看第一位的，所以评职称的时候一定要问清楚单位科研处排在第二的共同作者能否评职称。 不过事无绝对，以下一些例子里面的共同一作和第一作者的贡献量和含金量差不多，排序嘛，就比较随便了··· 按作者名字的字母顺序决定作者排序 抛硬币决定作者顺序 根据对星战的痴迷程度决定作者顺序 根据申tenure的时间远近决定作者顺序 注意:国内对作者排序还是很重视的，很多机构和单位甚至只认可排序靠前的，所以能排前面就别排后面啦~ 所有的论文都要有通讯作者吗？并不是要求所有的论文都一定要写通讯作者。对于没有通讯作者的稿件，默认第一作者为通讯作者。 通讯作者多数情况和第一作者是同一个人，这样的话实际上是省略了通讯作者。只有在通讯作者和第一作者不一致的时候，才有必要加通讯作者。不赞成一味地模仿国外杂志，加不加通讯作者应根据需要而定。 注意:通讯作者非必须，随意模仿不可取~ 我有两个老板，一个小老板，一个大老板，通讯作者排序要怎么排呢？目前，最常见的做法是权力最大的排最后，权力排倒数第二，也就是大老板排最后，小老板排倒数第二。一般期刊只能允许两位通讯作者，在文章中标注，列出他们的邮箱，偶尔也会看见有些期刊会有三个通讯，不过也有些期刊不准共同通讯，只能一个人。所以在投稿前一定要仔细阅读稿约。 注意:根据权力大小排就对了！ 导师可以既是第一作者，又是通讯作者吗？可以。第一作者兼任通讯作者没什么问题，更何况，对单一作者的论文来说，第一作者和通讯作者肯定是同一个人。如果你的教授对研究也出谋划策，拟出初始计划和研究设计，一定要将他列为共同作者。至于具体怎么做，还是需要跟导师商量，达成一致，避免日后产生争议。 注意:导师可以既当第一作者，又当通讯作者。 论文被接受，还能更换作者顺序和通讯作者吗？一般来说，期刊对于作者顺序变更不会有太大的意见，但非必要最好避免更换通讯作者，因为期刊编辑和通讯作者之间已经有过交流，有一定的熟悉程度。 不过，如果有不可抗拒的因素需要换通讯作者跟作者顺序的话，一定要跟编辑沟通解释清楚，因为这会涉及到之后的一系列问题，例如评职称、申奖金等等。另外，修改作者的时候，一定要附上新的版权~ 注意:作者顺序可以改，通讯作者最好不要改！ 不是通讯作者可以直接和期刊编辑联系吗？通讯作者的作用就是期刊编辑最主要的联系窗口，相关的沟通事宜都是通讯作者负责，不是通讯作者最好不要和期刊编辑联系，为避免将事情复杂化，最好是将事情积极反馈给通讯作者，再由通讯作者和期刊编辑沟通。 注意:让通讯作者架起沟通的桥梁~ 论文被查出学术不端，负责的应该是第一作者还是通讯作者？通讯作者是要对论文的全程进行把关的。特别是对里面内容的真实性，论证的根据等，有没有达到发表的水平。所以，通讯作者，既是一个署名权，更重要的是对这篇学术论文承担的责任。如果这篇文章出问题，通讯作者是第一责任人！当然那些没有被告知，就被别人列为论文的通讯作者，还是会有背黑锅的时候··· 注意:通讯作者负责就要负到底！ 让有名望的学者当通讯作者是不是能增加论文的投中率？如果在学术界口碑好、有名望教授当自己论文的通讯作者，会增加论文的投中率。因为通讯作者需要对论文把关，好口碑的教授一般学风严谨，出任通讯作者也是以自己的名誉来做担保，所以编辑在审查的时候，也会增加对论文的好感度，最后能不能投中关键的还是看论文的质量。 注意:论文能不能投中关键还是靠质量~ 最后,提醒一下大家：研究项目启动前是决定署名作者及其排名顺序的最佳时机，参与项目的团队成员必须在这些方面达成完全一致，毕竟按劳所得是亘古不变的真理~","link":"/2019/09/15/关于论文作者那点事/"},{"title":"机器学习分类算法","text":"说起分类算法，相信学过机器学习的同学都能侃上一二。 可是，你能够如数家珍地说出所有常用的分类算法，以及他们的特征、优缺点吗？比如说，你可以快速地回答下面的问题么: KNN算法的优缺点是什么？ Naive Bayes算法的基本假设是什么？ entropy loss是如何定义的？ 最后，分类算法调参常用的图像又有哪些？ 可能真的涉及这些问题时候，我们不能快速的回答，所以我总结了此文~ 机器学习是一种能从数据中学习的计算机编程科学以及艺术，就像下面这句话说得一样。 机器学习是使计算机无需显式编程就能学习的研究领域。——阿瑟·塞缪尔，1959年 不过还有一个更好的定义： “如果一个程序在使用既有的经验（E）执行某类任务（T）的过程中被认为是“具备学习能力的”，那么它一定需要展现出:利用现有的经验（E），不断改善其完成既定任务（T）的性能（P）的特性。” ——Tom Mitchell, 1997 例如，你的垃圾邮件过滤器是一个机器学习程序，通过学习用户标记好的垃圾邮件和常规非垃圾邮件示例，它可以学会标记垃圾邮件。系统用于学习的示例称为训练集。在此案例中，任务（T）是标记新邮件是否为垃圾邮件，经验（E）是训练数据，性能度量（P） 需要定义。例如，你可以定义正确分类的电子邮件的比例为P。这种特殊的性能度量称为准确度，这是一种有监督的学习方法，常被用于分类任务。 监督学习在监督学习中，算法从有标记数据中学习。在理解数据之后，该算法通过将模式与未标记的新数据关联来确定应该给新数据赋哪种标签。 监督学习可以分为两类：分类和回归。 分类问题预测数据所属的类别； 分类的例子包括垃圾邮件检测、客户流失预测、情感分析、犬种检测等。 回归问题根据先前观察到的数据预测数值； 回归的例子包括房价预测、股价预测、身高-体重预测等。 分类问题分类是一种基于一个或多个自变量确定因变量所属类别的技术。 分类算法逻辑回归逻辑回归类似于线性回归，适用于因变量不是一个数值字的情况 (例如，一个“是/否”的响应)。它虽然被称为回归，但却是基于根据回归的分类，将因变量分为两类。 如上所述，逻辑回归用于预测二分类的输出。例如，如果信用卡公司构建一个模型来决定是否通过向客户的发行信用卡申请，它将预测客户的信用卡是否会“违约”。 首先对变量之间的关系进行线性回归以构建模型，分类的阈值假设为0.5。 然后将Logistic函数应用于回归分析，得到两类的概率。 该函数给出了事件发生和不发生概率的对数。最后，根据这两类中较高的概率对变量进行分类。 K-近邻算法（K-NN）K-NN算法是一种最简单的分类算法，通过识别被分成若干类的数据点，以预测新样本点的分类。K-NN是一种非参数的算法，是“懒惰学习”的著名代表，它根据相似性（如，距离函数）对新数据进行分类。 K-NN能很好地处理少量输入变量（p）的情况，但当输入量非常大时就会出现问题。 支持向量机（SVM）支持向量机既可用于回归也可用于分类。它基于定义决策边界的决策平面。决策平面（超平面）可将一组属于不同类的对象分离开。 在支持向量的帮助下，SVM通过寻找超平面进行分类，并使两个类之间的边界距离最大化。 SVM中超平面的学习是通过将问题转化为使用一些某种线性代数转换问题来完成的。（上图的例子是一个线性核，它在每个变量之间具有线性可分性）。 对于高维数据，使用可使用其他核函数，但高维数据不容易进行分类。具体方法将在之后阐述。 核支持向量机核支持向量机将核函数引入到SVM算法中，并将其转换为所需的形式，将数据映射到可分的高维空间。 核函数的类型包括： 前文讨论的就是线性SVM。 多项式核中需要指定多项式的次数。它允许在输入空间中使用曲线进行分割。 径向基核（radial basis function, RBF）可用于非线性可分变量。使用平方欧几里德距离，参数的典型值会导致过度拟合。sklearn中默认使用RBF。 类似于与逻辑回归类似，sigmoid核用于二分类问题。 径向基核（RBF：Radial Basis Function ）RBF核支持向量机的决策区域实际上也是一个线性决策区域。RBF核支持向量机的实际作用是构造特征的非线性组合，将样本映射到高维特征空间，再利用线性决策边界分离类。 因此，可以得出经验是：对线性问题使用线性支持向量机，对非线性问题使用非线性核函数，如RBF核函数。 朴素贝叶斯朴素贝叶斯分类器建立在贝叶斯定理的基础上，基于特征之间互相独立的假设（假定类中存在一个与任何其他特征无关的特征）。即使这些特征相互依赖，或者依赖于其他特征的存在，朴素贝叶斯算法都认为这些特征都是独立的。这样的假设过于理想，朴素贝叶斯因此而得名。 在朴素贝叶斯的基础上，高斯朴素贝叶斯根据二项（正态）分布对数据进行分类。 P(class|data) 表示给定特征（属性）后数据属于某类（目标）的后验概率。给定数据，其属于各类的概率大小就是我们要计算的值。 P(class)表示某类的先验概率。 P(data|class)表示似然，是指定类别时特征出现的概率。 P(data)表示特征或边际似然的先验概率。 步骤: 1、计算先验概率 P(class) = 类中数据点的数量/观测值的总数量 P(yellow) = 10/17 P(green) = 7/17 2、计算边际似然 P(data) = 与观测值相似的数据点的数量/观测值的总数量 P(?) = 4/17 该值用于检查各个概率。 3、计算似然 P(data/class) = 类中与观测值相似的数量/类中点的总数量 P(?/yellow) = 1/7 P(?/green) = 3/10 4、计算各类的后验概率 5、分类 某一点归于后验概率高的类别，因为从上可知其属于绿色类的概率是75%根据其75%的概率这个点属于绿色类。 多项式、伯努利朴素贝叶斯是计算概率的其他模型。朴素贝叶斯模型易于构建，不需要复杂的参数迭代估计，这使得它对非常大的数据集特别有用。 决策树分类决策树以树状结构构建分类或回归模型。它通过将数据集不断拆分为更小的子集来使决策树不断生长。最终长成具有决策节点（包括根节点和内部节点）和叶节点的树。最初决策树算法它采用采用Iterative Dichotomiser 3（ID3）算法来确定分裂节点的顺序。 信息熵和信息增益用于被用来构建决策树。 信息熵信息熵是衡量元素无序状态程度的一个指标，即衡量信息的不纯度。 信息熵是衡量元素的无序状态的程度的一个指标，或者说，衡量信息的不纯度。 直观上说地理解，信息熵表示一个事件的确定性程度。信息熵度量样本的同一性，如果样本全部属于同一类，则信息熵为0；如果样本等分成不同的类别，则信息熵为1。 信息增益信息增益测量独立属性间信息熵的变化。它试图估计每个属性本身包含的信息，构造决策树就是要找到具有最高信息增益的属性（即纯度最高的分支）。 信息增益测量独立属性间的信息熵的变化。它试图估计每个属性本身包含的信息，构造决策树就是要找到具有最高信息增益的属性（即纯度最高的分支）。 其中Gain（(T,X）)是特征X的信息增益。Entropy(T)是整个集合的信息熵，第二项Entropy(T,X)是特征X的信息熵。 采用信息熵进行节点选择时，通过对该节点各个属性信息增益进行排序，选择具有最高信息增益的属性作为划分节点，过滤掉其他属性。 决策树模型存在的一个问题是容易过拟合。因为在其决策树构建过程中试图通过生成长一棵完整的树来拟合训练集，因此却降低了测试集的准确性。 通过剪枝技术可以减少小决策树的过拟合问题。 分类的集成算法集成算法是一个模型组。从技术上说，集成算法是单独训练几个有监督模型，并将训练好的模型以不同的方式进行融合，从而达到最终的得预测结果。集成后的模型比其中任何一个单独的模型都有更高的预测能力。 随机森林分类器随机森林分类器是一种基于装袋（bagging）的集成算法，即自举助聚合法(bootstrap aggregation)。集成算法结合了多个相同或不同类型的算法来对对象进行分类（例如，SVM的集成，基于朴素贝叶斯的集成或基于决策树的集成）。 集成的基本思想是算法的组合提升了最终的结果。 深度太大的决策树容易受过拟合的影响。但是随机森林通过在随机子集上构建决策树防止过拟合，主要原因是它会对所有树的结果进行投票的结果是所有树的分类结果的投票，从而消除了单棵树的偏差。 随机森林在决策树生增长的同时为模型增加了额外的随机性。它在分割节点时，不是搜索全部样本最重要的特征，而是在随机特征子集中搜索最佳特征。这种方式使得决策树具有多样性，从而能够得到更好的模型。 梯度提升分类器梯度提升分类器是一种提升集成算法。提升(boosting)算法是为了减少偏差而对弱分类器的而进行的一种集成方法。与装袋（bagging）方法构建预测结果池不同，提升算法是一种分类器的串行方法，它把每个输出作为下一个分类器的输入。通常，在装袋算法中，每棵树在原始数据集的子集上并行训练，并用所有树预测结果的均值作为模型最终的预测结果；梯度提升模型，采用串行方式而非并行模式获得预测结果。每棵决策树预测前一棵决策树的误差，因而使误差获得提升。 使用浅层决策树初始化预测结果。 计算残差值（实际预测值）。 构建另一棵浅层决策树，将上一棵树的残差作为输入进行预测。 用新预测值和学习率的乘积作为最新预测结果，更新原有预测结果。 重复步骤2-4，进行一定次数的迭代（迭代的次数即为构建的决策树的个数）。 如果想了解更多关于梯度提升分类器的知识，可参考：https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d%20/t%20_blank 分类器的性能混淆矩阵混淆矩阵是一张表，这张表通过对比已知分类结果的测试数据的预测值和真实值表来描述衡量分类器的性能。在二分类的情况下，混淆矩阵是展示预测值和真实值四种不同结果组合的表。 多分类问题的混淆矩阵可以帮助你确认错误模式。 对于二元分类器： 假正例&amp;假负例假正例和假负例用来衡量模型预测的分类效果。假正例是指模型错误地将负例预测为正例。假负例是指模型错误地将正例预测为负例。主对角线的值越大（主对角线为真正例和真负例），模型就越好；副对角线给出模型的最差预测结果。 假正例下面给出一个假正例的例子。比如：模型将一封邮件分类为垃圾邮件（正例），但这封邮件实际并不是垃圾邮件。这就像一个警示，错误如果能被修正就更好，但是与假负例相比，它并不是一个严重的问题。 作者注：个人观点，这个例子举的不太好，对垃圾邮件来说，相比于错误地将垃圾邮件分类为正常邮件（假负例），将正常邮件错误地分类为垃圾邮件（假正例）是更严重的问题。 假正例（I型错误）——原假设正确而拒绝原假设。 假负例假负例的一个例子。例如，该模型预测一封邮件不是垃圾邮件（负例），但实际上这封邮件是垃圾邮件。这就像一个危险的信号，错误应该被及早纠正，因为它比假正例更严重。 假负例（II型错误）——原假设错误而接受原假设。 上图能够很容易地说明上述指标。左图男士的测试结果是假正例因为男性不能怀孕；右图女士是假负例因为很明显她怀孕了。 从混淆矩阵，我们能计算出准确率、精度、召回率和F-1值。 准确率准确率是模型预测正确的部分。 准确率的公式为： 当数据集不平衡，也就是正样本和负样本的数量存在显著差异时，单独依靠准确率不能评价模型的性能。精度和召回率是衡量不平衡数据集的更好的指标。 精度精度是指在所有预测为正例的分类中，预测正确的程度为正例的效果。 精度越高越好。 召回率召回率是指在所有预测为正例（被正确预测为真的和没被正确预测但为真的）的分类样本中，召回率是指预测正确的程度。它，也被称为敏感度或真正率（TPR）。 召回率越高越好。 F-1值通常实用的做法是将精度和召回率合成一个指标F-1值更好用，特别是当你需要一种简单的方法来衡量两个分类器性能时。F-1值是精度和召回率的调和平均值。 普通的通常均值将所有的值平等对待，而调和平均值给予较低的值更高的权重，从而能够更多地惩罚极端值。所以，如果精度和召回率都很高，则分类器将得到很高的F-1值。 接受者操作曲线（ROC）和曲线下的面积（AUC）ROC曲线是衡量分类器性能的一个很重要指标，它代表模型准确预测的程度。ROC曲线通过绘制真正率和假正率的关系来衡量分类器的敏感度。如果分类器性能优越，则真正率将增加，曲线下的面积会接近于1.如果分类器类似于随机猜测，真正率将随假正率线性增加。AUC值越大，模型效果越好。 累积精度曲线CAP代表一个模型沿y轴为真正率的累积百分比与沿x轴的该分类样本累积百分比。CAP不同于接受者操作曲线（ROC，绘制的是真正率与假正率的关系）。与ROC曲线相比，CAP曲线很少使用。 以考虑一个预测客户是否会购买产品的模型为例，如果随机选择客户，他有50%的概率会购买产品。客户购买产品的累积数量会线性地增长到对应客户总量的最大值，这个曲线称为CAP随机曲线，为上图中的蓝色线。而一个完美的预测，准确地确定预测了哪些客户会购买产品，这样，在所有样本中只需选择最少的客户就能达到最大购买量。这在CAP曲线上产生了一条开始陡峭一旦达到最大值就会维持在1的折线，称为CAP的完美曲线，也被称为理想曲线，为上图中灰色的线。 最后，一个真实的模型应该能尽可能最大化地正确预测，接近于理想模型曲线。","link":"/2019/09/12/机器学习分类算法/"},{"title":"使用cython加速代码运行","text":"引入毫无疑问，Python是社区最喜爱的编程语言!到目前为止，它是最容易使用的语言之一，因为python代码是用一种直观的、人类可读的方式编写的。 然而，你经常会反复听到一些对Python的抱怨，尤其是来自C语言爱好者的抱怨，这些抱怨无非就是Python很慢。 是的，他们并没有说错。 与许多其他编程语言相比，Python确实很慢。Benchmark game有一些比较不同编程语言在不同任务上的速度的可靠基准。 https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/gpp-python3.html?source=post_page 对于Python，我们有几种不同的方法可以加快速度: 1.使用多进程库来使用所有的CPU核心https://towardsdatascience.com/heres-how-you-can-get-a-2-6x-speed-up-on-your-data-pre-processing-with-python-847887e63be52.如果你使用Numpy、panda或Scikit-Learn，使用Rapids来加速GPU上的处理。https://towardsdatascience.com/heres-how-you-can-accelerate-your-data-science-on-gpu-4ecf99db3430 如果你所做的实际上可以并行化，比如数据预处理或矩阵运算，这些都是很好的方法。 但是如果你的代码是纯Python的呢?如果你不得不使用一个很大的for循环，且不能将数据放入矩阵中，因为数据必须按顺序处理，那会怎样?有没有办法加快Python本身的速度呢? 答案是肯定的，这就是Cython来加速原生Python代码的地方。 什么是Cython？Cython是Python和C/C++之间的一个中间步骤。它允许你编写纯Python代码，并且只需要做一些小修改，然后将其直接翻译成C代码。 你对Python代码所做的惟一调整就是向每个变量添加类型信息。通常，我们可以像这样在Python中声明一个变量: 1x = 5 使用Cython，我们将向该变量添加一个类型: 1cdef int x = 5 这告诉Cython，我们的变量是浮点类型，就像我们在C中所做的一样。对于纯Python，变量的类型是动态确定的。Cython中类型的显式声明使转换为C成为可能，因为显式类型声明是必须的。 安装Cython只需要一行简单的pip命令: 1pip install cython Cython中的类型使用Cython时，变量和函数分别有不同的类型。 对于变量我们有以下类型: cdef int a, b, c cdef char *s cdef float x = 0.5 (单精度) cdef double x = 63.4 (双精度) cdef list names cdef dict goals_for_each_play cdef object card_deck 注意所有这些类型都来自C/C++ ! 而对于方法我们有以下类型: def — 常规python函数，仅从python调用。 cdef — 不能从python的代码中访问Cython的函数。即必须在Cython内调用 cpdef — C 和 Python. 可以从C和Python中访问 了解了Cython类型之后，我们就可以直接实现加速了! 如何使用Cython加速python代码我们要做的第一件事是设置Python代码基准:用于计算数值阶乘的for循环。原生Python代码如下: 12345def test(x): y = 1 for i in range(x+1): y *= i return y 相同功能的Cython方法看起来非常相似。首先，我们将确保Cython代码文件具有.pyx扩展名。对代码本身的惟一更改是，我们已经声明了每个变量和函数的类型。 123456cpdef int test(int x): cdef int y = 1 cdef int i for i in range(x+1): y *= i return y Boom ! 可以看到我们的C代码已经编译好了，可以使用了! 你将看到，在Cython代码所在的文件夹中，你拥有运行C代码所需的所有文件，包括run_cython.c文件。如果你感兴趣，可以查看一下Cython生成的C代码! 现在我们准备测试我们新的并且超级快的C代码!查看下面的代码，它实现了一个速度测试，将原生Python代码与Cython代码进行比较。 123456789101112131415161718192021import run_pythonimport run_cythonimport timenumber = 10start = time.time()run_python.test(number)end = time.time()py_time = end - startprint(\"Python time = {}\".format(py_time))start = time.time()run_cython.test(number)end = time.time()cy_time = end - startprint(\"Cython time = {}\".format(cy_time))print(\"Speedup = {}\".format(py_time / cy_time)) 代码非常直观，我们以与普通Python相同的方式导入文件，并以与普通Python相同的方式运行函数! Cython几乎可以让你在所有原生Python代码上获得良好的加速，而不需要太多额外的工作。需要注意的关键是，循环次数越多，处理的数据越多，Cython可以提供的帮助就越多。 下表显示了Cython为不同的数值阶乘带来的加速性能。当数值为10000000的时候，可以看到，我们的Cython加速超过了36倍。 注意目前我的运行存在有 1DistutilsPlatformError: Unable to find vcvarsall.bat 错误,正在想办法解决,希望可以能尽快进入到一个c与python共存的世界 注意:该问题我已经解决，现在给出方法: 安装vsstudio2019，教程在:cython加速你的代码运行 参考文章:cython加速python使用 我运行的代码源文件:下载 使用笔记","link":"/2019/09/10/使用cython加速代码运行/"},{"title":"《深度学习入门》阅读笔记","text":"第1章 Python入门1.5.4 Numpy的N维数组12345import numpy as npa = np.array([[1,2],[3,4]])b = np.array([[3,0],[0,6]])print(a+b)print(a*b) 注意:数学上，一维数组称为向量；二维数组称为矩阵；可以将一般化后的向量或矩阵等统称为张量。 1.5.5 广播1234import numpy as npa = np.array([[1,2],[3,4]])b = np.array([10,20])print(a*b) 1.6.3 显示图像12345import matplotlib.pyplot as pltfrom matplotlib.image import imreadimg = imread('图片名称')plt.imshow(img)plt.show() 第2章 感知机感知机是神经网络(深度学习)的起源算法。 2.3.3 使用权重和偏置的实现权重值是控制输入信号的重要参数；偏置值调整了神经元被激活的容易程度。 2.4.2 线性和非线性单层感知机的局限性在于它只能表示由一条直线分割的区间。 2.5.2 异或门的实现叠加了多层的感知机称为多层感知机。 感知机的层数叫法问题。 2.6 从与非门到计算机实际上，使用感知机甚至可以表示计算机！ 第3章 神经网络当拥有感知机的同时我们也知道了两个消息： 好消息：对于复杂的函数，感知机也能通过叠加层数来有可能性的实现。 坏消息是：设定权重的工作在感知机中仍只能是由人工进行的。 而神经网络的出现就是为了解决来自感知机的坏消息。 3.1.3 激活函数登场激活函数的作用在于决定如何来激活输入信号的总和。 3.2 激活函数阶跃函数：函数以阈值为界，一旦输入超过阈值，就切换输出。 实际上，如果将激活函数从阶跃函数换成其他函数，我们就可以进入到神经网络的世界了。 3.2.5 sigmiod函数和阶跃函数的比较sigmoid函数是一条平滑的曲线，输出随着输入发生连续性变化；而阶跃函数以0为界，输出发生急剧性的变化。sigmoid函数的平滑性对神经网络的学习具有重要的意义。 也就是说，相对于感知机中的神经元只能返回0或1的信号，神经网络中返回的是连续的实数值信号。 相同点 两者的图像结构均表示为：“输入小时，输出接近0（为0）；输入大时，随着输入的增大，输出靠近1（为1）”。 不管输入的大小为多少，输出信号的值始终在0到1之间。 均为非线性函数。 不同点 阶跃函数：“竹筒敲石”。 sigmoid函数：“水车”。 3.2.6 非线性函数输出值为输入值的常数倍的函数称为线性函数。 为了发挥叠加层的优势，神经网络必须使用非线性函数。 3.5 输出层的设计神经网络可以使用在分类和回归问题上，不过需要根据情况改变输出层的激活函数 ，一般而言，回归问题用恒等函数，分类问题用softmax函数。 softmax函数python实现： 12345def softmax(a): exp_a = np.exp(a) sum_exp_a = np.sum(exp_a) y = exp_a / sum_exp_a return y 3.5.2 使用softmax函数时的注意事项softmax函数的分子进行了指数的运算，可能会产生一些超大值，如果这些超大值进行除法运算，会出现”不确定”的情况，这就是产生了溢出问题。 改进的softmax函数python实现： 123456def softmax(a): c = np.max(a) exp_a = np.exp(a - c) sum_exp_a = np.sum(exp_a) y = exp_a / sum_exp_a return y 3.5.4 输出层的神经元数量输出层的神经元数量需要根据需要解决的问题来决定。对于分类问题，输出层的神经元的数量一般设为类别的数量。 第4章 神经网络的学习“学习”是指从训练数据中自动获取最优权重参数的过程。 4.1.1 数据驱动对于一个数字“5”的识别，我们可以采用一些方法来识别： 人暴力想出一个算法识别，得出答案。-人参与 人想到特征量（如一个横，一个类似s构成了5），然后采用机器学习（SVM，KNN）得出答案。-人参与 神经网络（深度学习）利用数据学习，机器自己识别判断。-完全机器 深度学习也被称为端到端的机器学习。 神经网络的优点是对所有问题都可以采用同样的流程来解决，不管解决的是识别数字还是人脸，神经网络都是通过不断的学习所提供的数据，尝试发现待解决的问题。 4.1.2 训练数据和测试数据 训练数据：也称监督数据，用来训练新的模型的数据。 测试数据：为了检验模型的泛化能力。 泛化能力指处理未被观察过的数据（不包含在训练数据中的数据）的能力。 获得泛化能力是机器学习的最终目标。 4.4.1 梯度法根据寻找最小值还是最大值，寻找最小值的梯度法称为梯度下降法，寻找最大值的梯度法称为梯度上升法。但是通过反转损失函数的符号，求最大和最小值会变成相同的问题，所以一般来说，神经网络（深度学习）中，梯度法指的是梯度下降法。 第5章 误差反向传播法5.4 简单层的实现Affine层是负责矩阵乘积的。 第6章 与学习相关的技巧6.1.3 SGD的缺点为了改正SGD的缺点，我们可以使用优化算法Momentum，AdaGrad，Adam等。 第7章 卷积神经网络第8章 深度学习","link":"/2019/09/07/《深度学习入门》阅读笔记/"},{"title":"机器学习VS深度学习的区别","text":"本文我们主要涉及到: 数据相关性 硬件依赖性 特征工程 解决问题方法 执行时间 可解释性 1.数据的相关性深度学习与传统机器学习最重要的区别是，随着数据量的增加，其性能也随之提高。当数据很小的时候，深度学习算法并不能很好地执行，这是因为深度学习算法需要大量的数据才能完全理解它。下图便能很好的说明这个事实：从上图我们可以看到，随着数据量的增大，深度学习的性能会越来越好，而传统机器学习方法性能表现却趋于平缓；但传统的机器学习算法在数据量较小的情况下，比深度学习有着更好的表现。 2.硬件的依赖性深度学习算法在很大程度上依赖于高端机器，而传统的机器学习算法可以在低端机器上工作。这是因为深度学习算法对GPU有较高的要求，GPU是其工作的一个组成部分。因为深度学习算法要固有地执行大量的矩阵乘法运算，而使用GPU可以有效地优化这些操作，这就免不了对GPU的依赖。而相比之下，机器学习算法对硬件配置没有很高的要求。 3.特征工程特征工程是将领域知识应用到特征抽取的创建过程，以降低数据的复杂性为目的。但这一过程在训练时间和如何提取特征方面十分地困难。 在机器学习中，大多数应用的特征需要由专家识别，然后根据域和数据类型手工编码。 例如，特征可以是像素值、形状、纹理、位置和方向，大多数机器学习算法的性能取决于特征识别和提取的准确程度。 而深度学习算法则试图从数据中学习更高级的特性。这是深度学习一个非常独特的部分，也是有别于传统机器学习的一部分。因此，深度学习减少了为每个问题开发新的特征抽取的任务，而是像卷积神经网络（CNN）这样尝试学习低层次的特征，如：早期层次的边缘和线条，然后是人脸的一部分，最后才是人脸的高层次表示。这样的方式相较于机器学习，在训练时间和成本上有较高的提升。 4.解决问题方法在使用传统的机器学习算法解决问题时，通常的做法是将问题分解成不同的部分，然后单独解决，最后结合起来得到结果。相比之下，深度学习更提倡端到端地解决问题。让我们举个例子来理解这一点。如图所示是一个多对象检测任务，我们的目标是哟啊确定对象是什么以及它在图像中的位置。 在典型的机器学习方法中，我们会将问题分为两个步骤：对象检测和对象识别。首先，我们将使用一个边界检测算法，如：GrabCut，来浏览图像并找到图像中所有可能的对象；然后，在所有已识别的对象中，我们再使用对象识别算法（如：SVM）来识别相关对象，最后再判断对象的位置。 不同于传统机器学习算法，在深度学习的方法中，我们将进行端到端的学习过程。例如，使用YOLO算法（一种深度学习算法）。我们往YOLO网络中传入一张图像，它将给出对象的具体位置和名称。是不是方便了很多呢？ 5.执行时间通常，深度学习算法需要很长的时间来训练，这是因为在深度学习算法中有太多的参数，所以训练这些参数的时间比平时要长。即使比较先进的深度学习算法Resnet，从零开始完全训练也需要大约两周的时间。相比之下，机器学习所需的训练时间要少得多，从几秒钟到几个小时不等。 相较于训练时间，测试时间就要短很多。在测试时，深度学习算法的运行时间要短得多。但是，如果将其与k近邻机器学习算法进行比较，测试时间会随着数据大小的增加而增加。但这并不适用于所有机器学习算法，因为其中一些算法的测试时间也很短。 6.可解释性最后，我们将可解释性作为比较机器学习和深度学习的一个因素。这一因素也是深度学习难以在工业中取得大规模应用的主要原因。 我们举个例子：假设我们使用深度学习为论文自动评分，它在得分方面的表现相当出色，接近于人类的表现。但有一个问题：深度学习并没有揭示它为什么会给出那个分数。事实上，从数学中我们可以发现深度神经网络的哪些节点被激活，但是我们不知道神经元应该做什模型以及这些神经元层共同在做什么，所以我们无法对结果进解释。 而相较于深度学习，类似于决策树这样的机器学习算法为我们提供了清晰的规则，告诉我们什么是它的选择以及为什么选择了它，很容易解释算法背后的推理。因此，决策树和线性/逻辑回归等机器学习算法主要用于工业中需要可解释性的场景。","link":"/2019/09/05/机器学习VS深度学习的区别/"},{"title":"Git操作","text":"一.Git简介Git 是一种分布式版本控制系统，它可以不受网络连接的限制，加上其它众多优点，目前已经成为程序开发人员做项目版本管理时的首选，非开发人员也可以用 Git 来做自己的文档版本管理工具。 Git 的api很多，但其实平时项目中90%的需求都只需要用到几个基本的功能即可，所以本文将从实用主和深入探索(后期更新)2个方面去谈谈如何在项目中使用 Git，一般来说，看完实用主义这一节就可以开始在项目中动手用。 说明：本文的操作都是基于Windows系统 二.实用主义1.准备阶段 工具准备 进入 Git官网下载合适你的安装包。 账号准备 进入Github网站 注册一个账号就可以使用了。 2.常用操作所谓实用主义，就是掌握了以下知识就可以玩转 Git，轻松应对90%以上的需求。以下是实用主义型的Git命令列表，先大致看一下: git clone git config git branch git checkout git status git add git commit git push git pull git log git tag (1)git clone 从git服务器拉取代码 1git clone https://github.com/user/repo.git (2)git config 配置开发者用户名和邮箱 12git config user.name usergit config user.email user@qq.com (3)git branch 创建、重命名、查看、删除项目分支，通过Git做项目开发时，一般都是在开发分支中进行，开发完成后合并分支到主干。 1git branch daily/0.0.0 创建一个名为daily/0.0.0的日常开发分支，分支名只要不包括特殊字符即可。 1git branch -m daily/0.0.0 daily/0.0.1 如果觉得之前的分支名不合适，可以为新建的分支重命名，重命名分支名为daily/0.0.1。 1git branch 通过不带参数的branch命令可以查看当前项目分支列表。 1git branch -d daily/0.0.1 如果分支已经完成使命则可以通过-d参数将分支删除，这里为了继续下一步操作，暂不执行删除操作。 (4)git checkout 切换分支 1git checkout daily/0.0.1 (5)git status 查看文件变动状态通过任何你喜欢的编辑器对项目中的 README.md 文件做一些改动，保存。 1git status 通过git status命令可以看到文件当前状态Changes not staged for commit:(改动文件未提交到暂存区） 123456On branch daily/0.0.1Changes not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: README.mdno changes added to commit (use \"git add\" and/or \"git commit -a\") (6)git add 添加文件变动到暂存区 1git add README.md 通过指定文件名README.md可以将该文件添加到暂存区，如果想添加所有文件可用git add. 命令，这时候可通过git status看到文件当前状态Changes to be committed:（文件已提交到暂存区） 1234On branch daily/0.0.1Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) modified: README.md (7)git commit 提交文件变动到版本库 1git commit -m '这里写提交原因' 通过-m参数可直接在命令行里输入提交描述文本。 (8)git push 将本地的代码改动推送到服务器 1git push origin daily/0.0.1 origin 指代的是当前的git服务器地址，这行命令的意思是把 daily/0.0.1 分支推送到服务器，当看到命令行返回如下字符表示推送成功了。 12345678Counting objects: 3, done.Delta compression using up to 8 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 267 bytes | 0 bytes/s, done.Total 3 (delta 1), reused 0 (delta 0)remote: Resolving deltas: 100% (1/1), completed with 1 local objects.To https://github.com/gafish/gafish.github.com.git * [new branch] daily/0.0.1 -&gt; daily/0.0.1 现在我们回到Github网站的项目首页，点击Branch:master下拉按钮，就会看到刚才推送的daily/00.1分支了。 (9)git pull 将服务器上的最新代码拉取到本地 1git pull origin daily/0.0.1 如果其它项目成员对项目做了改动并推送到服务器，我们需要将最新的改动更新到本地，这里我们来模拟一下这种情况。 进入Github网站的项目首页，再进入daily/0.0.1分支，在线对README.md文件做一些修改并保存，然后在命令中执行以上命令，它将把刚才在线修改的部分拉取到本地，用编辑器打开README.md，你会发现文件已经跟线上的内容同步了。 如果线上代码做了变动，而你本地的代码也有变动，拉取的代码就有可能会跟你本地的改动冲突，一般情况下Git会自动处理这种冲突合并，但如果改动的是同一行，那就需要手动来合并代码，编辑文件，保存最新的改动，再通过git add .和git commit -m ‘xxx’来提交合并。 (10)git log 查看版本提交记录 1git log 通过以上命令，我们可以查看整个项目的版本提交记录，它里面包含了提交人、日期、提交原因等信息，得到的结果如下： 123456789commit c334730f8dba5096c54c8ac04fdc2b31ede7107aAuthor: gafish &lt;gafish@qqqq.com&gt;Date: Wed Jan 11 09:44:13 2017 +0800 Update README.mdcommit ba6e3d21fcb1c87a718d2a73cdd11261eb672b2aAuthor: gafish &lt;gafish@qqqq.com&gt;Date: Wed Jan 11 09:31:33 2017 +0800 test..... 提交记录可能会非常多，按J键往下翻，按K键往上翻，按Q键退出查看。 (11)git tag 为项目标记里程碑 12git tag publish/0.0.1git push origin publish/0.0.1 当我们完成某个功能需求准备发布上线时，应该将此次完整的项目代码做个标记，并将这个标记好的版本发布到线上，这里我们以publish/0.0.1为标记名并发布，当看到命令行返回如下内容则表示发布成功了。 123Total 0 (delta 0), reused 0 (delta 0)To https://github.com/gafish/gafish.github.com.git * [new tag] publish/0.0.1 -&gt; publish/0.0.1 (12).gitignore 设置哪些内容不需要推送到服务器，这是一个配置文件 1touch .gitignore .gitignore 不是Git命令，而在项目中的一个文件，通过设置.gitignore的内容告诉Git哪些文件应该被忽略不需要推送到服务器，通过以上命令可以创建一个.gitignore文件，并在编辑器中打开文件，每一行代表一个要忽略的文件或目录，如： 12demo.htmlbuild/ 以上内容的意思是Git将忽略demo.html文件 和build/目录，这些内容不会被推送到服务器上。 小结 通过掌握以上这些基本命令就可以在项目中开始用起来了，如果追求实用，那关于Git的学习就可以到此结束了，偶尔遇到的问题也基本上通过Google/百度也能找到答案。","link":"/2019/09/04/Git操作/"}],"tags":[{"name":"学习资料","slug":"学习资料","link":"/tags/学习资料/"},{"name":"机器学习","slug":"机器学习","link":"/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","link":"/tags/深度学习/"},{"name":"Git常用操作","slug":"Git常用操作","link":"/tags/Git常用操作/"},{"name":"抠图","slug":"抠图","link":"/tags/抠图/"},{"name":"迷宫","slug":"迷宫","link":"/tags/迷宫/"},{"name":"生命游戏","slug":"生命游戏","link":"/tags/生命游戏/"},{"name":"Anaconda","slug":"Anaconda","link":"/tags/Anaconda/"},{"name":"python常用包","slug":"python常用包","link":"/tags/python常用包/"},{"name":"数学基础","slug":"数学基础","link":"/tags/数学基础/"},{"name":"内网穿透工具","slug":"内网穿透工具","link":"/tags/内网穿透工具/"},{"name":"matplotlib","slug":"matplotlib","link":"/tags/matplotlib/"},{"name":"周志华论文","slug":"周志华论文","link":"/tags/周志华论文/"},{"name":"python常用代码","slug":"python常用代码","link":"/tags/python常用代码/"},{"name":"概率分布","slug":"概率分布","link":"/tags/概率分布/"},{"name":"cython","slug":"cython","link":"/tags/cython/"},{"name":"数据集-推荐系统","slug":"数据集-推荐系统","link":"/tags/数据集-推荐系统/"},{"name":"小工具","slug":"小工具","link":"/tags/小工具/"},{"name":"开源协议","slug":"开源协议","link":"/tags/开源协议/"},{"name":"可视化","slug":"可视化","link":"/tags/可视化/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"镜像","slug":"镜像","link":"/tags/镜像/"},{"name":"电子书网站","slug":"电子书网站","link":"/tags/电子书网站/"},{"name":"简历制作","slug":"简历制作","link":"/tags/简历制作/"},{"name":"论文翻译","slug":"论文翻译","link":"/tags/论文翻译/"},{"name":"云栖大会","slug":"云栖大会","link":"/tags/云栖大会/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"},{"name":"验证码识别","slug":"验证码识别","link":"/tags/验证码识别/"},{"name":"论文","slug":"论文","link":"/tags/论文/"},{"name":"告研究生新生/研究生导师书","slug":"告研究生新生-研究生导师书","link":"/tags/告研究生新生-研究生导师书/"},{"name":"Numpy","slug":"Numpy","link":"/tags/Numpy/"},{"name":"论文-续","slug":"论文-续","link":"/tags/论文-续/"},{"name":"简历","slug":"简历","link":"/tags/简历/"},{"name":"祖国母亲七十周年","slug":"祖国母亲七十周年","link":"/tags/祖国母亲七十周年/"},{"name":"Child’s Play","slug":"Child’s-Play","link":"/tags/Child’s-Play/"},{"name":"数据集","slug":"数据集","link":"/tags/数据集/"},{"name":"学术网站","slug":"学术网站","link":"/tags/学术网站/"},{"name":"C++","slug":"C","link":"/tags/C/"}],"categories":[{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"内网穿透","slug":"内网穿透","link":"/categories/内网穿透/"},{"name":"阅读笔记","slug":"阅读笔记","link":"/categories/阅读笔记/"},{"name":"杂谈","slug":"杂谈","link":"/categories/杂谈/"},{"name":"学习","slug":"学习","link":"/categories/学习/"},{"name":"死磕系列","slug":"死磕系列","link":"/categories/死磕系列/"},{"name":"随记","slug":"随记","link":"/categories/随记/"},{"name":"随笔","slug":"随笔","link":"/categories/随笔/"},{"name":"编程语言","slug":"编程语言","link":"/categories/编程语言/"}]}